{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-rO6TQRIGB1",
        "outputId": "d4c31802-a2b9-4588-93bf-030f5a3260a8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/chatterbox-finetuning"
      ],
      "metadata": {
        "id": "KDeS-4AHain1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# CHATTERBOX FINETUNING - FIXED VERSION\n",
        "# ========================================\n",
        "\n",
        "\n",
        "!git clone https://github.com/thienphucope/chatterbox-lora\n",
        "\n",
        "%cd chatterbox-lora\n",
        "\n",
        "\n",
        "# 2. Gá»¡ cÃ¡c packages conflict\n",
        "!pip uninstall -y torchvision torch torchaudio transformers peft\n",
        "\n",
        "# 3. CÃ i PyTorch stack\n",
        "!pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "# 4. CÃ i numpy\n",
        "!pip install numpy==1.24.4 --only-binary=numpy\n",
        "\n",
        "# 5. CRITICAL: CÃ i transformers + peft compatible versions\n",
        "!pip install transformers==4.44.2 peft==0.13.2\n",
        "\n",
        "# 6. CÃ i cÃ¡c dependencies cÃ²n láº¡i\n",
        "!pip install librosa==0.11.0 \\\n",
        "    s3tokenizer \\\n",
        "    diffusers==0.29.0 \\\n",
        "    resemble-perth==1.0.1 \\\n",
        "    conformer==0.3.2 \\\n",
        "    safetensors==0.5.3 \\\n",
        "    pykakasi==2.3.0 \\\n",
        "    gradio==5.44.1\n",
        "\n",
        "!pip install whisper-openai \\\n",
        "    jiwer \\\n",
        "    sounddevice==0.5.2 \\\n",
        "\n",
        "# 7. CÃ i training dependencies\n",
        "!pip install datasets>=2.17.0 \\\n",
        "    accelerate>=0.27.0 \\\n",
        "    evaluate>=0.4.1 \\\n",
        "    tensorboard \\\n",
        "    wandb\n",
        "\n",
        "# 8. Verify installation\n",
        "import torch\n",
        "import torchvision\n",
        "import transformers\n",
        "import peft\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(f\"âœ“ PyTorch: {torch.__version__}\")\n",
        "print(f\"âœ“ Torchvision: {torchvision.__version__}\")\n",
        "print(f\"âœ“ Transformers: {transformers.__version__}\")\n",
        "print(f\"âœ“ PEFT: {peft.__version__}\")\n",
        "print(f\"âœ“ CUDA: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"âœ“ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"âœ“ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 9. Test critical imports\n",
        "try:\n",
        "    from transformers import Trainer, TrainingArguments\n",
        "    print(\"âœ“ Trainer import OK!\")\n",
        "except Exception as e:\n",
        "    print(f\"âœ— Trainer Error: {e}\")\n",
        "\n",
        "import os\n",
        "if os.path.exists('src/finetune_t3.py'):\n",
        "    print(\"âœ“ finetune_t3.py found!\")\n",
        "    print(\"\\nğŸš€ Ready to train!\")\n",
        "else:\n",
        "    print(\"âœ— finetune_t3.py not found\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-O060dWZ3iW",
        "outputId": "5729e4b4-0d52-4684-da71-7065a9c87246"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'chatterbox-lora'...\n",
            "remote: Enumerating objects: 100, done.\u001b[K\n",
            "remote: Counting objects: 100% (100/100), done.\u001b[K\n",
            "remote: Compressing objects: 100% (93/93), done.\u001b[K\n",
            "remote: Total 100 (delta 20), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (100/100), 136.80 KiB | 9.12 MiB/s, done.\n",
            "Resolving deltas: 100% (20/20), done.\n",
            "/content/chatterbox-lora\n",
            "Found existing installation: torchvision 0.24.0+cu126\n",
            "Uninstalling torchvision-0.24.0+cu126:\n",
            "  Successfully uninstalled torchvision-0.24.0+cu126\n",
            "Found existing installation: torch 2.9.0+cu126\n",
            "Uninstalling torch-2.9.0+cu126:\n",
            "  Successfully uninstalled torch-2.9.0+cu126\n",
            "Found existing installation: torchaudio 2.9.0+cu126\n",
            "Uninstalling torchaudio-2.9.0+cu126:\n",
            "  Successfully uninstalled torchaudio-2.9.0+cu126\n",
            "Found existing installation: transformers 4.57.3\n",
            "Uninstalling transformers-4.57.3:\n",
            "  Successfully uninstalled transformers-4.57.3\n",
            "Found existing installation: peft 0.18.0\n",
            "Uninstalling peft-0.18.0:\n",
            "  Successfully uninstalled peft-0.18.0\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting torch==2.5.1\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp312-cp312-linux_x86_64.whl (780.4 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m780.4/780.4 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.20.1\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp312-cp312-linux_x86_64.whl (7.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m144.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.5.1\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp312-cp312-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m119.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (4.15.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m119.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m144.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.21.5 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.1.0 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.6 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m209.6/209.6 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (75.2.0)\n",
            "Collecting sympy==1.13.1 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m115.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.20.1) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.20.1) (11.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.5.1) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch==2.5.1) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.5.1) (3.0.3)\n",
            "Installing collected packages: triton, sympy, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.5.0\n",
            "    Uninstalling triton-3.5.0:\n",
            "      Successfully uninstalled triton-3.5.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.14.0\n",
            "    Uninstalling sympy-1.14.0:\n",
            "      Successfully uninstalled sympy-1.14.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 5.1.2 requires transformers<5.0.0,>=4.41.0, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.21.5 nvidia-nvtx-cu12-12.1.105 sympy-1.13.1 torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121 triton-3.1.0\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement numpy==1.24.4 (from versions: 1.26.0, 1.26.1, 1.26.2, 1.26.3, 1.26.4, 2.0.0, 2.0.1, 2.0.2, 2.1.0, 2.1.1, 2.1.2, 2.1.3, 2.2.0, 2.2.1, 2.2.2, 2.2.3, 2.2.4, 2.2.5, 2.2.6, 2.3.0, 2.3.1, 2.3.2, 2.3.3, 2.3.4, 2.3.5, 2.4.0rc1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for numpy==1.24.4\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting transformers==4.44.2\n",
            "  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting peft==0.13.2\n",
            "  Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (2.32.4)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (0.7.0)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers==4.44.2)\n",
            "  Downloading tokenizers-0.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft==0.13.2) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from peft==0.13.2) (2.5.1+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from peft==0.13.2) (1.12.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (1.2.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (75.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.13.2) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft==0.13.2) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft==0.13.2) (1.3.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (2025.11.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->peft==0.13.2) (3.0.3)\n",
            "Downloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m116.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.13.2-py3-none-any.whl (320 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m103.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers, peft\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.1\n",
            "    Uninstalling tokenizers-0.22.1:\n",
            "      Successfully uninstalled tokenizers-0.22.1\n",
            "Successfully installed peft-0.13.2 tokenizers-0.19.1 transformers-4.44.2\n",
            "Requirement already satisfied: librosa==0.11.0 in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Collecting s3tokenizer\n",
            "  Downloading s3tokenizer-0.2.0.tar.gz (225 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m225.2/225.2 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting diffusers==0.29.0\n",
            "  Downloading diffusers-0.29.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting resemble-perth==1.0.1\n",
            "  Downloading resemble_perth-1.0.1-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting conformer==0.3.2\n",
            "  Downloading conformer-0.3.2-py3-none-any.whl.metadata (631 bytes)\n",
            "Collecting safetensors==0.5.3\n",
            "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting pykakasi==2.3.0\n",
            "  Downloading pykakasi-2.3.0-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting gradio==5.44.1\n",
            "  Downloading gradio-5.44.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa==0.11.0) (3.1.0)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa==0.11.0) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from librosa==0.11.0) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from librosa==0.11.0) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa==0.11.0) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa==0.11.0) (1.5.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa==0.11.0) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from librosa==0.11.0) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa==0.11.0) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa==0.11.0) (1.0.0)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from librosa==0.11.0) (4.15.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa==0.11.0) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa==0.11.0) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.12/dist-packages (from diffusers==0.29.0) (8.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from diffusers==0.29.0) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.2 in /usr/local/lib/python3.12/dist-packages (from diffusers==0.29.0) (0.36.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from diffusers==0.29.0) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from diffusers==0.29.0) (2.32.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from diffusers==0.29.0) (11.3.0)\n",
            "Requirement already satisfied: einops>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from conformer==0.3.2) (0.8.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from conformer==0.3.2) (2.5.1+cu121)\n",
            "Collecting jaconv (from pykakasi==2.3.0)\n",
            "  Downloading jaconv-0.4.1-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting deprecated (from pykakasi==2.3.0)\n",
            "  Downloading deprecated-1.3.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio==5.44.1) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio==5.44.1) (4.12.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio==5.44.1) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio==5.44.1) (0.118.3)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio==5.44.1) (1.0.0)\n",
            "Collecting gradio-client==1.12.1 (from gradio==5.44.1)\n",
            "  Downloading gradio_client-1.12.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio==5.44.1) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio==5.44.1) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio==5.44.1) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio==5.44.1) (3.0.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio==5.44.1) (3.11.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio==5.44.1) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio==5.44.1) (2.2.2)\n",
            "Collecting pydantic<2.12,>=2.0 (from gradio==5.44.1)\n",
            "  Downloading pydantic-2.11.10-py3-none-any.whl.metadata (68 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m68.6/68.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio==5.44.1) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio==5.44.1) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio==5.44.1) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio==5.44.1) (0.14.8)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio==5.44.1) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio==5.44.1) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio==5.44.1) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio==5.44.1) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio==5.44.1) (0.20.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio==5.44.1) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio==5.44.1) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio==5.44.1) (15.0.1)\n",
            "Collecting pre-commit (from s3tokenizer)\n",
            "  Downloading pre_commit-4.5.0-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting onnx (from s3tokenizer)\n",
            "  Downloading onnx-1.20.0-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from s3tokenizer) (4.67.1)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (from s3tokenizer) (2.5.1+cu121)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio==5.44.1) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio==5.44.1) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio==5.44.1) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio==5.44.1) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.29.0) (1.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa==0.11.0) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio==5.44.1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio==5.44.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio==5.44.1) (2025.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa==0.11.0) (4.5.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio==5.44.1) (0.7.0)\n",
            "Collecting pydantic-core==2.33.2 (from pydantic<2.12,>=2.0->gradio==5.44.1)\n",
            "  Downloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio==5.44.1) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.29.0) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers==0.29.0) (2.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa==0.11.0) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->librosa==0.11.0) (2.0.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio==5.44.1) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio==5.44.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio==5.44.1) (13.9.4)\n",
            "Requirement already satisfied: wrapt<3,>=1.10 in /usr/local/lib/python3.12/dist-packages (from deprecated->pykakasi==2.3.0) (2.0.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata->diffusers==0.29.0) (3.23.0)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx->s3tokenizer) (5.29.5)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from onnx->s3tokenizer) (0.5.4)\n",
            "Collecting cfgv>=2.0.0 (from pre-commit->s3tokenizer)\n",
            "  Downloading cfgv-3.5.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting identify>=1.0.0 (from pre-commit->s3tokenizer)\n",
            "  Downloading identify-2.6.15-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting nodeenv>=0.11.1 (from pre-commit->s3tokenizer)\n",
            "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Collecting virtualenv>=20.10.0 (from pre-commit->s3tokenizer)\n",
            "  Downloading virtualenv-20.35.4-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->conformer==0.3.2) (3.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->conformer==0.3.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->conformer==0.3.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->conformer==0.3.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch->conformer==0.3.2) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch->conformer==0.3.2) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch->conformer==0.3.2) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch->conformer==0.3.2) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch->conformer==0.3.2) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch->conformer==0.3.2) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.12/dist-packages (from torch->conformer==0.3.2) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->conformer==0.3.2) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.12/dist-packages (from torch->conformer==0.3.2) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->conformer==0.3.2) (75.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.12/dist-packages (from torch->conformer==0.3.2) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->conformer==0.3.2) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch->conformer==0.3.2) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa==0.11.0) (2.23)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio==5.44.1) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==5.44.1) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==5.44.1) (2.19.2)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit->s3tokenizer)\n",
            "  Downloading distlib-0.4.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio==5.44.1) (0.1.2)\n",
            "Downloading diffusers-0.29.0-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading resemble_perth-1.0.1-py3-none-any.whl (34.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading conformer-0.3.2-py3-none-any.whl (4.3 kB)\n",
            "Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pykakasi-2.3.0-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-5.44.1-py3-none-any.whl (60.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.2/60.2 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.12.1-py3-none-any.whl (324 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m324.6/324.6 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.11.10-py3-none-any.whl (444 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m444.8/444.8 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deprecated-1.3.1-py2.py3-none-any.whl (11 kB)\n",
            "Downloading jaconv-0.4.1-py3-none-any.whl (15 kB)\n",
            "Downloading onnx-1.20.0-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (18.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m123.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pre_commit-4.5.0-py2.py3-none-any.whl (226 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m226.4/226.4 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cfgv-3.5.0-py2.py3-none-any.whl (7.4 kB)\n",
            "Downloading identify-2.6.15-py2.py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.2/99.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading virtualenv-20.35.4-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m140.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distlib-0.4.0-py2.py3-none-any.whl (469 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: s3tokenizer\n",
            "  Building wheel for s3tokenizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for s3tokenizer: filename=s3tokenizer-0.2.0-py3-none-any.whl size=221564 sha256=2ddb14d7307fb12499d5823a494f8bb744010cb43aae9623ba0c47d648a41b10\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/b7/c0/8cbcc805e7cc360cf38296016fb2dd0324cc7b3fb90e3baf7a\n",
            "Successfully built s3tokenizer\n",
            "Installing collected packages: jaconv, distlib, virtualenv, safetensors, resemble-perth, pydantic-core, nodeenv, identify, deprecated, cfgv, pykakasi, pydantic, pre-commit, onnx, gradio-client, diffusers, gradio, conformer, s3tokenizer\n",
            "  Attempting uninstall: safetensors\n",
            "    Found existing installation: safetensors 0.7.0\n",
            "    Uninstalling safetensors-0.7.0:\n",
            "      Successfully uninstalled safetensors-0.7.0\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.41.4\n",
            "    Uninstalling pydantic_core-2.41.4:\n",
            "      Successfully uninstalled pydantic_core-2.41.4\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.12.3\n",
            "    Uninstalling pydantic-2.12.3:\n",
            "      Successfully uninstalled pydantic-2.12.3\n",
            "  Attempting uninstall: gradio-client\n",
            "    Found existing installation: gradio_client 1.14.0\n",
            "    Uninstalling gradio_client-1.14.0:\n",
            "      Successfully uninstalled gradio_client-1.14.0\n",
            "  Attempting uninstall: diffusers\n",
            "    Found existing installation: diffusers 0.35.2\n",
            "    Uninstalling diffusers-0.35.2:\n",
            "      Successfully uninstalled diffusers-0.35.2\n",
            "  Attempting uninstall: gradio\n",
            "    Found existing installation: gradio 5.50.0\n",
            "    Uninstalling gradio-5.50.0:\n",
            "      Successfully uninstalled gradio-5.50.0\n",
            "Successfully installed cfgv-3.5.0 conformer-0.3.2 deprecated-1.3.1 diffusers-0.29.0 distlib-0.4.0 gradio-5.44.1 gradio-client-1.12.1 identify-2.6.15 jaconv-0.4.1 nodeenv-1.9.1 onnx-1.20.0 pre-commit-4.5.0 pydantic-2.11.10 pydantic-core-2.33.2 pykakasi-2.3.0 resemble-perth-1.0.1 s3tokenizer-0.2.0 safetensors-0.5.3 virtualenv-20.35.4\n",
            "Collecting whisper-openai\n",
            "  Downloading whisper_openai-1.0.0-py3-none-any.whl.metadata (480 bytes)\n",
            "Collecting jiwer\n",
            "  Downloading jiwer-4.0.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting sounddevice==0.5.2\n",
            "  Downloading sounddevice-0.5.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.12/dist-packages (from sounddevice==0.5.2) (2.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from whisper-openai) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from whisper-openai) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from whisper-openai) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from whisper-openai) (10.8.0)\n",
            "Requirement already satisfied: transformers>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from whisper-openai) (4.44.2)\n",
            "Collecting ffmpeg-python==0.2.0 (from whisper-openai)\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from ffmpeg-python==0.2.0->whisper-openai) (1.0.0)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from jiwer) (8.3.1)\n",
            "Collecting rapidfuzz>=3.9.7 (from jiwer)\n",
            "  Downloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from CFFI>=1.0->sounddevice==0.5.2) (2.23)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers>=4.19.0->whisper-openai) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.19.0->whisper-openai) (0.36.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.19.0->whisper-openai) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.19.0->whisper-openai) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.19.0->whisper-openai) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers>=4.19.0->whisper-openai) (2.32.4)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.19.0->whisper-openai) (0.5.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.19.0->whisper-openai) (0.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch->whisper-openai) (4.15.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->whisper-openai) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->whisper-openai) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->whisper-openai) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->whisper-openai) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->whisper-openai) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->whisper-openai) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch->whisper-openai) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch->whisper-openai) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch->whisper-openai) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch->whisper-openai) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch->whisper-openai) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch->whisper-openai) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.12/dist-packages (from torch->whisper-openai) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->whisper-openai) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.12/dist-packages (from torch->whisper-openai) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->whisper-openai) (75.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.12/dist-packages (from torch->whisper-openai) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->whisper-openai) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch->whisper-openai) (1.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers>=4.19.0->whisper-openai) (1.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->whisper-openai) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.19.0->whisper-openai) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.19.0->whisper-openai) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.19.0->whisper-openai) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.19.0->whisper-openai) (2025.11.12)\n",
            "Downloading sounddevice-0.5.2-py3-none-any.whl (32 kB)\n",
            "Downloading whisper_openai-1.0.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Downloading jiwer-4.0.0-py3-none-any.whl (23 kB)\n",
            "Downloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m113.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, ffmpeg-python, sounddevice, jiwer, whisper-openai\n",
            "Successfully installed ffmpeg-python-0.2.0 jiwer-4.0.0 rapidfuzz-3.14.3 sounddevice-0.5.2 whisper-openai-1.0.0\n",
            "============================================================\n",
            "âœ“ PyTorch: 2.5.1+cu121\n",
            "âœ“ Torchvision: 0.20.1+cu121\n",
            "âœ“ Transformers: 4.44.2\n",
            "âœ“ PEFT: 0.13.2\n",
            "âœ“ CUDA: True\n",
            "âœ“ GPU: NVIDIA L4\n",
            "âœ“ VRAM: 23.80 GB\n",
            "============================================================\n",
            "âœ“ Trainer import OK!\n",
            "âœ— finetune_t3.py not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.makedirs(\"/content/chatterbox-lora/viterbox\", exist_ok=True)\n",
        "%cd /content/chatterbox-lora/viterbox\n",
        "\n",
        "!wget https://huggingface.co/ResembleAI/chatterbox/resolve/main/ve.pt -O ve.pt\n",
        "!wget https://huggingface.co/ResembleAI/chatterbox/resolve/main/s3gen.safetensors -O s3gen.safetensors\n",
        "!wget https://huggingface.co/ResembleAI/chatterbox/resolve/main/conds.pt -O conds.pt\n",
        "\n",
        "# Ä‘á»•i tÃªn t3_ml24ls_v2.safetensors thÃ nh t3_cfg.safetensors\n",
        "!wget https://huggingface.co/dolly-vn/viterbox/resolve/main/t3_ml24ls_v2.safetensors -O t3_cfg.safetensors\n",
        "\n",
        "# Ä‘á»•i tÃªn tokenizer_vi_expanded.json thÃ nh tokenizer.json\n",
        "!wget https://huggingface.co/dolly-vn/viterbox/resolve/main/tokenizer_vi_expanded.json -O tokenizer.json\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuOEih2kg6Up",
        "outputId": "ae7fd717-68b0-4cc8-966e-1ab30a001bbf",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/chatterbox-lora/viterbox\n",
            "--2025-12-10 09:48:20--  https://huggingface.co/ResembleAI/chatterbox/resolve/main/ve.pt\n",
            "Resolving huggingface.co (huggingface.co)... 13.35.238.7, 13.35.238.89, 13.35.238.47, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.35.238.7|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/680a289582ee1640eea64f70/c2191264313a0c9411d8a001dac2f58b7fae8d22f11420fef84e6c44fddbad67?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251210%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251210T094820Z&X-Amz-Expires=3600&X-Amz-Signature=3108ee25180b63a9ed8a17cf0e40ddd8d5ff4fde2b581cb2bbbbdcf1dd7ded6a&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27ve.pt%3B+filename%3D%22ve.pt%22%3B&x-id=GetObject&Expires=1765363700&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2NTM2MzcwMH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82ODBhMjg5NTgyZWUxNjQwZWVhNjRmNzAvYzIxOTEyNjQzMTNhMGM5NDExZDhhMDAxZGFjMmY1OGI3ZmFlOGQyMmYxMTQyMGZlZjg0ZTZjNDRmZGRiYWQ2NyoifV19&Signature=I%7E5PEeCJ1Nv7867fyzPS3DqbOPD6k2BVIMorAukBsYjC%7Ea3en5KgEt2eA-H%7EA77sdjuvkWUUwa8OIaZqJuxC2Ksl6rxq%7Ei6%7EQ%7EZQd1Q4Iix93d7UY5cVWDUQMmdlmzUriW4ANs8LOoz2ZLmLp7dq40fSZYW2OhZzfdx%7EFT7GBF8SYaR293JvS9zddrSY5xG7RGhRnf2NZ-l3tUtUupw4ngXuMyyhLuaaiC-ipaCLiwOvLi2Nt4-cXGUNZJ1h-K8922-KdMAUeRxaGqByMuMP8a83neuaS9R2fjzV4gn4GqzlBL7dCQ9WlMJyO7E3YJ3TArpbj9DxJ7jWMq%7EANwR9WQ__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n",
            "--2025-12-10 09:48:20--  https://cas-bridge.xethub.hf.co/xet-bridge-us/680a289582ee1640eea64f70/c2191264313a0c9411d8a001dac2f58b7fae8d22f11420fef84e6c44fddbad67?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251210%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251210T094820Z&X-Amz-Expires=3600&X-Amz-Signature=3108ee25180b63a9ed8a17cf0e40ddd8d5ff4fde2b581cb2bbbbdcf1dd7ded6a&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27ve.pt%3B+filename%3D%22ve.pt%22%3B&x-id=GetObject&Expires=1765363700&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2NTM2MzcwMH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82ODBhMjg5NTgyZWUxNjQwZWVhNjRmNzAvYzIxOTEyNjQzMTNhMGM5NDExZDhhMDAxZGFjMmY1OGI3ZmFlOGQyMmYxMTQyMGZlZjg0ZTZjNDRmZGRiYWQ2NyoifV19&Signature=I%7E5PEeCJ1Nv7867fyzPS3DqbOPD6k2BVIMorAukBsYjC%7Ea3en5KgEt2eA-H%7EA77sdjuvkWUUwa8OIaZqJuxC2Ksl6rxq%7Ei6%7EQ%7EZQd1Q4Iix93d7UY5cVWDUQMmdlmzUriW4ANs8LOoz2ZLmLp7dq40fSZYW2OhZzfdx%7EFT7GBF8SYaR293JvS9zddrSY5xG7RGhRnf2NZ-l3tUtUupw4ngXuMyyhLuaaiC-ipaCLiwOvLi2Nt4-cXGUNZJ1h-K8922-KdMAUeRxaGqByMuMP8a83neuaS9R2fjzV4gn4GqzlBL7dCQ9WlMJyO7E3YJ3TArpbj9DxJ7jWMq%7EANwR9WQ__&Key-Pair-Id=K2L8F4GPSG1IFC\n",
            "Resolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 18.155.68.69, 18.155.68.125, 18.155.68.14, ...\n",
            "Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|18.155.68.69|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5698626 (5.4M)\n",
            "Saving to: â€˜ve.ptâ€™\n",
            "\n",
            "ve.pt               100%[===================>]   5.43M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-12-10 09:48:20 (294 MB/s) - â€˜ve.ptâ€™ saved [5698626/5698626]\n",
            "\n",
            "--2025-12-10 09:48:20--  https://huggingface.co/ResembleAI/chatterbox/resolve/main/s3gen.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 13.35.238.7, 13.35.238.89, 13.35.238.47, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.35.238.7|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/680a289582ee1640eea64f70/ff5bfeb1f056b26d2db78035095e5c4c72b78db5bfbaae8f329a3eb6b8b7c914?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251210%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251210T093506Z&X-Amz-Expires=3600&X-Amz-Signature=aaf9b8ce3d7bf415a39b37f144ee5412b37a98200704a1f0da592532a3df8dfe&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27s3gen.safetensors%3B+filename%3D%22s3gen.safetensors%22%3B&x-id=GetObject&Expires=1765362906&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2NTM2MjkwNn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82ODBhMjg5NTgyZWUxNjQwZWVhNjRmNzAvZmY1YmZlYjFmMDU2YjI2ZDJkYjc4MDM1MDk1ZTVjNGM3MmI3OGRiNWJmYmFhZThmMzI5YTNlYjZiOGI3YzkxNCoifV19&Signature=Yits3lVpSUQ6N85UQkwClkVyF5LK-AIjFbq3pmxeDFMqg7SS3ohKN4kETva6t2JPGF0rkVDz1geGlm2w7oEVx26iJ2%7EtH6Q0UGfaGPKjiK8x-6elNpfU8hdIgtQpn0nGCIAasCeA-H36fdqwjrgu1LYZm0Ys-Xk4M%7EQBFsE4hEep8T4W%7EY5WXLmtijZgUHzYB84WnFWEnWkw6iUOKFc2-%7Eb1PlXJ9Jaqa1socpAGMCsThuZBciVsjAjjapehlwbiJFQgJmFY%7EKtY9LafshtRzYkKx%7Eq2WVaAYILoqKSKcWra%7ElNtrQH%7EVtZ55s8PuuiAEatFBwM7ZbzBndqtc0lCrg__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n",
            "--2025-12-10 09:48:21--  https://cas-bridge.xethub.hf.co/xet-bridge-us/680a289582ee1640eea64f70/ff5bfeb1f056b26d2db78035095e5c4c72b78db5bfbaae8f329a3eb6b8b7c914?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251210%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251210T093506Z&X-Amz-Expires=3600&X-Amz-Signature=aaf9b8ce3d7bf415a39b37f144ee5412b37a98200704a1f0da592532a3df8dfe&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27s3gen.safetensors%3B+filename%3D%22s3gen.safetensors%22%3B&x-id=GetObject&Expires=1765362906&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2NTM2MjkwNn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82ODBhMjg5NTgyZWUxNjQwZWVhNjRmNzAvZmY1YmZlYjFmMDU2YjI2ZDJkYjc4MDM1MDk1ZTVjNGM3MmI3OGRiNWJmYmFhZThmMzI5YTNlYjZiOGI3YzkxNCoifV19&Signature=Yits3lVpSUQ6N85UQkwClkVyF5LK-AIjFbq3pmxeDFMqg7SS3ohKN4kETva6t2JPGF0rkVDz1geGlm2w7oEVx26iJ2%7EtH6Q0UGfaGPKjiK8x-6elNpfU8hdIgtQpn0nGCIAasCeA-H36fdqwjrgu1LYZm0Ys-Xk4M%7EQBFsE4hEep8T4W%7EY5WXLmtijZgUHzYB84WnFWEnWkw6iUOKFc2-%7Eb1PlXJ9Jaqa1socpAGMCsThuZBciVsjAjjapehlwbiJFQgJmFY%7EKtY9LafshtRzYkKx%7Eq2WVaAYILoqKSKcWra%7ElNtrQH%7EVtZ55s8PuuiAEatFBwM7ZbzBndqtc0lCrg__&Key-Pair-Id=K2L8F4GPSG1IFC\n",
            "Resolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 18.155.68.69, 18.155.68.125, 18.155.68.14, ...\n",
            "Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|18.155.68.69|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1056484620 (1008M)\n",
            "Saving to: â€˜s3gen.safetensorsâ€™\n",
            "\n",
            "s3gen.safetensors   100%[===================>]   1008M   363MB/s    in 2.8s    \n",
            "\n",
            "2025-12-10 09:48:23 (363 MB/s) - â€˜s3gen.safetensorsâ€™ saved [1056484620/1056484620]\n",
            "\n",
            "--2025-12-10 09:48:24--  https://huggingface.co/ResembleAI/chatterbox/resolve/main/conds.pt\n",
            "Resolving huggingface.co (huggingface.co)... 13.35.238.7, 13.35.238.89, 13.35.238.47, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.35.238.7|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/680a289582ee1640eea64f70/f3671d13fefc57b8361ae771bdf603d992c239855916d511f7799245810df3cc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251210%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251210T093151Z&X-Amz-Expires=3600&X-Amz-Signature=4f05cb2d1ffa10b2a14ab87fcb9ccd40c0f055ec641291ba242bcd896b0b1498&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27conds.pt%3B+filename%3D%22conds.pt%22%3B&x-id=GetObject&Expires=1765362711&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2NTM2MjcxMX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82ODBhMjg5NTgyZWUxNjQwZWVhNjRmNzAvZjM2NzFkMTNmZWZjNTdiODM2MWFlNzcxYmRmNjAzZDk5MmMyMzk4NTU5MTZkNTExZjc3OTkyNDU4MTBkZjNjYyoifV19&Signature=negFhSxNzI77KUkN69yHJJWZZqOFQ4CPWvG0HbaxLBrN-6IjV47uWhJfULqoV2IbuPdYay5i4U6hnhstxJivIC1HM9RBXkHeys3pCpkT5t8VORxg-7wo0Q15rw3GNyWyOkYrzwJNfgDebIVFtaNsiM-XyHA8YvVF4TAJhfejjnXf48BycocCql1pKbuX8qV-TBPgl7P8e3pCwQC6vrQJQo-QRp6nfb1-xHqkVOR73PZ1RY7QAwV4pJpmeQvuMbyABFNQjsHtd5qHXEh5cC2O-xMRZuhSONR0s14hh7nv12%7EbBQDmfsZNlRQDlQm8XD-yS0oywyzsIYoTbea-2BOP-Q__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n",
            "--2025-12-10 09:48:24--  https://cas-bridge.xethub.hf.co/xet-bridge-us/680a289582ee1640eea64f70/f3671d13fefc57b8361ae771bdf603d992c239855916d511f7799245810df3cc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251210%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251210T093151Z&X-Amz-Expires=3600&X-Amz-Signature=4f05cb2d1ffa10b2a14ab87fcb9ccd40c0f055ec641291ba242bcd896b0b1498&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27conds.pt%3B+filename%3D%22conds.pt%22%3B&x-id=GetObject&Expires=1765362711&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2NTM2MjcxMX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82ODBhMjg5NTgyZWUxNjQwZWVhNjRmNzAvZjM2NzFkMTNmZWZjNTdiODM2MWFlNzcxYmRmNjAzZDk5MmMyMzk4NTU5MTZkNTExZjc3OTkyNDU4MTBkZjNjYyoifV19&Signature=negFhSxNzI77KUkN69yHJJWZZqOFQ4CPWvG0HbaxLBrN-6IjV47uWhJfULqoV2IbuPdYay5i4U6hnhstxJivIC1HM9RBXkHeys3pCpkT5t8VORxg-7wo0Q15rw3GNyWyOkYrzwJNfgDebIVFtaNsiM-XyHA8YvVF4TAJhfejjnXf48BycocCql1pKbuX8qV-TBPgl7P8e3pCwQC6vrQJQo-QRp6nfb1-xHqkVOR73PZ1RY7QAwV4pJpmeQvuMbyABFNQjsHtd5qHXEh5cC2O-xMRZuhSONR0s14hh7nv12%7EbBQDmfsZNlRQDlQm8XD-yS0oywyzsIYoTbea-2BOP-Q__&Key-Pair-Id=K2L8F4GPSG1IFC\n",
            "Resolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 18.155.68.69, 18.155.68.125, 18.155.68.14, ...\n",
            "Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|18.155.68.69|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 107374 (105K)\n",
            "Saving to: â€˜conds.ptâ€™\n",
            "\n",
            "conds.pt            100%[===================>] 104.86K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2025-12-10 09:48:24 (47.3 MB/s) - â€˜conds.ptâ€™ saved [107374/107374]\n",
            "\n",
            "--2025-12-10 09:48:24--  https://huggingface.co/dolly-vn/viterbox/resolve/main/t3_ml24ls_v2.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 13.35.238.7, 13.35.238.89, 13.35.238.47, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.35.238.7|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/69325d61a8bb9e4689f25c21/a6c2ca786074b39311454f2dfdc3e493d687216224e2cf5206a3b49c4824de60?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251210%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251210T094824Z&X-Amz-Expires=3600&X-Amz-Signature=b04ae03216f1903d910769bb6ba4ecf7d262b3759dbd6ac789d9a44a28ba66b6&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27t3_ml24ls_v2.safetensors%3B+filename%3D%22t3_ml24ls_v2.safetensors%22%3B&x-id=GetObject&Expires=1765363704&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2NTM2MzcwNH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82OTMyNWQ2MWE4YmI5ZTQ2ODlmMjVjMjEvYTZjMmNhNzg2MDc0YjM5MzExNDU0ZjJkZmRjM2U0OTNkNjg3MjE2MjI0ZTJjZjUyMDZhM2I0OWM0ODI0ZGU2MCoifV19&Signature=sG-A9FQUYlnqi-XkS2NsB83VJ9zYkLxcLnyMIlPzWCbgFvVFQDA6Ov51kaZJA79gorUI1DhR-zEBVvqYhCFh9rzUTo2DwhoY-TnQA48HIw05ylnFOSZvC0vbFC8eOjlZ-e6YFWq%7EvGCOARwf0n7VmpyGEjYOvr-bHIiWYjxqUCa72h2zsVdsbSzcn-fVRDDYiUT-xcVVFM71sxnbfjbcWpJvU90F0IR18H94rUZbfJaCrZjeP4CH8J%7ETVN0Ur0YDBg6r%7EjesK2ZVGWRIEWrcqVmpmvdyQYhew0bihz2tBJu9tQtR1Rh90SEz5xENn5oWUGjkp%7EvlWPpEb17%7E-xmfww__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n",
            "--2025-12-10 09:48:24--  https://cas-bridge.xethub.hf.co/xet-bridge-us/69325d61a8bb9e4689f25c21/a6c2ca786074b39311454f2dfdc3e493d687216224e2cf5206a3b49c4824de60?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251210%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251210T094824Z&X-Amz-Expires=3600&X-Amz-Signature=b04ae03216f1903d910769bb6ba4ecf7d262b3759dbd6ac789d9a44a28ba66b6&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27t3_ml24ls_v2.safetensors%3B+filename%3D%22t3_ml24ls_v2.safetensors%22%3B&x-id=GetObject&Expires=1765363704&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2NTM2MzcwNH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82OTMyNWQ2MWE4YmI5ZTQ2ODlmMjVjMjEvYTZjMmNhNzg2MDc0YjM5MzExNDU0ZjJkZmRjM2U0OTNkNjg3MjE2MjI0ZTJjZjUyMDZhM2I0OWM0ODI0ZGU2MCoifV19&Signature=sG-A9FQUYlnqi-XkS2NsB83VJ9zYkLxcLnyMIlPzWCbgFvVFQDA6Ov51kaZJA79gorUI1DhR-zEBVvqYhCFh9rzUTo2DwhoY-TnQA48HIw05ylnFOSZvC0vbFC8eOjlZ-e6YFWq%7EvGCOARwf0n7VmpyGEjYOvr-bHIiWYjxqUCa72h2zsVdsbSzcn-fVRDDYiUT-xcVVFM71sxnbfjbcWpJvU90F0IR18H94rUZbfJaCrZjeP4CH8J%7ETVN0Ur0YDBg6r%7EjesK2ZVGWRIEWrcqVmpmvdyQYhew0bihz2tBJu9tQtR1Rh90SEz5xENn5oWUGjkp%7EvlWPpEb17%7E-xmfww__&Key-Pair-Id=K2L8F4GPSG1IFC\n",
            "Resolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 18.155.68.69, 18.155.68.125, 18.155.68.14, ...\n",
            "Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|18.155.68.69|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2144767992 (2.0G)\n",
            "Saving to: â€˜t3_cfg.safetensorsâ€™\n",
            "\n",
            "t3_cfg.safetensors  100%[===================>]   2.00G   278MB/s    in 6.4s    \n",
            "\n",
            "2025-12-10 09:48:31 (318 MB/s) - â€˜t3_cfg.safetensorsâ€™ saved [2144767992/2144767992]\n",
            "\n",
            "--2025-12-10 09:48:31--  https://huggingface.co/dolly-vn/viterbox/resolve/main/tokenizer_vi_expanded.json\n",
            "Resolving huggingface.co (huggingface.co)... 13.35.238.7, 13.35.238.89, 13.35.238.47, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.35.238.7|:443... connected.\n",
            "HTTP request sent, awaiting response... 307 Temporary Redirect\n",
            "Location: /api/resolve-cache/models/dolly-vn/viterbox/2a5f635f782ec548b47c158e2ee3d140b317a531/tokenizer_vi_expanded.json?%2Fdolly-vn%2Fviterbox%2Fresolve%2Fmain%2Ftokenizer_vi_expanded.json=&etag=%2293eb1e052c91babab7503be36eb677a6ef64151d%22 [following]\n",
            "--2025-12-10 09:48:31--  https://huggingface.co/api/resolve-cache/models/dolly-vn/viterbox/2a5f635f782ec548b47c158e2ee3d140b317a531/tokenizer_vi_expanded.json?%2Fdolly-vn%2Fviterbox%2Fresolve%2Fmain%2Ftokenizer_vi_expanded.json=&etag=%2293eb1e052c91babab7503be36eb677a6ef64151d%22\n",
            "Reusing existing connection to huggingface.co:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75701 (74K) [text/plain]\n",
            "Saving to: â€˜tokenizer.jsonâ€™\n",
            "\n",
            "tokenizer.json      100%[===================>]  73.93K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2025-12-10 09:48:31 (38.2 MB/s) - â€˜tokenizer.jsonâ€™ saved [75701/75701]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.makedirs(\"/content/chatterbox-lora/audio_data\", exist_ok=True)\n",
        "%cd /content/chatterbox-lora/audio_data\n",
        "!cp /content/drive/MyDrive/Thien/splitthienfinal/dataset-BEDTIME_STORY_Truyen_co_tich_Grimm_3Di_VTuber_Pro_56efaeab/wavs/*.wav /content/chatterbox-lora/audio_data 2>/dev/null"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uYLeukMf8X8",
        "outputId": "62f75ef0-33b6-43d9-8fdb-6f6b4cff7f84"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/chatterbox-lora/audio_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# ================= Cáº¤U HÃŒNH =================\n",
        "# ÄÆ°á»ng dáº«n Ä‘áº¿n file metadata trÃªn Drive cá»§a báº¡n\n",
        "csv_path = \"/content/drive/MyDrive/Thien/splitthienfinal/dataset-BEDTIME_STORY_Truyen_co_tich_Grimm_3Di_VTuber_Pro_56efaeab/metadata.csv\"\n",
        "\n",
        "# ÄÆ°á»ng dáº«n Ä‘áº¿n thÆ° má»¥c audio_data trong code Chatterbox\n",
        "# (LÆ°u Ã½: Náº¿u tÃªn thÆ° má»¥c code cá»§a báº¡n khÃ¡c, hÃ£y sá»­a láº¡i pháº§n 'chatterbox-streaming')\n",
        "output_dir = \"/content/chatterbox-lora/audio_data\"\n",
        "output_json_path = os.path.join(output_dir, \"transcripts_cache.json\")\n",
        "\n",
        "# ================= Xá»¬ LÃ =================\n",
        "print(f\"Äang Ä‘á»c file CSV tá»«: {csv_path}\")\n",
        "\n",
        "data_cache = {}\n",
        "\n",
        "try:\n",
        "    # Äáº£m báº£o thÆ° má»¥c Ä‘Ã­ch tá»“n táº¡i\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    with open(csv_path, 'r', encoding='utf-8') as f:\n",
        "        # Äá»c file CSV vá»›i dáº¥u phÃ¢n cÃ¡ch lÃ  '|'\n",
        "        reader = csv.reader(f, delimiter='|')\n",
        "\n",
        "        # Bá» qua dÃ²ng tiÃªu Ä‘á» náº¿u file cÃ³ tiÃªu Ä‘á» (audio_file|text|speaker_name)\n",
        "        # Náº¿u file cá»§a báº¡n dÃ²ng Ä‘áº§u tiÃªn lÃ  dá»¯ liá»‡u luÃ´n thÃ¬ comment dÃ²ng bÃªn dÆ°á»›i láº¡i\n",
        "        # next(reader, None)\n",
        "\n",
        "        count = 0\n",
        "        for row in reader:\n",
        "            if len(row) < 2:\n",
        "                continue # Bá» qua dÃ²ng lá»—i\n",
        "\n",
        "            # Cáº¥u trÃºc row: [0]=wavs/chunk_000.wav, [1]=text, [2]=speaker\n",
        "            full_path = row[0].strip()\n",
        "            transcript = row[1].strip()\n",
        "\n",
        "            # Xá»­ lÃ½ tÃªn file: \"wavs/chunk_0000.wav\" -> \"chunk_0000.wav\"\n",
        "            # VÃ¬ báº¡n copy tháº³ng file wav vÃ o audio_data nÃªn pháº£i cáº¯t bá» folder máº¹\n",
        "            filename = os.path.basename(full_path)\n",
        "\n",
        "            # Táº¡o entry cho JSON\n",
        "            # LÆ°u Ã½: Code lora.py sáº½ tá»± tÃ­nh láº¡i duration/sample_rate khi load file\n",
        "            # nÃªn á»Ÿ Ä‘Ã¢y ta Ä‘á»ƒ giÃ¡ trá»‹ máº·c Ä‘á»‹nh Ä‘á»ƒ khÃ´ng bá»‹ lá»—i format.\n",
        "            data_cache[filename] = {\n",
        "                \"transcript\": transcript,\n",
        "                \"duration\": 5.0,      # GiÃ¡ trá»‹ giáº£ Ä‘á»‹nh (code sáº½ tá»± update)\n",
        "                \"sample_rate\": 22050  # GiÃ¡ trá»‹ giáº£ Ä‘á»‹nh\n",
        "            }\n",
        "            count += 1\n",
        "\n",
        "    # LÆ°u ra file JSON\n",
        "    print(f\"Äang lÆ°u {count} dÃ²ng dá»¯ liá»‡u vÃ o JSON...\")\n",
        "    with open(output_json_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(data_cache, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(\"âœ… Xong! ÄÃ£ táº¡o file transcripts_cache.json thÃ nh cÃ´ng.\")\n",
        "    print(f\"ÄÆ°á»ng dáº«n file: {output_json_path}\")\n",
        "    print(\"BÃ¢y giá» báº¡n cÃ³ thá»ƒ cháº¡y file lora.py, nÃ³ sáº½ tá»± nháº­n diá»‡n text nÃ y vÃ  khÃ´ng cháº¡y Whisper.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"âŒ Lá»—i: KhÃ´ng tÃ¬m tháº¥y file metadata.csv. Kiá»ƒm tra láº¡i Ä‘Æ°á»ng dáº«n Drive.\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7y6xNYoiIzs",
        "outputId": "0c226819-7f67-4046-8a60-a18b1ce23f75"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Äang Ä‘á»c file CSV tá»«: /content/drive/MyDrive/Thien/splitthienfinal/dataset-BEDTIME_STORY_Truyen_co_tich_Grimm_3Di_VTuber_Pro_56efaeab/metadata.csv\n",
            "Äang lÆ°u 594 dÃ²ng dá»¯ liá»‡u vÃ o JSON...\n",
            "âœ… Xong! ÄÃ£ táº¡o file transcripts_cache.json thÃ nh cÃ´ng.\n",
            "ÄÆ°á»ng dáº«n file: /content/chatterbox-lora/audio_data/transcripts_cache.json\n",
            "BÃ¢y giá» báº¡n cÃ³ thá»ƒ cháº¡y file lora.py, nÃ³ sáº½ tá»± nháº­n diá»‡n text nÃ y vÃ  khÃ´ng cháº¡y Whisper.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from safetensors.torch import load_file\n",
        "import os\n",
        "\n",
        "# ÄÆ°á»ng dáº«n Ä‘áº¿n thÆ° má»¥c chá»©a model cá»§a báº¡n\n",
        "model_dir = \"/content/chatterbox-lora/viterbox\"\n",
        "\n",
        "# Danh sÃ¡ch cÃ¡c file cáº§n convert (thÆ°á»ng model cÃ³ 3 pháº§n nÃ y)\n",
        "components = [\"t3_cfg\", \"ve\", \"s3gen\"]\n",
        "\n",
        "print(f\"Báº¯t Ä‘áº§u convert Safetensors sang PT trong thÆ° má»¥c: {model_dir}\")\n",
        "\n",
        "for name in components:\n",
        "    # 1. XÃ¡c Ä‘á»‹nh Ä‘Æ°á»ng dáº«n file\n",
        "    safetensors_path = os.path.join(model_dir, f\"{name}.safetensors\")\n",
        "    pt_path = os.path.join(model_dir, f\"{name}.pt\")\n",
        "\n",
        "    # 2. Xá»­ lÃ½ file báº¡n Ä‘Ã£ lá»¡ Ä‘á»•i tÃªn (náº¿u báº¡n rename t3_cfg.safetensors -> t3_cfg.pt mÃ  ruá»™t váº«n lÃ  safetensors)\n",
        "    # Code nÃ y sáº½ thá»­ Ä‘á»c file .pt hiá»‡n táº¡i báº±ng safetensors, náº¿u Ä‘á»c Ä‘Æ°á»£c tá»©c lÃ  file \"giáº£ cáº§y\"\n",
        "    if os.path.exists(pt_path) and not os.path.exists(safetensors_path):\n",
        "        try:\n",
        "            print(f\"Kiá»ƒm tra file {name}.pt xem cÃ³ pháº£i lÃ  safetensors Ä‘á»•i tÃªn khÃ´ng...\")\n",
        "            weights = load_file(pt_path)\n",
        "            print(f\"-> PhÃ¡t hiá»‡n {name}.pt thá»±c cháº¥t lÃ  safetensors. Äang ghi Ä‘Ã¨ láº¡i chuáº©n .pt...\")\n",
        "            torch.save(weights, pt_path)\n",
        "            print(f\"-> ÄÃ£ sá»­a xong {name}.pt!\")\n",
        "            continue\n",
        "        except Exception:\n",
        "            print(f\"-> File {name}.pt cÃ³ váº» khÃ´ng pháº£i safetensors hoáº·c Ä‘Ã£ chuáº©n rá»“i.\")\n",
        "\n",
        "    # 3. Xá»­ lÃ½ trÆ°á»ng há»£p file .safetensors gá»‘c cÃ²n Ä‘Ã³\n",
        "    if os.path.exists(safetensors_path):\n",
        "        print(f\"Äang convert {name}.safetensors sang .pt ...\")\n",
        "        weights = load_file(safetensors_path)\n",
        "        torch.save(weights, pt_path)\n",
        "        print(f\"-> ÄÃ£ lÆ°u: {pt_path}\")\n",
        "    else:\n",
        "        print(f\"Bá» qua {name} (khÃ´ng tÃ¬m tháº¥y file nguá»“n)\")\n",
        "\n",
        "print(\"\\nHoÃ n táº¥t! BÃ¢y giá» báº¡n cÃ³ thá»ƒ cháº¡y láº¡i file lora.py\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7FkcpTIlRd2",
        "outputId": "4ba7eb93-2902-4597-e035-45ee5fc683c1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Báº¯t Ä‘áº§u convert Safetensors sang PT trong thÆ° má»¥c: /content/chatterbox-lora/viterbox\n",
            "Äang convert t3_cfg.safetensors sang .pt ...\n",
            "-> ÄÃ£ lÆ°u: /content/chatterbox-lora/viterbox/t3_cfg.pt\n",
            "Kiá»ƒm tra file ve.pt xem cÃ³ pháº£i lÃ  safetensors Ä‘á»•i tÃªn khÃ´ng...\n",
            "-> File ve.pt cÃ³ váº» khÃ´ng pháº£i safetensors hoáº·c Ä‘Ã£ chuáº©n rá»“i.\n",
            "Bá» qua ve (khÃ´ng tÃ¬m tháº¥y file nguá»“n)\n",
            "Äang convert s3gen.safetensors sang .pt ...\n",
            "-> ÄÃ£ lÆ°u: /content/chatterbox-lora/viterbox/s3gen.pt\n",
            "\n",
            "HoÃ n táº¥t! BÃ¢y giá» báº¡n cÃ³ thá»ƒ cháº¡y láº¡i file lora.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/chatterbox-lora\n",
        "!python lora_batch.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "474XA8Lliswx",
        "outputId": "f690be0f-fefa-44ea-dc83-5c057e2f9db9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.982908\n",
            "Epoch 2/5:  16% 44/267 [00:56<05:06,  1.37s/it, loss=0.8000, lr=0.000020]Text tokens shape: torch.Size([2, 100])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 883, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 883, 1024])\n",
            "Speech logits slice: [134:883]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.121466\n",
            "Epoch 2/5:  17% 45/267 [00:57<04:39,  1.26s/it, loss=0.8000, lr=0.000020]Text tokens shape: torch.Size([2, 84])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 867, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 867, 1024])\n",
            "Speech logits slice: [118:867]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.725725\n",
            "Epoch 2/5:  17% 46/267 [00:59<05:12,  1.41s/it, loss=0.8000, lr=0.000020]Text tokens shape: torch.Size([2, 86])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 869, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 869, 1024])\n",
            "Speech logits slice: [120:869]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.562318\n",
            "Epoch 2/5:  18% 47/267 [01:00<04:42,  1.28s/it, loss=0.8000, lr=0.000020]Text tokens shape: torch.Size([2, 143])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 926, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 926, 1024])\n",
            "Speech logits slice: [177:926]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.929288\n",
            "Epoch 2/5:  18% 48/267 [01:01<04:29,  1.23s/it, loss=0.8108, lr=0.000020]Text tokens shape: torch.Size([2, 69])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 852, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 852, 1024])\n",
            "Speech logits slice: [103:852]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.625919\n",
            "Epoch 2/5:  18% 49/267 [01:02<04:08,  1.14s/it, loss=0.8108, lr=0.000020]Text tokens shape: torch.Size([2, 95])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 878, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 878, 1024])\n",
            "Speech logits slice: [129:878]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.755376\n",
            "Epoch 2/5:  19% 50/267 [01:03<03:56,  1.09s/it, loss=0.8108, lr=0.000020]Text tokens shape: torch.Size([2, 53])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 836, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 836, 1024])\n",
            "Speech logits slice: [87:836]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.547256\n",
            "Epoch 2/5:  19% 51/267 [01:05<04:45,  1.32s/it, loss=0.8108, lr=0.000020]Text tokens shape: torch.Size([2, 66])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 849, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 849, 1024])\n",
            "Speech logits slice: [100:849]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.577662\n",
            "Epoch 2/5:  19% 52/267 [01:06<04:24,  1.23s/it, loss=0.7928, lr=0.000020]Text tokens shape: torch.Size([2, 119])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 902, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 902, 1024])\n",
            "Speech logits slice: [153:902]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.891065\n",
            "Epoch 2/5:  20% 53/267 [01:08<04:44,  1.33s/it, loss=0.7928, lr=0.000020]Text tokens shape: torch.Size([2, 244])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 1027, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 1027, 1024])\n",
            "Speech logits slice: [278:1027]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.300346\n",
            "Epoch 2/5:  20% 54/267 [01:09<04:39,  1.31s/it, loss=0.7928, lr=0.000020]Text tokens shape: torch.Size([2, 100])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 883, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 883, 1024])\n",
            "Speech logits slice: [134:883]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.819311\n",
            "Epoch 2/5:  21% 55/267 [01:10<04:16,  1.21s/it, loss=0.7928, lr=0.000020]Text tokens shape: torch.Size([2, 241])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 1024, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 1024, 1024])\n",
            "Speech logits slice: [275:1024]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.276064\n",
            "Epoch 2/5:  21% 56/267 [01:11<04:16,  1.21s/it, loss=0.8274, lr=0.000020]Text tokens shape: torch.Size([2, 65])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 848, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 848, 1024])\n",
            "Speech logits slice: [99:848]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.623107\n",
            "Epoch 2/5:  21% 57/267 [01:12<04:01,  1.15s/it, loss=0.8274, lr=0.000020]Text tokens shape: torch.Size([2, 86])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 869, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 869, 1024])\n",
            "Speech logits slice: [120:869]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.959448\n",
            "Epoch 2/5:  22% 58/267 [01:14<04:53,  1.40s/it, loss=0.8274, lr=0.000020]Text tokens shape: torch.Size([2, 101])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 884, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 884, 1024])\n",
            "Speech logits slice: [135:884]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.706006\n",
            "Epoch 2/5:  22% 59/267 [01:15<04:24,  1.27s/it, loss=0.8274, lr=0.000020]Text tokens shape: torch.Size([2, 65])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 848, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 848, 1024])\n",
            "Speech logits slice: [99:848]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.500967\n",
            "Epoch 2/5:  22% 60/267 [01:16<04:07,  1.20s/it, loss=0.8056, lr=0.000020]Text tokens shape: torch.Size([2, 109])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 892, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 892, 1024])\n",
            "Speech logits slice: [143:892]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.730148\n",
            "Epoch 2/5:  23% 61/267 [01:17<03:52,  1.13s/it, loss=0.8056, lr=0.000020]Text tokens shape: torch.Size([2, 78])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 861, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 861, 1024])\n",
            "Speech logits slice: [112:861]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.652194\n",
            "Epoch 2/5:  23% 62/267 [01:19<04:19,  1.27s/it, loss=0.8056, lr=0.000020]Text tokens shape: torch.Size([2, 82])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 865, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 865, 1024])\n",
            "Speech logits slice: [116:865]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.636701\n",
            "Epoch 2/5:  24% 63/267 [01:20<04:32,  1.34s/it, loss=0.8056, lr=0.000020]Text tokens shape: torch.Size([2, 99])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 882, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 882, 1024])\n",
            "Speech logits slice: [133:882]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.759096\n",
            "Epoch 2/5:  24% 64/267 [01:21<04:16,  1.26s/it, loss=0.8027, lr=0.000020]Text tokens shape: torch.Size([2, 96])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 879, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 879, 1024])\n",
            "Speech logits slice: [130:879]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.946379\n",
            "Epoch 2/5:  24% 65/267 [01:23<04:35,  1.37s/it, loss=0.8027, lr=0.000020]Text tokens shape: torch.Size([2, 111])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 894, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 894, 1024])\n",
            "Speech logits slice: [145:894]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.905859\n",
            "Epoch 2/5:  25% 66/267 [01:24<04:12,  1.25s/it, loss=0.8027, lr=0.000020]Text tokens shape: torch.Size([2, 87])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 870, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 870, 1024])\n",
            "Speech logits slice: [121:870]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.666848\n",
            "Epoch 2/5:  25% 67/267 [01:25<03:55,  1.18s/it, loss=0.8027, lr=0.000020]Text tokens shape: torch.Size([2, 82])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 865, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 865, 1024])\n",
            "Speech logits slice: [116:865]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.574763\n",
            "Epoch 2/5:  25% 68/267 [01:27<04:39,  1.40s/it, loss=0.7893, lr=0.000020]Text tokens shape: torch.Size([2, 91])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 874, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 874, 1024])\n",
            "Speech logits slice: [125:874]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.744045\n",
            "Epoch 2/5:  26% 69/267 [01:28<04:10,  1.27s/it, loss=0.7893, lr=0.000020]Text tokens shape: torch.Size([2, 49])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 832, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 832, 1024])\n",
            "Speech logits slice: [83:832]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.464164\n",
            "Epoch 2/5:  26% 70/267 [01:29<04:10,  1.27s/it, loss=0.7893, lr=0.000020]Text tokens shape: torch.Size([2, 62])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 845, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 845, 1024])\n",
            "Speech logits slice: [96:845]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.621830\n",
            "Epoch 2/5:  27% 71/267 [01:30<04:28,  1.37s/it, loss=0.7893, lr=0.000020]Text tokens shape: torch.Size([2, 59])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 842, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 842, 1024])\n",
            "Speech logits slice: [93:842]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.527958\n",
            "Epoch 2/5:  27% 72/267 [01:31<04:06,  1.26s/it, loss=0.7748, lr=0.000020]Text tokens shape: torch.Size([2, 109])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 892, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 892, 1024])\n",
            "Speech logits slice: [143:892]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.980928\n",
            "Epoch 2/5:  27% 73/267 [01:33<04:17,  1.33s/it, loss=0.7748, lr=0.000020]Text tokens shape: torch.Size([2, 67])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 850, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 850, 1024])\n",
            "Speech logits slice: [101:850]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.568412\n",
            "Epoch 2/5:  28% 74/267 [01:34<04:00,  1.25s/it, loss=0.7748, lr=0.000020]Text tokens shape: torch.Size([2, 103])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 886, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 886, 1024])\n",
            "Speech logits slice: [137:886]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.852721\n",
            "Epoch 2/5:  28% 75/267 [01:35<03:43,  1.17s/it, loss=0.7748, lr=0.000020]Text tokens shape: torch.Size([2, 169])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 952, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 952, 1024])\n",
            "Speech logits slice: [203:952]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.294151\n",
            "Epoch 2/5:  28% 76/267 [01:37<04:16,  1.34s/it, loss=0.8021, lr=0.000020]Text tokens shape: torch.Size([2, 68])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 851, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 851, 1024])\n",
            "Speech logits slice: [102:851]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.729993\n",
            "Epoch 2/5:  29% 77/267 [01:38<03:53,  1.23s/it, loss=0.8021, lr=0.000020]Text tokens shape: torch.Size([2, 95])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 878, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 878, 1024])\n",
            "Speech logits slice: [129:878]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.704325\n",
            "Epoch 2/5:  29% 78/267 [01:39<03:37,  1.15s/it, loss=0.8021, lr=0.000020]Text tokens shape: torch.Size([2, 118])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 901, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 901, 1024])\n",
            "Speech logits slice: [152:901]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.067194\n",
            "Epoch 2/5:  30% 79/267 [01:41<04:19,  1.38s/it, loss=0.8021, lr=0.000020]Text tokens shape: torch.Size([2, 67])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 850, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 850, 1024])\n",
            "Speech logits slice: [101:850]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.542967\n",
            "Epoch 2/5:  30% 80/267 [01:42<03:57,  1.27s/it, loss=0.7891, lr=0.000020]Text tokens shape: torch.Size([2, 63])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 846, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 846, 1024])\n",
            "Speech logits slice: [97:846]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.529334\n",
            "Epoch 2/5:  30% 81/267 [01:43<04:09,  1.34s/it, loss=0.7891, lr=0.000020]Text tokens shape: torch.Size([2, 53])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 836, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 836, 1024])\n",
            "Speech logits slice: [87:836]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.468803\n",
            "Epoch 2/5:  31% 82/267 [01:44<03:52,  1.26s/it, loss=0.7891, lr=0.000020]Text tokens shape: torch.Size([2, 62])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 845, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 845, 1024])\n",
            "Speech logits slice: [96:845]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.567009\n",
            "Epoch 2/5:  31% 83/267 [01:45<03:34,  1.17s/it, loss=0.7891, lr=0.000020]Text tokens shape: torch.Size([2, 227])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 1010, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 1010, 1024])\n",
            "Speech logits slice: [261:1010]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.450186\n",
            "Epoch 2/5:  31% 84/267 [01:46<03:34,  1.17s/it, loss=0.8206, lr=0.000020]Text tokens shape: torch.Size([2, 58])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 841, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 841, 1024])\n",
            "Speech logits slice: [92:841]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.639408\n",
            "Epoch 2/5:  32% 85/267 [01:47<03:20,  1.10s/it, loss=0.8206, lr=0.000020]Text tokens shape: torch.Size([2, 118])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 901, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 901, 1024])\n",
            "Speech logits slice: [152:901]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.940587\n",
            "Epoch 2/5:  32% 86/267 [01:49<04:05,  1.35s/it, loss=0.8206, lr=0.000020]Text tokens shape: torch.Size([2, 77])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 860, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 860, 1024])\n",
            "Speech logits slice: [111:860]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.594853\n",
            "Epoch 2/5:  33% 87/267 [01:50<03:44,  1.24s/it, loss=0.8206, lr=0.000020]Text tokens shape: torch.Size([2, 155])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 938, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 938, 1024])\n",
            "Speech logits slice: [189:938]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.002414\n",
            "Epoch 2/5:  33% 88/267 [01:51<03:40,  1.23s/it, loss=0.8289, lr=0.000020]Text tokens shape: torch.Size([2, 191])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 974, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 974, 1024])\n",
            "Speech logits slice: [225:974]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.070329\n",
            "Epoch 2/5:  33% 89/267 [01:52<03:31,  1.19s/it, loss=0.8289, lr=0.000020]Text tokens shape: torch.Size([2, 46])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 829, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 829, 1024])\n",
            "Speech logits slice: [80:829]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.501231\n",
            "Epoch 2/5:  34% 90/267 [01:54<03:25,  1.16s/it, loss=0.8289, lr=0.000020]Text tokens shape: torch.Size([2, 186])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 969, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 969, 1024])\n",
            "Speech logits slice: [220:969]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.417092\n",
            "Epoch 2/5:  34% 91/267 [01:55<03:59,  1.36s/it, loss=0.8289, lr=0.000020]Text tokens shape: torch.Size([2, 71])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 854, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 854, 1024])\n",
            "Speech logits slice: [105:854]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.563486\n",
            "Epoch 2/5:  34% 92/267 [01:56<03:41,  1.26s/it, loss=0.8173, lr=0.000020]Text tokens shape: torch.Size([2, 49])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 832, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 832, 1024])\n",
            "Speech logits slice: [83:832]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.466032\n",
            "Epoch 2/5:  35% 93/267 [01:58<03:46,  1.30s/it, loss=0.8173, lr=0.000020]Text tokens shape: torch.Size([2, 62])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 845, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 845, 1024])\n",
            "Speech logits slice: [96:845]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.509006\n",
            "Epoch 2/5:  35% 94/267 [01:59<03:32,  1.23s/it, loss=0.8173, lr=0.000020]Text tokens shape: torch.Size([2, 76])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 859, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 859, 1024])\n",
            "Speech logits slice: [110:859]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.570778\n",
            "Epoch 2/5:  36% 95/267 [02:00<03:16,  1.14s/it, loss=0.8173, lr=0.000020]Text tokens shape: torch.Size([2, 70])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 853, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 853, 1024])\n",
            "Speech logits slice: [104:853]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.720036\n",
            "Epoch 2/5:  36% 96/267 [02:02<03:49,  1.34s/it, loss=0.8133, lr=0.000020]Text tokens shape: torch.Size([2, 70])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 853, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 853, 1024])\n",
            "Speech logits slice: [104:853]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.580239\n",
            "Epoch 2/5:  36% 97/267 [02:03<03:28,  1.23s/it, loss=0.8133, lr=0.000020]Text tokens shape: torch.Size([2, 87])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 870, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 870, 1024])\n",
            "Speech logits slice: [121:870]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.570791\n",
            "Epoch 2/5:  37% 98/267 [02:04<03:13,  1.14s/it, loss=0.8133, lr=0.000020]Text tokens shape: torch.Size([2, 116])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 899, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 899, 1024])\n",
            "Speech logits slice: [150:899]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.963499\n",
            "Epoch 2/5:  37% 99/267 [02:06<03:53,  1.39s/it, loss=0.8133, lr=0.000020]Text tokens shape: torch.Size([2, 99])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 882, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 882, 1024])\n",
            "Speech logits slice: [133:882]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.900946\n",
            "Epoch 2/5:  37% 100/267 [02:07<03:34,  1.29s/it, loss=0.8168, lr=0.000020]Text tokens shape: torch.Size([2, 58])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 841, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 841, 1024])\n",
            "Speech logits slice: [92:841]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.699791\n",
            "Epoch 2/5:  38% 101/267 [02:08<03:35,  1.30s/it, loss=0.8168, lr=0.000020]Text tokens shape: torch.Size([2, 110])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 893, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 893, 1024])\n",
            "Speech logits slice: [144:893]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.013842\n",
            "Epoch 2/5:  38% 102/267 [02:09<03:37,  1.32s/it, loss=0.8168, lr=0.000020]Text tokens shape: torch.Size([2, 70])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 853, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 853, 1024])\n",
            "Speech logits slice: [104:853]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.787777\n",
            "Epoch 2/5:  39% 103/267 [02:10<03:17,  1.20s/it, loss=0.8168, lr=0.000020]Text tokens shape: torch.Size([2, 54])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 837, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 837, 1024])\n",
            "Speech logits slice: [88:837]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.594545\n",
            "Epoch 2/5:  39% 104/267 [02:11<03:07,  1.15s/it, loss=0.8083, lr=0.000020]Text tokens shape: torch.Size([2, 59])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 842, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 842, 1024])\n",
            "Speech logits slice: [93:842]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.459341\n",
            "Epoch 2/5:  39% 105/267 [02:12<02:55,  1.08s/it, loss=0.8083, lr=0.000020]Text tokens shape: torch.Size([2, 37])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 820, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 820, 1024])\n",
            "Speech logits slice: [71:820]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.436140\n",
            "Epoch 2/5:  40% 106/267 [02:13<03:06,  1.16s/it, loss=0.8083, lr=0.000020]Text tokens shape: torch.Size([2, 87])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 870, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 870, 1024])\n",
            "Speech logits slice: [121:870]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.807525\n",
            "Epoch 2/5:  40% 107/267 [02:15<03:10,  1.19s/it, loss=0.8083, lr=0.000020]Text tokens shape: torch.Size([2, 65])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 848, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 848, 1024])\n",
            "Speech logits slice: [99:848]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.667758\n",
            "Epoch 2/5:  40% 108/267 [02:16<03:01,  1.14s/it, loss=0.8030, lr=0.000020]Text tokens shape: torch.Size([2, 101])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 884, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 884, 1024])\n",
            "Speech logits slice: [135:884]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.677986\n",
            "Epoch 2/5:  41% 109/267 [02:17<03:15,  1.23s/it, loss=0.8030, lr=0.000020]Text tokens shape: torch.Size([2, 124])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 907, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 907, 1024])\n",
            "Speech logits slice: [158:907]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.886685\n",
            "Epoch 2/5:  41% 110/267 [02:18<03:04,  1.17s/it, loss=0.8030, lr=0.000020]Text tokens shape: torch.Size([2, 118])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 901, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 901, 1024])\n",
            "Speech logits slice: [152:901]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.959411\n",
            "Epoch 2/5:  42% 111/267 [02:19<02:56,  1.13s/it, loss=0.8030, lr=0.000020]Text tokens shape: torch.Size([2, 76])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 859, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 859, 1024])\n",
            "Speech logits slice: [110:859]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.769150\n",
            "Epoch 2/5:  42% 112/267 [02:21<03:40,  1.42s/it, loss=0.8018, lr=0.000020]Text tokens shape: torch.Size([2, 72])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 855, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 855, 1024])\n",
            "Speech logits slice: [106:855]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.706270\n",
            "Epoch 2/5:  42% 113/267 [02:22<03:16,  1.28s/it, loss=0.8018, lr=0.000020]Text tokens shape: torch.Size([2, 116])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 899, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 899, 1024])\n",
            "Speech logits slice: [150:899]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.806201\n",
            "Epoch 2/5:  43% 114/267 [02:23<03:05,  1.21s/it, loss=0.8018, lr=0.000020]Text tokens shape: torch.Size([2, 205])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 988, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 988, 1024])\n",
            "Speech logits slice: [239:988]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.563800\n",
            "Epoch 2/5:  43% 115/267 [02:25<03:35,  1.41s/it, loss=0.8018, lr=0.000020]Text tokens shape: torch.Size([2, 82])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 865, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 865, 1024])\n",
            "Speech logits slice: [116:865]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.585661\n",
            "Epoch 2/5:  43% 116/267 [02:26<03:16,  1.30s/it, loss=0.7944, lr=0.000020]Text tokens shape: torch.Size([2, 56])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 839, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 839, 1024])\n",
            "Speech logits slice: [90:839]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.444452\n",
            "Epoch 2/5:  44% 117/267 [02:28<03:22,  1.35s/it, loss=0.7944, lr=0.000020]Text tokens shape: torch.Size([2, 100])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 883, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 883, 1024])\n",
            "Speech logits slice: [134:883]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.616924\n",
            "Epoch 2/5:  44% 118/267 [02:29<03:12,  1.29s/it, loss=0.7944, lr=0.000020]Text tokens shape: torch.Size([2, 116])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 899, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 899, 1024])\n",
            "Speech logits slice: [150:899]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.941500\n",
            "Epoch 2/5:  45% 119/267 [02:30<02:57,  1.20s/it, loss=0.7944, lr=0.000020]Text tokens shape: torch.Size([2, 170])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 953, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 953, 1024])\n",
            "Speech logits slice: [204:953]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.135342\n",
            "Epoch 2/5:  45% 120/267 [02:31<02:53,  1.18s/it, loss=0.8057, lr=0.000020]Text tokens shape: torch.Size([2, 85])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 868, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 868, 1024])\n",
            "Speech logits slice: [119:868]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.604219\n",
            "Epoch 2/5:  45% 121/267 [02:32<02:42,  1.11s/it, loss=0.8057, lr=0.000020]Text tokens shape: torch.Size([2, 63])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 846, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 846, 1024])\n",
            "Speech logits slice: [97:846]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.587007\n",
            "Epoch 2/5:  46% 122/267 [02:34<03:04,  1.27s/it, loss=0.8057, lr=0.000020]Text tokens shape: torch.Size([2, 76])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 859, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 859, 1024])\n",
            "Speech logits slice: [110:859]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.744585\n",
            "Epoch 2/5:  46% 123/267 [02:35<02:49,  1.18s/it, loss=0.8057, lr=0.000020]Text tokens shape: torch.Size([2, 136])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 919, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 919, 1024])\n",
            "Speech logits slice: [170:919]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.955911\n",
            "Epoch 2/5:  46% 124/267 [02:36<02:45,  1.16s/it, loss=0.8106, lr=0.000020]Text tokens shape: torch.Size([2, 98])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 881, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 881, 1024])\n",
            "Speech logits slice: [132:881]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.802239\n",
            "Epoch 2/5:  47% 125/267 [02:37<02:35,  1.10s/it, loss=0.8106, lr=0.000020]Text tokens shape: torch.Size([2, 72])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 855, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 855, 1024])\n",
            "Speech logits slice: [106:855]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.603729\n",
            "Epoch 2/5:  47% 126/267 [02:38<02:28,  1.05s/it, loss=0.8106, lr=0.000020]Text tokens shape: torch.Size([2, 101])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 884, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 884, 1024])\n",
            "Speech logits slice: [135:884]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.854394\n",
            "Epoch 2/5:  48% 127/267 [02:40<03:03,  1.31s/it, loss=0.8106, lr=0.000020]Text tokens shape: torch.Size([2, 112])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 895, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 895, 1024])\n",
            "Speech logits slice: [146:895]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.847431\n",
            "Epoch 2/5:  48% 128/267 [02:41<02:52,  1.24s/it, loss=0.8117, lr=0.000020]Text tokens shape: torch.Size([2, 78])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 861, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 861, 1024])\n",
            "Speech logits slice: [112:861]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.662458\n",
            "Epoch 2/5:  48% 129/267 [02:42<03:02,  1.32s/it, loss=0.8117, lr=0.000020]Text tokens shape: torch.Size([2, 61])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 844, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 844, 1024])\n",
            "Speech logits slice: [95:844]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.680618\n",
            "Epoch 2/5:  49% 130/267 [02:43<02:51,  1.25s/it, loss=0.8117, lr=0.000020]Text tokens shape: torch.Size([2, 60])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 843, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 843, 1024])\n",
            "Speech logits slice: [94:843]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.576030\n",
            "Epoch 2/5:  49% 131/267 [02:44<02:37,  1.16s/it, loss=0.8117, lr=0.000020]Text tokens shape: torch.Size([2, 238])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 1021, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 1021, 1024])\n",
            "Speech logits slice: [272:1021]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.357978\n",
            "Epoch 2/5:  49% 132/267 [02:45<02:37,  1.17s/it, loss=0.8283, lr=0.000020]Text tokens shape: torch.Size([2, 141])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 924, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 924, 1024])\n",
            "Speech logits slice: [175:924]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.202727\n",
            "Epoch 2/5:  50% 133/267 [02:46<02:29,  1.12s/it, loss=0.8283, lr=0.000020]Text tokens shape: torch.Size([2, 79])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 862, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 862, 1024])\n",
            "Speech logits slice: [113:862]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.825484\n",
            "Epoch 2/5:  50% 134/267 [02:48<02:50,  1.28s/it, loss=0.8283, lr=0.000020]Text tokens shape: torch.Size([2, 67])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 850, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 850, 1024])\n",
            "Speech logits slice: [101:850]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.705806\n",
            "Epoch 2/5:  51% 135/267 [02:49<02:35,  1.18s/it, loss=0.8283, lr=0.000020]Text tokens shape: torch.Size([2, 72])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 855, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 855, 1024])\n",
            "Speech logits slice: [106:855]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.592424\n",
            "Epoch 2/5:  51% 136/267 [02:50<02:28,  1.13s/it, loss=0.8214, lr=0.000020]Text tokens shape: torch.Size([2, 207])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 990, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 990, 1024])\n",
            "Speech logits slice: [241:990]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.506095\n",
            "Epoch 2/5:  51% 137/267 [02:52<03:01,  1.40s/it, loss=0.8214, lr=0.000020]Text tokens shape: torch.Size([2, 62])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 845, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 845, 1024])\n",
            "Speech logits slice: [96:845]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.605589\n",
            "Epoch 2/5:  52% 138/267 [02:53<02:43,  1.27s/it, loss=0.8214, lr=0.000020]Text tokens shape: torch.Size([2, 77])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 860, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 860, 1024])\n",
            "Speech logits slice: [111:860]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.674038\n",
            "Epoch 2/5:  52% 139/267 [02:55<03:07,  1.47s/it, loss=0.8214, lr=0.000020]Text tokens shape: torch.Size([2, 108])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 891, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 891, 1024])\n",
            "Speech logits slice: [142:891]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.927386\n",
            "Epoch 2/5:  52% 140/267 [02:56<02:56,  1.39s/it, loss=0.8244, lr=0.000020]Text tokens shape: torch.Size([2, 52])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 835, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 835, 1024])\n",
            "Speech logits slice: [86:835]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.570014\n",
            "Epoch 2/5:  53% 141/267 [02:57<02:36,  1.24s/it, loss=0.8244, lr=0.000020]Text tokens shape: torch.Size([2, 90])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 873, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 873, 1024])\n",
            "Speech logits slice: [124:873]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.642863\n",
            "Epoch 2/5:  53% 142/267 [02:58<02:44,  1.32s/it, loss=0.8244, lr=0.000020]Text tokens shape: torch.Size([2, 125])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 908, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 908, 1024])\n",
            "Speech logits slice: [159:908]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.927950\n",
            "Epoch 2/5:  54% 143/267 [03:00<02:33,  1.24s/it, loss=0.8244, lr=0.000020]Text tokens shape: torch.Size([2, 77])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 860, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 860, 1024])\n",
            "Speech logits slice: [111:860]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.648311\n",
            "Epoch 2/5:  54% 144/267 [03:01<02:23,  1.17s/it, loss=0.8195, lr=0.000020]Text tokens shape: torch.Size([2, 54])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 837, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 837, 1024])\n",
            "Speech logits slice: [88:837]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.570363\n",
            "Epoch 2/5:  54% 145/267 [03:02<02:32,  1.25s/it, loss=0.8195, lr=0.000020]Text tokens shape: torch.Size([2, 78])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 861, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 861, 1024])\n",
            "Speech logits slice: [112:861]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.683811\n",
            "Epoch 2/5:  55% 146/267 [03:03<02:24,  1.19s/it, loss=0.8195, lr=0.000020]Text tokens shape: torch.Size([2, 116])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 899, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 899, 1024])\n",
            "Speech logits slice: [150:899]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.786380\n",
            "Epoch 2/5:  55% 147/267 [03:04<02:15,  1.13s/it, loss=0.8195, lr=0.000020]Text tokens shape: torch.Size([2, 65])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 848, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 848, 1024])\n",
            "Speech logits slice: [99:848]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.524982\n",
            "Epoch 2/5:  55% 148/267 [03:06<02:36,  1.32s/it, loss=0.8115, lr=0.000020]Text tokens shape: torch.Size([2, 115])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 898, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 898, 1024])\n",
            "Speech logits slice: [149:898]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.695825\n",
            "Epoch 2/5:  56% 149/267 [03:07<02:23,  1.22s/it, loss=0.8115, lr=0.000020]Text tokens shape: torch.Size([2, 126])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 909, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 909, 1024])\n",
            "Speech logits slice: [160:909]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.132734\n",
            "Epoch 2/5:  56% 150/267 [03:08<02:14,  1.15s/it, loss=0.8115, lr=0.000020]Text tokens shape: torch.Size([2, 111])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 894, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 894, 1024])\n",
            "Speech logits slice: [145:894]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.787803\n",
            "Epoch 2/5:  57% 151/267 [03:10<02:39,  1.38s/it, loss=0.8115, lr=0.000020]Text tokens shape: torch.Size([2, 61])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 844, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 844, 1024])\n",
            "Speech logits slice: [95:844]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.564409\n",
            "Epoch 2/5:  57% 152/267 [03:11<02:26,  1.27s/it, loss=0.8050, lr=0.000020]Text tokens shape: torch.Size([2, 63])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 846, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 846, 1024])\n",
            "Speech logits slice: [97:846]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.547340\n",
            "Epoch 2/5:  57% 153/267 [03:12<02:22,  1.25s/it, loss=0.8050, lr=0.000020]Text tokens shape: torch.Size([2, 100])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 883, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 883, 1024])\n",
            "Speech logits slice: [134:883]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.894894\n",
            "Epoch 2/5:  58% 154/267 [03:13<02:32,  1.35s/it, loss=0.8050, lr=0.000020]Text tokens shape: torch.Size([2, 96])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 879, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 879, 1024])\n",
            "Speech logits slice: [130:879]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.931356\n",
            "Epoch 2/5:  58% 155/267 [03:14<02:17,  1.23s/it, loss=0.8050, lr=0.000020]Text tokens shape: torch.Size([2, 74])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 857, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 857, 1024])\n",
            "Speech logits slice: [108:857]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.484468\n",
            "Epoch 2/5:  58% 156/267 [03:15<02:09,  1.16s/it, loss=0.7968, lr=0.000020]Text tokens shape: torch.Size([2, 74])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 857, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 857, 1024])\n",
            "Speech logits slice: [108:857]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.497108\n",
            "Epoch 2/5:  59% 157/267 [03:16<01:59,  1.09s/it, loss=0.7968, lr=0.000020]Text tokens shape: torch.Size([2, 97])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 880, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 880, 1024])\n",
            "Speech logits slice: [131:880]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.951499\n",
            "Epoch 2/5:  59% 158/267 [03:18<02:03,  1.13s/it, loss=0.7968, lr=0.000020]Text tokens shape: torch.Size([2, 73])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 856, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 856, 1024])\n",
            "Speech logits slice: [107:856]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.544560\n",
            "Epoch 2/5:  60% 159/267 [03:19<02:14,  1.25s/it, loss=0.7968, lr=0.000020]Text tokens shape: torch.Size([2, 111])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 894, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 894, 1024])\n",
            "Speech logits slice: [145:894]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.986605\n",
            "Epoch 2/5:  60% 160/267 [03:20<02:08,  1.20s/it, loss=0.8016, lr=0.000020]Text tokens shape: torch.Size([2, 66])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 849, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 849, 1024])\n",
            "Speech logits slice: [100:849]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.588165\n",
            "Epoch 2/5:  60% 161/267 [03:22<02:14,  1.27s/it, loss=0.8016, lr=0.000020]Text tokens shape: torch.Size([2, 71])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 854, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 854, 1024])\n",
            "Speech logits slice: [105:854]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.653438\n",
            "Epoch 2/5:  61% 162/267 [03:23<02:09,  1.23s/it, loss=0.8016, lr=0.000020]Text tokens shape: torch.Size([2, 121])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 904, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 904, 1024])\n",
            "Speech logits slice: [155:904]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.830389\n",
            "Epoch 2/5:  61% 163/267 [03:24<02:00,  1.16s/it, loss=0.8016, lr=0.000020]Text tokens shape: torch.Size([2, 52])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 835, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 835, 1024])\n",
            "Speech logits slice: [86:835]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.502782\n",
            "Epoch 2/5:  61% 164/267 [03:25<01:54,  1.11s/it, loss=0.7943, lr=0.000020]Text tokens shape: torch.Size([2, 135])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 918, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 918, 1024])\n",
            "Speech logits slice: [169:918]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.109818\n",
            "Epoch 2/5:  62% 165/267 [03:26<01:49,  1.07s/it, loss=0.7943, lr=0.000020]Text tokens shape: torch.Size([2, 83])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 866, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 866, 1024])\n",
            "Speech logits slice: [117:866]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.775128\n",
            "Epoch 2/5:  62% 166/267 [03:28<02:11,  1.30s/it, loss=0.7943, lr=0.000020]Text tokens shape: torch.Size([2, 48])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 831, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 831, 1024])\n",
            "Speech logits slice: [82:831]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.535163\n",
            "Epoch 2/5:  63% 167/267 [03:29<02:01,  1.22s/it, loss=0.7943, lr=0.000020]Text tokens shape: torch.Size([2, 56])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 839, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 839, 1024])\n",
            "Speech logits slice: [90:839]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.525409\n",
            "Epoch 2/5:  63% 168/267 [03:30<01:54,  1.15s/it, loss=0.7879, lr=0.000020]Text tokens shape: torch.Size([2, 73])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 856, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 856, 1024])\n",
            "Speech logits slice: [107:856]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.602882\n",
            "Epoch 2/5:  63% 169/267 [03:31<02:02,  1.25s/it, loss=0.7879, lr=0.000020]Text tokens shape: torch.Size([2, 62])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 845, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 845, 1024])\n",
            "Speech logits slice: [96:845]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.742924\n",
            "Epoch 2/5:  64% 170/267 [03:32<01:55,  1.19s/it, loss=0.7879, lr=0.000020]Text tokens shape: torch.Size([2, 186])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 969, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 969, 1024])\n",
            "Speech logits slice: [220:969]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.508020\n",
            "Epoch 2/5:  64% 171/267 [03:33<01:50,  1.15s/it, loss=0.7879, lr=0.000020]Text tokens shape: torch.Size([2, 144])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 927, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 927, 1024])\n",
            "Speech logits slice: [178:927]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.081397\n",
            "Epoch 2/5:  64% 172/267 [03:35<02:13,  1.40s/it, loss=0.7947, lr=0.000020]Text tokens shape: torch.Size([2, 90])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 873, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 873, 1024])\n",
            "Speech logits slice: [124:873]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.602108\n",
            "Epoch 2/5:  65% 173/267 [03:36<01:58,  1.26s/it, loss=0.7947, lr=0.000020]Text tokens shape: torch.Size([2, 116])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 899, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 899, 1024])\n",
            "Speech logits slice: [150:899]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.065585\n",
            "Epoch 2/5:  65% 174/267 [03:37<01:59,  1.29s/it, loss=0.7947, lr=0.000020]Text tokens shape: torch.Size([2, 65])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 848, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 848, 1024])\n",
            "Speech logits slice: [99:848]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.513969\n",
            "Epoch 2/5:  66% 175/267 [03:39<02:04,  1.35s/it, loss=0.7947, lr=0.000020]Text tokens shape: torch.Size([2, 88])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 871, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 871, 1024])\n",
            "Speech logits slice: [122:871]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.944812\n",
            "Epoch 2/5:  66% 176/267 [03:40<01:54,  1.26s/it, loss=0.7981, lr=0.000020]Text tokens shape: torch.Size([2, 71])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 854, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 854, 1024])\n",
            "Speech logits slice: [105:854]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.525205\n",
            "Epoch 2/5:  66% 177/267 [03:42<01:59,  1.33s/it, loss=0.7981, lr=0.000020]Text tokens shape: torch.Size([2, 91])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 874, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 874, 1024])\n",
            "Speech logits slice: [125:874]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.668275\n",
            "Epoch 2/5:  67% 178/267 [03:43<01:53,  1.27s/it, loss=0.7981, lr=0.000020]Text tokens shape: torch.Size([2, 50])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 833, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 833, 1024])\n",
            "Speech logits slice: [84:833]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.504261\n",
            "Epoch 2/5:  67% 179/267 [03:44<01:42,  1.17s/it, loss=0.7981, lr=0.000020]Text tokens shape: torch.Size([2, 55])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 838, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 838, 1024])\n",
            "Speech logits slice: [89:838]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.473217\n",
            "Epoch 2/5:  67% 180/267 [03:45<01:37,  1.12s/it, loss=0.7909, lr=0.000020]Text tokens shape: torch.Size([2, 92])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 875, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 875, 1024])\n",
            "Speech logits slice: [126:875]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.823733\n",
            "Epoch 2/5:  68% 181/267 [03:46<01:32,  1.08s/it, loss=0.7909, lr=0.000020]Text tokens shape: torch.Size([2, 168])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 951, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 951, 1024])\n",
            "Speech logits slice: [202:951]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.407670\n",
            "Epoch 2/5:  68% 182/267 [03:47<01:43,  1.21s/it, loss=0.7909, lr=0.000020]Text tokens shape: torch.Size([2, 73])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 856, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 856, 1024])\n",
            "Speech logits slice: [107:856]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.599842\n",
            "Epoch 2/5:  69% 183/267 [03:48<01:39,  1.18s/it, loss=0.7909, lr=0.000020]Text tokens shape: torch.Size([2, 74])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 857, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 857, 1024])\n",
            "Speech logits slice: [108:857]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.524091\n",
            "Epoch 2/5:  69% 184/267 [03:49<01:34,  1.14s/it, loss=0.7851, lr=0.000020]Text tokens shape: torch.Size([2, 94])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 877, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 877, 1024])\n",
            "Speech logits slice: [128:877]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.845771\n",
            "Epoch 2/5:  69% 185/267 [03:51<01:41,  1.23s/it, loss=0.7851, lr=0.000020]Text tokens shape: torch.Size([2, 107])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 890, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 890, 1024])\n",
            "Speech logits slice: [141:890]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.709947\n",
            "Epoch 2/5:  70% 186/267 [03:52<01:35,  1.18s/it, loss=0.7851, lr=0.000020]Text tokens shape: torch.Size([2, 68])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 851, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 851, 1024])\n",
            "Speech logits slice: [102:851]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.490088\n",
            "Epoch 2/5:  70% 187/267 [03:53<01:28,  1.11s/it, loss=0.7851, lr=0.000020]Text tokens shape: torch.Size([2, 77])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 860, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 860, 1024])\n",
            "Speech logits slice: [111:860]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.531116\n",
            "Epoch 2/5:  70% 188/267 [03:55<01:44,  1.33s/it, loss=0.7797, lr=0.000020]Text tokens shape: torch.Size([2, 127])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 910, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 910, 1024])\n",
            "Speech logits slice: [161:910]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.140498\n",
            "Epoch 2/5:  71% 189/267 [03:56<01:36,  1.24s/it, loss=0.7797, lr=0.000020]Text tokens shape: torch.Size([2, 139])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 922, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 922, 1024])\n",
            "Speech logits slice: [173:922]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.973168\n",
            "Epoch 2/5:  71% 190/267 [03:57<01:45,  1.37s/it, loss=0.7797, lr=0.000020]Text tokens shape: torch.Size([2, 66])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 849, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 849, 1024])\n",
            "Speech logits slice: [100:849]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.541048\n",
            "Epoch 2/5:  72% 191/267 [03:59<01:50,  1.45s/it, loss=0.7797, lr=0.000020]Text tokens shape: torch.Size([2, 96])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 879, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 879, 1024])\n",
            "Speech logits slice: [130:879]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.708909\n",
            "Epoch 2/5:  72% 192/267 [04:00<01:40,  1.34s/it, loss=0.7782, lr=0.000020]Text tokens shape: torch.Size([2, 59])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 842, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 842, 1024])\n",
            "Speech logits slice: [93:842]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.546709\n",
            "Epoch 2/5:  72% 193/267 [04:01<01:35,  1.29s/it, loss=0.7782, lr=0.000020]Text tokens shape: torch.Size([2, 76])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 859, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 859, 1024])\n",
            "Speech logits slice: [110:859]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.739477\n",
            "Epoch 2/5:  73% 194/267 [04:03<01:39,  1.36s/it, loss=0.7782, lr=0.000020]Text tokens shape: torch.Size([2, 72])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 855, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 855, 1024])\n",
            "Speech logits slice: [106:855]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.511267\n",
            "Epoch 2/5:  73% 195/267 [04:04<01:28,  1.23s/it, loss=0.7782, lr=0.000020]Text tokens shape: torch.Size([2, 60])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 843, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 843, 1024])\n",
            "Speech logits slice: [94:843]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.439968\n",
            "Epoch 2/5:  73% 196/267 [04:05<01:22,  1.16s/it, loss=0.7713, lr=0.000020]Text tokens shape: torch.Size([2, 173])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 956, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 956, 1024])\n",
            "Speech logits slice: [207:956]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.207900\n",
            "Epoch 2/5:  74% 197/267 [04:06<01:18,  1.13s/it, loss=0.7713, lr=0.000020]Text tokens shape: torch.Size([2, 58])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 841, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 841, 1024])\n",
            "Speech logits slice: [92:841]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.517414\n",
            "Epoch 2/5:  74% 198/267 [04:07<01:24,  1.23s/it, loss=0.7713, lr=0.000020]Text tokens shape: torch.Size([2, 46])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 829, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 829, 1024])\n",
            "Speech logits slice: [80:829]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.517422\n",
            "Epoch 2/5:  75% 199/267 [04:08<01:23,  1.22s/it, loss=0.7713, lr=0.000020]Text tokens shape: torch.Size([2, 77])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 860, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 860, 1024])\n",
            "Speech logits slice: [111:860]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.722300\n",
            "Epoch 2/5:  75% 200/267 [04:09<01:18,  1.17s/it, loss=0.7703, lr=0.000020]Text tokens shape: torch.Size([2, 56])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 839, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 839, 1024])\n",
            "Speech logits slice: [90:839]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.609245\n",
            "Epoch 2/5:  75% 201/267 [04:11<01:25,  1.29s/it, loss=0.7703, lr=0.000020]Text tokens shape: torch.Size([2, 73])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 856, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 856, 1024])\n",
            "Speech logits slice: [107:856]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.541440\n",
            "Epoch 2/5:  76% 202/267 [04:12<01:18,  1.21s/it, loss=0.7703, lr=0.000020]Text tokens shape: torch.Size([2, 66])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 849, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 849, 1024])\n",
            "Speech logits slice: [100:849]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.659230\n",
            "Epoch 2/5:  76% 203/267 [04:13<01:12,  1.13s/it, loss=0.7703, lr=0.000020]Text tokens shape: torch.Size([2, 92])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 875, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 875, 1024])\n",
            "Speech logits slice: [126:875]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.679437\n",
            "Epoch 2/5:  76% 204/267 [04:14<01:10,  1.12s/it, loss=0.7685, lr=0.000020]Text tokens shape: torch.Size([2, 130])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 913, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 913, 1024])\n",
            "Speech logits slice: [164:913]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.948311\n",
            "Epoch 2/5:  77% 205/267 [04:15<01:07,  1.08s/it, loss=0.7685, lr=0.000020]Text tokens shape: torch.Size([2, 155])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 938, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 938, 1024])\n",
            "Speech logits slice: [189:938]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.967081\n",
            "Epoch 2/5:  77% 206/267 [04:17<01:14,  1.22s/it, loss=0.7685, lr=0.000020]Text tokens shape: torch.Size([2, 66])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 849, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 849, 1024])\n",
            "Speech logits slice: [100:849]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.507088\n",
            "Epoch 2/5:  78% 207/267 [04:18<01:08,  1.15s/it, loss=0.7685, lr=0.000020]Text tokens shape: torch.Size([2, 70])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 853, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 853, 1024])\n",
            "Speech logits slice: [104:853]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.806174\n",
            "Epoch 2/5:  78% 208/267 [04:19<01:05,  1.11s/it, loss=0.7693, lr=0.000020]Text tokens shape: torch.Size([2, 101])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 884, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 884, 1024])\n",
            "Speech logits slice: [135:884]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.854656\n",
            "Epoch 2/5:  78% 209/267 [04:20<01:10,  1.22s/it, loss=0.7693, lr=0.000020]Text tokens shape: torch.Size([2, 57])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 840, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 840, 1024])\n",
            "Speech logits slice: [91:840]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.540730\n",
            "Epoch 2/5:  79% 210/267 [04:21<01:06,  1.16s/it, loss=0.7693, lr=0.000020]Text tokens shape: torch.Size([2, 81])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 864, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 864, 1024])\n",
            "Speech logits slice: [115:864]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.678754\n",
            "Epoch 2/5:  79% 211/267 [04:22<01:01,  1.09s/it, loss=0.7693, lr=0.000020]Text tokens shape: torch.Size([2, 85])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 868, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 868, 1024])\n",
            "Speech logits slice: [119:868]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.709171\n",
            "Epoch 2/5:  79% 212/267 [04:24<01:14,  1.36s/it, loss=0.7681, lr=0.000020]Text tokens shape: torch.Size([2, 86])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 869, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 869, 1024])\n",
            "Speech logits slice: [120:869]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.796705\n",
            "Epoch 2/5:  80% 213/267 [04:25<01:06,  1.24s/it, loss=0.7681, lr=0.000020]Text tokens shape: torch.Size([2, 89])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 872, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 872, 1024])\n",
            "Speech logits slice: [123:872]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.583438\n",
            "Epoch 2/5:  80% 214/267 [04:26<01:01,  1.15s/it, loss=0.7681, lr=0.000020]Text tokens shape: torch.Size([2, 69])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 852, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 852, 1024])\n",
            "Speech logits slice: [103:852]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.808948\n",
            "Epoch 2/5:  81% 215/267 [04:28<01:17,  1.49s/it, loss=0.7681, lr=0.000020]Text tokens shape: torch.Size([2, 98])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 881, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 881, 1024])\n",
            "Speech logits slice: [132:881]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.642454\n",
            "Epoch 2/5:  81% 216/267 [04:29<01:09,  1.36s/it, loss=0.7658, lr=0.000020]Text tokens shape: torch.Size([2, 134])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 917, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 917, 1024])\n",
            "Speech logits slice: [168:917]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.155891\n",
            "Epoch 2/5:  81% 217/267 [04:30<01:06,  1.32s/it, loss=0.7658, lr=0.000020]Text tokens shape: torch.Size([2, 73])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 856, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 856, 1024])\n",
            "Speech logits slice: [107:856]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.572669\n",
            "Epoch 2/5:  82% 218/267 [04:32<01:08,  1.39s/it, loss=0.7658, lr=0.000020]Text tokens shape: torch.Size([2, 77])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 860, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 860, 1024])\n",
            "Speech logits slice: [111:860]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.526295\n",
            "Epoch 2/5:  82% 219/267 [04:33<01:00,  1.25s/it, loss=0.7658, lr=0.000020]Text tokens shape: torch.Size([2, 74])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 857, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 857, 1024])\n",
            "Speech logits slice: [108:857]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.562737\n",
            "Epoch 2/5:  82% 220/267 [04:34<00:55,  1.18s/it, loss=0.7621, lr=0.000020]Text tokens shape: torch.Size([2, 229])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 1012, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 1012, 1024])\n",
            "Speech logits slice: [263:1012]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.413159\n",
            "Epoch 2/5:  83% 221/267 [04:35<00:53,  1.15s/it, loss=0.7621, lr=0.000020]Text tokens shape: torch.Size([2, 103])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 886, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 886, 1024])\n",
            "Speech logits slice: [137:886]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.790994\n",
            "Epoch 2/5:  83% 222/267 [04:37<00:57,  1.27s/it, loss=0.7621, lr=0.000020]Text tokens shape: torch.Size([2, 84])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 867, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 867, 1024])\n",
            "Speech logits slice: [118:867]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.627025\n",
            "Epoch 2/5:  84% 223/267 [04:38<00:54,  1.24s/it, loss=0.7621, lr=0.000020]Text tokens shape: torch.Size([2, 61])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 844, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 844, 1024])\n",
            "Speech logits slice: [95:844]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.606642\n",
            "Epoch 2/5:  84% 224/267 [04:39<00:50,  1.17s/it, loss=0.7593, lr=0.000020]Text tokens shape: torch.Size([2, 133])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 916, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 916, 1024])\n",
            "Speech logits slice: [167:916]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.871413\n",
            "Epoch 2/5:  84% 225/267 [04:40<00:53,  1.28s/it, loss=0.7593, lr=0.000020]Text tokens shape: torch.Size([2, 71])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 854, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 854, 1024])\n",
            "Speech logits slice: [105:854]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.628633\n",
            "Epoch 2/5:  85% 226/267 [04:41<00:51,  1.26s/it, loss=0.7593, lr=0.000020]Text tokens shape: torch.Size([2, 83])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 866, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 866, 1024])\n",
            "Speech logits slice: [117:866]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.647989\n",
            "Epoch 2/5:  85% 227/267 [04:42<00:46,  1.17s/it, loss=0.7593, lr=0.000020]Text tokens shape: torch.Size([2, 85])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 868, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 868, 1024])\n",
            "Speech logits slice: [119:868]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.643836\n",
            "Epoch 2/5:  85% 228/267 [04:43<00:43,  1.12s/it, loss=0.7573, lr=0.000020]Text tokens shape: torch.Size([2, 141])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 924, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 924, 1024])\n",
            "Speech logits slice: [175:924]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.853038\n",
            "Epoch 2/5:  86% 229/267 [04:44<00:41,  1.08s/it, loss=0.7573, lr=0.000020]Text tokens shape: torch.Size([2, 75])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 858, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 858, 1024])\n",
            "Speech logits slice: [109:858]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.631002\n",
            "Epoch 2/5:  86% 230/267 [04:46<00:44,  1.22s/it, loss=0.7573, lr=0.000020]Text tokens shape: torch.Size([2, 79])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 862, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 862, 1024])\n",
            "Speech logits slice: [113:862]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.622996\n",
            "Epoch 2/5:  87% 231/267 [04:47<00:42,  1.18s/it, loss=0.7573, lr=0.000020]Text tokens shape: torch.Size([2, 72])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 855, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 855, 1024])\n",
            "Speech logits slice: [106:855]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.696190\n",
            "Epoch 2/5:  87% 232/267 [04:48<00:39,  1.14s/it, loss=0.7563, lr=0.000020]Text tokens shape: torch.Size([2, 85])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 868, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 868, 1024])\n",
            "Speech logits slice: [119:868]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.600035\n",
            "Epoch 2/5:  87% 233/267 [04:50<00:42,  1.25s/it, loss=0.7563, lr=0.000020]Text tokens shape: torch.Size([2, 152])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 935, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 935, 1024])\n",
            "Speech logits slice: [186:935]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.578073\n",
            "Epoch 2/5:  88% 234/267 [04:51<00:40,  1.23s/it, loss=0.7563, lr=0.000020]Text tokens shape: torch.Size([2, 104])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 887, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 887, 1024])\n",
            "Speech logits slice: [138:887]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.999017\n",
            "Epoch 2/5:  88% 235/267 [04:52<00:36,  1.15s/it, loss=0.7563, lr=0.000020]Text tokens shape: torch.Size([2, 76])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 859, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 859, 1024])\n",
            "Speech logits slice: [110:859]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.701036\n",
            "Epoch 2/5:  88% 236/267 [04:53<00:34,  1.11s/it, loss=0.7553, lr=0.000020]Text tokens shape: torch.Size([2, 103])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 886, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 886, 1024])\n",
            "Speech logits slice: [137:886]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.617734\n",
            "Epoch 2/5:  89% 237/267 [04:54<00:31,  1.06s/it, loss=0.7553, lr=0.000020]Text tokens shape: torch.Size([2, 195])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 978, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 978, 1024])\n",
            "Speech logits slice: [229:978]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.037462\n",
            "Epoch 2/5:  89% 238/267 [04:55<00:34,  1.20s/it, loss=0.7553, lr=0.000020]Text tokens shape: torch.Size([2, 100])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 883, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 883, 1024])\n",
            "Speech logits slice: [134:883]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.734349\n",
            "Epoch 2/5:  90% 239/267 [04:56<00:32,  1.15s/it, loss=0.7553, lr=0.000020]Text tokens shape: torch.Size([2, 60])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 843, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 843, 1024])\n",
            "Speech logits slice: [94:843]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.721206\n",
            "Epoch 2/5:  90% 240/267 [04:57<00:29,  1.10s/it, loss=0.7548, lr=0.000020]Text tokens shape: torch.Size([2, 91])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 874, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 874, 1024])\n",
            "Speech logits slice: [125:874]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.832593\n",
            "Epoch 2/5:  90% 241/267 [04:59<00:31,  1.21s/it, loss=0.7548, lr=0.000020]Text tokens shape: torch.Size([2, 54])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 837, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 837, 1024])\n",
            "Speech logits slice: [88:837]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.541216\n",
            "Epoch 2/5:  91% 242/267 [05:00<00:29,  1.17s/it, loss=0.7548, lr=0.000020]Text tokens shape: torch.Size([2, 61])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 844, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 844, 1024])\n",
            "Speech logits slice: [95:844]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.522004\n",
            "Epoch 2/5:  91% 243/267 [05:01<00:26,  1.11s/it, loss=0.7548, lr=0.000020]Text tokens shape: torch.Size([2, 89])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 872, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 872, 1024])\n",
            "Speech logits slice: [123:872]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.746866\n",
            "Epoch 2/5:  91% 244/267 [05:02<00:25,  1.09s/it, loss=0.7546, lr=0.000020]Text tokens shape: torch.Size([2, 207])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 990, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 990, 1024])\n",
            "Speech logits slice: [241:990]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.238083\n",
            "Epoch 2/5:  92% 245/267 [05:03<00:23,  1.08s/it, loss=0.7546, lr=0.000020]Text tokens shape: torch.Size([2, 97])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 880, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 880, 1024])\n",
            "Speech logits slice: [131:880]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.692690\n",
            "Epoch 2/5:  92% 246/267 [05:05<00:27,  1.32s/it, loss=0.7546, lr=0.000020]Text tokens shape: torch.Size([2, 113])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 896, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 896, 1024])\n",
            "Speech logits slice: [147:896]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.936173\n",
            "Epoch 2/5:  93% 247/267 [05:06<00:24,  1.24s/it, loss=0.7546, lr=0.000020]Text tokens shape: torch.Size([2, 51])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 834, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 834, 1024])\n",
            "Speech logits slice: [85:834]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.598298\n",
            "Epoch 2/5:  93% 248/267 [05:07<00:22,  1.16s/it, loss=0.7521, lr=0.000020]Text tokens shape: torch.Size([2, 122])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 905, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 905, 1024])\n",
            "Speech logits slice: [156:905]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.875853\n",
            "Epoch 2/5:  93% 249/267 [05:08<00:22,  1.26s/it, loss=0.7521, lr=0.000020]Text tokens shape: torch.Size([2, 220])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 1003, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 1003, 1024])\n",
            "Speech logits slice: [254:1003]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.363235\n",
            "Epoch 2/5:  94% 250/267 [05:09<00:20,  1.23s/it, loss=0.7521, lr=0.000020]Text tokens shape: torch.Size([2, 120])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 903, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 903, 1024])\n",
            "Speech logits slice: [154:903]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.763181\n",
            "Epoch 2/5:  94% 251/267 [05:10<00:18,  1.15s/it, loss=0.7521, lr=0.000020]Text tokens shape: torch.Size([2, 77])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 860, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 860, 1024])\n",
            "Speech logits slice: [111:860]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.721797\n",
            "Epoch 2/5:  94% 252/267 [05:12<00:20,  1.35s/it, loss=0.7516, lr=0.000020]Text tokens shape: torch.Size([2, 51])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 834, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 834, 1024])\n",
            "Speech logits slice: [85:834]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.458124\n",
            "Epoch 2/5:  95% 253/267 [05:13<00:16,  1.21s/it, loss=0.7516, lr=0.000020]Text tokens shape: torch.Size([2, 102])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 885, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 885, 1024])\n",
            "Speech logits slice: [136:885]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.636078\n",
            "Epoch 2/5:  95% 254/267 [05:14<00:14,  1.14s/it, loss=0.7516, lr=0.000020]Text tokens shape: torch.Size([2, 57])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 840, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 840, 1024])\n",
            "Speech logits slice: [91:840]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.515774\n",
            "Epoch 2/5:  96% 255/267 [05:16<00:16,  1.39s/it, loss=0.7516, lr=0.000020]Text tokens shape: torch.Size([2, 64])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 847, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 847, 1024])\n",
            "Speech logits slice: [98:847]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.527836\n",
            "Epoch 2/5:  96% 256/267 [05:17<00:14,  1.28s/it, loss=0.7481, lr=0.000020]Text tokens shape: torch.Size([2, 74])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 857, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 857, 1024])\n",
            "Speech logits slice: [108:857]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.585459\n",
            "Epoch 2/5:  96% 257/267 [05:18<00:12,  1.27s/it, loss=0.7481, lr=0.000020]Text tokens shape: torch.Size([2, 92])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 875, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 875, 1024])\n",
            "Speech logits slice: [126:875]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.721366\n",
            "Epoch 2/5:  97% 258/267 [05:20<00:12,  1.40s/it, loss=0.7481, lr=0.000020]Text tokens shape: torch.Size([2, 97])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 880, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 880, 1024])\n",
            "Speech logits slice: [131:880]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.710320\n",
            "Epoch 2/5:  97% 259/267 [05:21<00:10,  1.27s/it, loss=0.7481, lr=0.000020]Text tokens shape: torch.Size([2, 69])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 852, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 852, 1024])\n",
            "Speech logits slice: [103:852]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.588321\n",
            "Epoch 2/5:  97% 260/267 [05:22<00:08,  1.20s/it, loss=0.7457, lr=0.000020]Text tokens shape: torch.Size([2, 150])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 933, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 933, 1024])\n",
            "Speech logits slice: [184:933]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.061626\n",
            "Epoch 2/5:  98% 261/267 [05:23<00:06,  1.14s/it, loss=0.7457, lr=0.000020]Text tokens shape: torch.Size([2, 68])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 851, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 851, 1024])\n",
            "Speech logits slice: [102:851]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.571063\n",
            "Epoch 2/5:  98% 262/267 [05:24<00:05,  1.16s/it, loss=0.7457, lr=0.000020]Text tokens shape: torch.Size([2, 68])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 851, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 851, 1024])\n",
            "Speech logits slice: [102:851]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.539260\n",
            "Epoch 2/5:  99% 263/267 [05:26<00:05,  1.25s/it, loss=0.7457, lr=0.000020]Text tokens shape: torch.Size([2, 62])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 845, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 845, 1024])\n",
            "Speech logits slice: [96:845]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.494049\n",
            "Epoch 2/5:  99% 264/267 [05:27<00:03,  1.18s/it, loss=0.7419, lr=0.000020]Text tokens shape: torch.Size([2, 127])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 910, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 910, 1024])\n",
            "Speech logits slice: [161:910]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.868600\n",
            "Epoch 2/5:  99% 265/267 [05:28<00:02,  1.24s/it, loss=0.7419, lr=0.000020]Text tokens shape: torch.Size([2, 107])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 890, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 890, 1024])\n",
            "Speech logits slice: [141:890]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.677492\n",
            "Epoch 2/5: 100% 266/267 [05:29<00:01,  1.24s/it, loss=0.7419, lr=0.000020]Text tokens shape: torch.Size([2, 59])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 842, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 842, 1024])\n",
            "Speech logits slice: [93:842]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.458028\n",
            "Epoch 2/5: 100% 267/267 [05:30<00:00,  1.24s/it, loss=0.7419, lr=0.000020]\n",
            "Validation:   0% 0/30 [00:00<?, ?it/s]Text tokens shape: torch.Size([2, 70])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 853, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 853, 1024])\n",
            "Speech logits slice: [104:853]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.545673\n",
            "Validation:   3% 1/30 [00:01<00:43,  1.51s/it]Text tokens shape: torch.Size([2, 81])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 864, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 864, 1024])\n",
            "Speech logits slice: [115:864]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.670465\n",
            "Validation:   7% 2/30 [00:02<00:26,  1.05it/s]Text tokens shape: torch.Size([2, 116])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 899, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 899, 1024])\n",
            "Speech logits slice: [150:899]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.906074\n",
            "Validation:  10% 3/30 [00:02<00:21,  1.28it/s]Text tokens shape: torch.Size([2, 264])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 1047, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 1047, 1024])\n",
            "Speech logits slice: [298:1047]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.267010\n",
            "Validation:  13% 4/30 [00:03<00:18,  1.37it/s]Text tokens shape: torch.Size([2, 101])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 884, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 884, 1024])\n",
            "Speech logits slice: [135:884]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.689812\n",
            "Validation:  17% 5/30 [00:03<00:16,  1.48it/s]Text tokens shape: torch.Size([2, 99])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 882, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 882, 1024])\n",
            "Speech logits slice: [133:882]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.901764\n",
            "Validation:  20% 6/30 [00:04<00:15,  1.55it/s]Text tokens shape: torch.Size([2, 94])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 877, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 877, 1024])\n",
            "Speech logits slice: [128:877]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.811205\n",
            "Validation:  23% 7/30 [00:05<00:14,  1.59it/s]Text tokens shape: torch.Size([2, 67])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 850, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 850, 1024])\n",
            "Speech logits slice: [101:850]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.496648\n",
            "Validation:  27% 8/30 [00:05<00:13,  1.65it/s]Text tokens shape: torch.Size([2, 70])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 853, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 853, 1024])\n",
            "Speech logits slice: [104:853]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.585991\n",
            "Validation:  30% 9/30 [00:06<00:12,  1.69it/s]Text tokens shape: torch.Size([2, 82])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 865, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 865, 1024])\n",
            "Speech logits slice: [116:865]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.619289\n",
            "Validation:  33% 10/30 [00:06<00:11,  1.68it/s]Text tokens shape: torch.Size([2, 51])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 834, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 834, 1024])\n",
            "Speech logits slice: [85:834]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.531310\n",
            "Validation:  37% 11/30 [00:07<00:11,  1.72it/s]Text tokens shape: torch.Size([2, 73])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 856, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 856, 1024])\n",
            "Speech logits slice: [107:856]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.615995\n",
            "Validation:  40% 12/30 [00:07<00:10,  1.72it/s]Text tokens shape: torch.Size([2, 122])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 905, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 905, 1024])\n",
            "Speech logits slice: [156:905]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.907202\n",
            "Validation:  43% 13/30 [00:08<00:09,  1.70it/s]Text tokens shape: torch.Size([2, 86])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 869, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 869, 1024])\n",
            "Speech logits slice: [120:869]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.532795\n",
            "Validation:  47% 14/30 [00:09<00:09,  1.71it/s]Text tokens shape: torch.Size([2, 102])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 885, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 885, 1024])\n",
            "Speech logits slice: [136:885]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.795989\n",
            "Validation:  50% 15/30 [00:09<00:08,  1.72it/s]Text tokens shape: torch.Size([2, 130])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 913, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 913, 1024])\n",
            "Speech logits slice: [164:913]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.873355\n",
            "Validation:  53% 16/30 [00:10<00:08,  1.70it/s]Text tokens shape: torch.Size([2, 149])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 932, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 932, 1024])\n",
            "Speech logits slice: [183:932]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.997314\n",
            "Validation:  57% 17/30 [00:10<00:07,  1.66it/s]Text tokens shape: torch.Size([2, 144])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 927, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 927, 1024])\n",
            "Speech logits slice: [178:927]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.968441\n",
            "Validation:  60% 18/30 [00:11<00:07,  1.65it/s]Text tokens shape: torch.Size([2, 56])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 839, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 839, 1024])\n",
            "Speech logits slice: [90:839]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.542627\n",
            "Validation:  63% 19/30 [00:12<00:06,  1.71it/s]Text tokens shape: torch.Size([2, 104])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 887, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 887, 1024])\n",
            "Speech logits slice: [138:887]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.596832\n",
            "Validation:  67% 20/30 [00:12<00:05,  1.68it/s]Text tokens shape: torch.Size([2, 137])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 920, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 920, 1024])\n",
            "Speech logits slice: [171:920]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.873891\n",
            "Validation:  70% 21/30 [00:13<00:05,  1.67it/s]Text tokens shape: torch.Size([2, 74])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 857, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 857, 1024])\n",
            "Speech logits slice: [108:857]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.687163\n",
            "Validation:  73% 22/30 [00:13<00:04,  1.65it/s]Text tokens shape: torch.Size([2, 104])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 887, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 887, 1024])\n",
            "Speech logits slice: [138:887]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.692249\n",
            "Validation:  77% 23/30 [00:14<00:04,  1.69it/s]Text tokens shape: torch.Size([2, 60])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 843, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 843, 1024])\n",
            "Speech logits slice: [94:843]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.591280\n",
            "Validation:  80% 24/30 [00:14<00:03,  1.75it/s]Text tokens shape: torch.Size([2, 64])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 847, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 847, 1024])\n",
            "Speech logits slice: [98:847]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.518485\n",
            "Validation:  83% 25/30 [00:15<00:02,  1.80it/s]Text tokens shape: torch.Size([2, 159])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 942, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 942, 1024])\n",
            "Speech logits slice: [193:942]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.927614\n",
            "Validation:  87% 26/30 [00:16<00:02,  1.74it/s]Text tokens shape: torch.Size([2, 107])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 890, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 890, 1024])\n",
            "Speech logits slice: [141:890]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.739635\n",
            "Validation:  90% 27/30 [00:16<00:01,  1.74it/s]Text tokens shape: torch.Size([2, 213])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 996, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 996, 1024])\n",
            "Speech logits slice: [247:996]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.507330\n",
            "Validation:  93% 28/30 [00:17<00:01,  1.67it/s]Text tokens shape: torch.Size([2, 40])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 823, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 823, 1024])\n",
            "Speech logits slice: [74:823]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.564707\n",
            "Validation:  97% 29/30 [00:17<00:00,  1.73it/s]Text tokens shape: torch.Size([1, 75])\n",
            "Target tokens shape: torch.Size([1, 750])\n",
            "Batch size: 1\n",
            "Embeds shape: torch.Size([2, 858, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([2, 858, 1024])\n",
            "Speech logits slice: [109:858]\n",
            "Speech logits shape: torch.Size([2, 749, 8194])\n",
            "Target shifted shape: torch.Size([2, 749])\n",
            "Final shapes - logits: torch.Size([2, 749, 8194]), targets: torch.Size([2, 749])\n",
            "Computed loss: 0.635633\n",
            "Validation: 100% 30/30 [00:18<00:00,  1.65it/s]\n",
            "Epoch 2 - Train Loss: 0.7419, Val Loss: 0.7531\n",
            "Saved checkpoint to checkpoints_lora/checkpoint_epoch1_step132.pt\n",
            "Epoch 3/5:   0% 0/267 [00:00<?, ?it/s]Text tokens shape: torch.Size([2, 49])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 832, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 832, 1024])\n",
            "Speech logits slice: [83:832]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.456006\n",
            "Epoch 3/5:   0% 1/267 [00:02<10:32,  2.38s/it]Text tokens shape: torch.Size([2, 102])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 885, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 885, 1024])\n",
            "Speech logits slice: [136:885]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.691798\n",
            "Epoch 3/5:   1% 2/267 [00:03<06:49,  1.55s/it]Text tokens shape: torch.Size([2, 101])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 884, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 884, 1024])\n",
            "Speech logits slice: [135:884]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.874521\n",
            "Epoch 3/5:   1% 3/267 [00:04<05:38,  1.28s/it]Text tokens shape: torch.Size([2, 77])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 860, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 860, 1024])\n",
            "Speech logits slice: [111:860]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.560669\n",
            "Epoch 3/5:   1% 4/267 [00:05<05:11,  1.18s/it, loss=0.5607, lr=0.000020]Text tokens shape: torch.Size([2, 116])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 899, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 899, 1024])\n",
            "Speech logits slice: [150:899]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.857301\n",
            "Epoch 3/5:   2% 5/267 [00:07<06:28,  1.48s/it, loss=0.5607, lr=0.000020]Text tokens shape: torch.Size([2, 51])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 834, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 834, 1024])\n",
            "Speech logits slice: [85:834]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.503033\n",
            "Epoch 3/5:   2% 6/267 [00:08<05:48,  1.33s/it, loss=0.5607, lr=0.000020]Text tokens shape: torch.Size([2, 82])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 865, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 865, 1024])\n",
            "Speech logits slice: [116:865]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.674927\n",
            "Epoch 3/5:   3% 7/267 [00:09<05:12,  1.20s/it, loss=0.5607, lr=0.000020]Text tokens shape: torch.Size([2, 140])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 923, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 923, 1024])\n",
            "Speech logits slice: [174:923]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.856521\n",
            "Epoch 3/5:   3% 8/267 [00:10<05:01,  1.16s/it, loss=0.7086, lr=0.000020]Text tokens shape: torch.Size([2, 116])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 899, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 899, 1024])\n",
            "Speech logits slice: [150:899]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.912253\n",
            "Epoch 3/5:   3% 9/267 [00:11<04:51,  1.13s/it, loss=0.7086, lr=0.000020]Text tokens shape: torch.Size([2, 110])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 893, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 893, 1024])\n",
            "Speech logits slice: [144:893]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.975524\n",
            "Epoch 3/5:   4% 10/267 [00:13<05:32,  1.29s/it, loss=0.7086, lr=0.000020]Text tokens shape: torch.Size([2, 108])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 891, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 891, 1024])\n",
            "Speech logits slice: [142:891]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.892796\n",
            "Epoch 3/5:   4% 11/267 [00:14<05:09,  1.21s/it, loss=0.7086, lr=0.000020]Text tokens shape: torch.Size([2, 55])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 838, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 838, 1024])\n",
            "Speech logits slice: [89:838]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.519093\n",
            "Epoch 3/5:   4% 12/267 [00:15<04:56,  1.16s/it, loss=0.6454, lr=0.000020]Text tokens shape: torch.Size([2, 90])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 873, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 873, 1024])\n",
            "Speech logits slice: [124:873]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.691536\n",
            "Epoch 3/5:   5% 13/267 [00:17<05:47,  1.37s/it, loss=0.6454, lr=0.000020]Text tokens shape: torch.Size([2, 73])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 856, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 856, 1024])\n",
            "Speech logits slice: [107:856]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.521752\n",
            "Epoch 3/5:   5% 14/267 [00:17<05:11,  1.23s/it, loss=0.6454, lr=0.000020]Text tokens shape: torch.Size([2, 77])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 860, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 860, 1024])\n",
            "Speech logits slice: [111:860]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.633668\n",
            "Epoch 3/5:   6% 15/267 [00:18<04:51,  1.16s/it, loss=0.6454, lr=0.000020]Text tokens shape: torch.Size([2, 51])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 834, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 834, 1024])\n",
            "Speech logits slice: [85:834]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.441799\n",
            "Epoch 3/5:   6% 16/267 [00:20<05:50,  1.39s/it, loss=0.5945, lr=0.000020]Text tokens shape: torch.Size([2, 68])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 851, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 851, 1024])\n",
            "Speech logits slice: [102:851]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.755166\n",
            "Epoch 3/5:   6% 17/267 [00:21<05:12,  1.25s/it, loss=0.5945, lr=0.000020]Text tokens shape: torch.Size([2, 78])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 861, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 861, 1024])\n",
            "Speech logits slice: [112:861]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.719099\n",
            "Epoch 3/5:   7% 18/267 [00:22<04:47,  1.16s/it, loss=0.5945, lr=0.000020]Text tokens shape: torch.Size([2, 104])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 887, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 887, 1024])\n",
            "Speech logits slice: [138:887]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.642386\n",
            "Epoch 3/5:   7% 19/267 [00:24<05:38,  1.36s/it, loss=0.5945, lr=0.000020]Text tokens shape: torch.Size([2, 67])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 850, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 850, 1024])\n",
            "Speech logits slice: [101:850]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.718384\n",
            "Epoch 3/5:   7% 20/267 [00:25<05:10,  1.26s/it, loss=0.6193, lr=0.000020]Text tokens shape: torch.Size([2, 156])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 939, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 939, 1024])\n",
            "Speech logits slice: [190:939]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.812182\n",
            "Epoch 3/5:   8% 21/267 [00:26<05:12,  1.27s/it, loss=0.6193, lr=0.000020]Text tokens shape: torch.Size([2, 109])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 892, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 892, 1024])\n",
            "Speech logits slice: [143:892]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.681550\n",
            "Epoch 3/5:   8% 22/267 [00:28<05:39,  1.39s/it, loss=0.6193, lr=0.000020]Text tokens shape: torch.Size([2, 113])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 896, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 896, 1024])\n",
            "Speech logits slice: [147:896]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.920786\n",
            "Epoch 3/5:   9% 23/267 [00:29<05:09,  1.27s/it, loss=0.6193, lr=0.000020]Text tokens shape: torch.Size([2, 141])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 924, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 924, 1024])\n",
            "Speech logits slice: [175:924]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.005841\n",
            "Epoch 3/5:   9% 24/267 [00:30<04:56,  1.22s/it, loss=0.6837, lr=0.000020]Text tokens shape: torch.Size([2, 96])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 879, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 879, 1024])\n",
            "Speech logits slice: [130:879]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.679046\n",
            "Epoch 3/5:   9% 25/267 [00:31<04:35,  1.14s/it, loss=0.6837, lr=0.000020]Text tokens shape: torch.Size([2, 186])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 969, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 969, 1024])\n",
            "Speech logits slice: [220:969]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.744906\n",
            "Epoch 3/5:  10% 26/267 [00:33<05:10,  1.29s/it, loss=0.6837, lr=0.000020]Text tokens shape: torch.Size([2, 70])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 853, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 853, 1024])\n",
            "Speech logits slice: [104:853]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.600843\n",
            "Epoch 3/5:  10% 27/267 [00:34<04:55,  1.23s/it, loss=0.6837, lr=0.000020]Text tokens shape: torch.Size([2, 69])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 852, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 852, 1024])\n",
            "Speech logits slice: [103:852]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.571074\n",
            "Epoch 3/5:  10% 28/267 [00:35<04:39,  1.17s/it, loss=0.6676, lr=0.000020]Text tokens shape: torch.Size([2, 60])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 843, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 843, 1024])\n",
            "Speech logits slice: [94:843]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.678330\n",
            "Epoch 3/5:  11% 29/267 [00:37<05:31,  1.39s/it, loss=0.6676, lr=0.000020]Text tokens shape: torch.Size([2, 62])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 845, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 845, 1024])\n",
            "Speech logits slice: [96:845]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.477234\n",
            "Epoch 3/5:  11% 30/267 [00:38<05:07,  1.30s/it, loss=0.6676, lr=0.000020]Text tokens shape: torch.Size([2, 73])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 856, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 856, 1024])\n",
            "Speech logits slice: [107:856]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.558935\n",
            "Epoch 3/5:  12% 31/267 [00:39<04:39,  1.18s/it, loss=0.6676, lr=0.000020]Text tokens shape: torch.Size([2, 229])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 1012, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 1012, 1024])\n",
            "Speech logits slice: [263:1012]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.219220\n",
            "Epoch 3/5:  12% 32/267 [00:40<04:39,  1.19s/it, loss=0.7366, lr=0.000020]Text tokens shape: torch.Size([2, 45])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 828, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 828, 1024])\n",
            "Speech logits slice: [79:828]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.468156\n",
            "Epoch 3/5:  12% 33/267 [00:41<04:19,  1.11s/it, loss=0.7366, lr=0.000020]Text tokens shape: torch.Size([2, 79])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 862, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 862, 1024])\n",
            "Speech logits slice: [113:862]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.595055\n",
            "Epoch 3/5:  13% 34/267 [00:42<04:51,  1.25s/it, loss=0.7366, lr=0.000020]Text tokens shape: torch.Size([2, 75])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 858, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 858, 1024])\n",
            "Speech logits slice: [109:858]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.479220\n",
            "Epoch 3/5:  13% 35/267 [00:44<04:39,  1.20s/it, loss=0.7366, lr=0.000020]Text tokens shape: torch.Size([2, 69])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 852, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 852, 1024])\n",
            "Speech logits slice: [103:852]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.668653\n",
            "Epoch 3/5:  13% 36/267 [00:45<04:24,  1.15s/it, loss=0.7290, lr=0.000020]Text tokens shape: torch.Size([2, 71])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 854, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 854, 1024])\n",
            "Speech logits slice: [105:854]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.653434\n",
            "Epoch 3/5:  14% 37/267 [00:46<04:46,  1.25s/it, loss=0.7290, lr=0.000020]Text tokens shape: torch.Size([2, 89])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 872, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 872, 1024])\n",
            "Speech logits slice: [123:872]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.626962\n",
            "Epoch 3/5:  14% 38/267 [00:47<04:41,  1.23s/it, loss=0.7290, lr=0.000020]Text tokens shape: torch.Size([2, 58])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 841, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 841, 1024])\n",
            "Speech logits slice: [92:841]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.549427\n",
            "Epoch 3/5:  15% 39/267 [00:48<04:19,  1.14s/it, loss=0.7290, lr=0.000020]Text tokens shape: torch.Size([2, 45])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 828, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 828, 1024])\n",
            "Speech logits slice: [79:828]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.435737\n",
            "Epoch 3/5:  15% 40/267 [00:49<04:10,  1.10s/it, loss=0.6997, lr=0.000020]Text tokens shape: torch.Size([2, 103])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 886, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 886, 1024])\n",
            "Speech logits slice: [137:886]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.589933\n",
            "Epoch 3/5:  15% 41/267 [00:50<03:57,  1.05s/it, loss=0.6997, lr=0.000020]Text tokens shape: torch.Size([2, 96])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 879, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 879, 1024])\n",
            "Speech logits slice: [130:879]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.827415\n",
            "Epoch 3/5:  16% 42/267 [00:51<04:07,  1.10s/it, loss=0.6997, lr=0.000020]Text tokens shape: torch.Size([2, 93])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 876, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 876, 1024])\n",
            "Speech logits slice: [127:876]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.899864\n",
            "Epoch 3/5:  16% 43/267 [00:53<04:35,  1.23s/it, loss=0.6997, lr=0.000020]Text tokens shape: torch.Size([2, 49])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 832, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 832, 1024])\n",
            "Speech logits slice: [83:832]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.524899\n",
            "Epoch 3/5:  16% 44/267 [00:54<04:22,  1.18s/it, loss=0.6838, lr=0.000019]Text tokens shape: torch.Size([2, 57])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 840, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 840, 1024])\n",
            "Speech logits slice: [91:840]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.502376\n",
            "Epoch 3/5:  17% 45/267 [00:55<04:21,  1.18s/it, loss=0.6838, lr=0.000019]Text tokens shape: torch.Size([2, 77])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 860, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 860, 1024])\n",
            "Speech logits slice: [111:860]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.535356\n",
            "Epoch 3/5:  17% 46/267 [00:57<04:44,  1.29s/it, loss=0.6838, lr=0.000019]Text tokens shape: torch.Size([2, 130])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 913, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 913, 1024])\n",
            "Speech logits slice: [164:913]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.843102\n",
            "Epoch 3/5:  18% 47/267 [00:58<04:24,  1.20s/it, loss=0.6838, lr=0.000019]Text tokens shape: torch.Size([2, 192])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 975, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 975, 1024])\n",
            "Speech logits slice: [226:975]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.318192\n",
            "Epoch 3/5:  18% 48/267 [00:59<04:19,  1.19s/it, loss=0.7367, lr=0.000019]Text tokens shape: torch.Size([2, 63])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 846, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 846, 1024])\n",
            "Speech logits slice: [97:846]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.512471\n",
            "Epoch 3/5:  18% 49/267 [01:00<03:59,  1.10s/it, loss=0.7367, lr=0.000019]Text tokens shape: torch.Size([2, 110])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 893, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 893, 1024])\n",
            "Speech logits slice: [144:893]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.894842\n",
            "Epoch 3/5:  19% 50/267 [01:01<04:24,  1.22s/it, loss=0.7367, lr=0.000019]Text tokens shape: torch.Size([2, 54])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 837, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 837, 1024])\n",
            "Speech logits slice: [88:837]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.625107\n",
            "Epoch 3/5:  19% 51/267 [01:02<04:25,  1.23s/it, loss=0.7367, lr=0.000019]Text tokens shape: torch.Size([2, 123])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 906, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 906, 1024])\n",
            "Speech logits slice: [157:906]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.908044\n",
            "Epoch 3/5:  19% 52/267 [01:04<04:13,  1.18s/it, loss=0.7499, lr=0.000019]Text tokens shape: torch.Size([2, 61])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 844, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 844, 1024])\n",
            "Speech logits slice: [95:844]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.600781\n",
            "Epoch 3/5:  20% 53/267 [01:05<04:32,  1.27s/it, loss=0.7499, lr=0.000019]Text tokens shape: torch.Size([2, 63])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 846, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 846, 1024])\n",
            "Speech logits slice: [97:846]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.531577\n",
            "Epoch 3/5:  20% 54/267 [01:06<04:31,  1.27s/it, loss=0.7499, lr=0.000019]Text tokens shape: torch.Size([2, 85])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 868, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 868, 1024])\n",
            "Speech logits slice: [119:868]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.591509\n",
            "Epoch 3/5:  21% 55/267 [01:07<04:10,  1.18s/it, loss=0.7499, lr=0.000019]Text tokens shape: torch.Size([2, 75])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 858, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 858, 1024])\n",
            "Speech logits slice: [109:858]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.546241\n",
            "Epoch 3/5:  21% 56/267 [01:08<03:59,  1.14s/it, loss=0.7353, lr=0.000019]Text tokens shape: torch.Size([2, 119])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 902, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 902, 1024])\n",
            "Speech logits slice: [153:902]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.722167\n",
            "Epoch 3/5:  21% 57/267 [01:09<03:47,  1.08s/it, loss=0.7353, lr=0.000019]Text tokens shape: torch.Size([2, 92])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 875, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 875, 1024])\n",
            "Speech logits slice: [126:875]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.654151\n",
            "Epoch 3/5:  22% 58/267 [01:10<03:54,  1.12s/it, loss=0.7353, lr=0.000019]Text tokens shape: torch.Size([2, 139])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 922, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 922, 1024])\n",
            "Speech logits slice: [173:922]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.935403\n",
            "Epoch 3/5:  22% 59/267 [01:12<04:21,  1.26s/it, loss=0.7353, lr=0.000019]Text tokens shape: torch.Size([2, 80])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 863, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 863, 1024])\n",
            "Speech logits slice: [114:863]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.676375\n",
            "Epoch 3/5:  22% 60/267 [01:13<04:06,  1.19s/it, loss=0.7314, lr=0.000019]Text tokens shape: torch.Size([2, 81])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 864, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 864, 1024])\n",
            "Speech logits slice: [115:864]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.620910\n",
            "Epoch 3/5:  23% 61/267 [01:15<04:41,  1.37s/it, loss=0.7314, lr=0.000019]Text tokens shape: torch.Size([2, 61])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 844, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 844, 1024])\n",
            "Speech logits slice: [95:844]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.547277\n",
            "Epoch 3/5:  23% 62/267 [01:16<04:33,  1.33s/it, loss=0.7314, lr=0.000019]Text tokens shape: torch.Size([2, 63])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 846, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 846, 1024])\n",
            "Speech logits slice: [97:846]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.473608\n",
            "Epoch 3/5:  24% 63/267 [01:17<04:05,  1.20s/it, loss=0.7314, lr=0.000019]Text tokens shape: torch.Size([2, 58])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 841, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 841, 1024])\n",
            "Speech logits slice: [92:841]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.458352\n",
            "Epoch 3/5:  24% 64/267 [01:18<03:51,  1.14s/it, loss=0.7143, lr=0.000019]Text tokens shape: torch.Size([2, 169])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 952, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 952, 1024])\n",
            "Speech logits slice: [203:952]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.976639\n",
            "Epoch 3/5:  24% 65/267 [01:19<03:45,  1.11s/it, loss=0.7143, lr=0.000019]Text tokens shape: torch.Size([2, 85])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 868, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 868, 1024])\n",
            "Speech logits slice: [119:868]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.623051\n",
            "Epoch 3/5:  25% 66/267 [01:20<03:50,  1.15s/it, loss=0.7143, lr=0.000019]Text tokens shape: torch.Size([2, 67])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 850, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 850, 1024])\n",
            "Speech logits slice: [101:850]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.462721\n",
            "Epoch 3/5:  25% 67/267 [01:22<04:10,  1.25s/it, loss=0.7143, lr=0.000019]Text tokens shape: torch.Size([2, 58])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 841, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 841, 1024])\n",
            "Speech logits slice: [92:841]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.470279\n",
            "Epoch 3/5:  25% 68/267 [01:23<03:55,  1.18s/it, loss=0.7000, lr=0.000019]Text tokens shape: torch.Size([2, 71])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 854, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 854, 1024])\n",
            "Speech logits slice: [105:854]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.639251\n",
            "Epoch 3/5:  26% 69/267 [01:24<03:54,  1.18s/it, loss=0.7000, lr=0.000019]Text tokens shape: torch.Size([2, 65])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 848, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 848, 1024])\n",
            "Speech logits slice: [99:848]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.590997\n",
            "Epoch 3/5:  26% 70/267 [01:25<04:11,  1.28s/it, loss=0.7000, lr=0.000019]Text tokens shape: torch.Size([2, 127])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 910, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 910, 1024])\n",
            "Speech logits slice: [161:910]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.808754\n",
            "Epoch 3/5:  27% 71/267 [01:26<03:53,  1.19s/it, loss=0.7000, lr=0.000019]Text tokens shape: torch.Size([2, 99])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 882, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 882, 1024])\n",
            "Speech logits slice: [133:882]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.745455\n",
            "Epoch 3/5:  27% 72/267 [01:27<03:44,  1.15s/it, loss=0.7025, lr=0.000019]Text tokens shape: torch.Size([2, 68])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 851, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 851, 1024])\n",
            "Speech logits slice: [102:851]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.512783\n",
            "Epoch 3/5:  27% 73/267 [01:28<03:29,  1.08s/it, loss=0.7025, lr=0.000019]Text tokens shape: torch.Size([2, 55])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 838, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 838, 1024])\n",
            "Speech logits slice: [89:838]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.534220\n",
            "Epoch 3/5:  28% 74/267 [01:30<03:36,  1.12s/it, loss=0.7025, lr=0.000019]Text tokens shape: torch.Size([2, 68])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 851, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 851, 1024])\n",
            "Speech logits slice: [102:851]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.636564\n",
            "Epoch 3/5:  28% 75/267 [01:31<04:02,  1.26s/it, loss=0.7025, lr=0.000019]Text tokens shape: torch.Size([2, 118])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 901, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 901, 1024])\n",
            "Speech logits slice: [152:901]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.589649\n",
            "Epoch 3/5:  28% 76/267 [01:32<03:49,  1.20s/it, loss=0.6966, lr=0.000019]Text tokens shape: torch.Size([2, 94])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 877, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 877, 1024])\n",
            "Speech logits slice: [128:877]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.719996\n",
            "Epoch 3/5:  29% 77/267 [01:34<03:49,  1.21s/it, loss=0.6966, lr=0.000019]Text tokens shape: torch.Size([2, 112])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 895, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 895, 1024])\n",
            "Speech logits slice: [146:895]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.782149\n",
            "Epoch 3/5:  29% 78/267 [01:35<04:07,  1.31s/it, loss=0.6966, lr=0.000019]Text tokens shape: torch.Size([2, 65])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 848, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 848, 1024])\n",
            "Speech logits slice: [99:848]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.486725\n",
            "Epoch 3/5:  30% 79/267 [01:36<03:43,  1.19s/it, loss=0.6966, lr=0.000019]Text tokens shape: torch.Size([2, 98])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 881, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 881, 1024])\n",
            "Speech logits slice: [132:881]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.637116\n",
            "Epoch 3/5:  30% 80/267 [01:37<03:36,  1.16s/it, loss=0.6936, lr=0.000019]Text tokens shape: torch.Size([2, 63])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 846, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 846, 1024])\n",
            "Speech logits slice: [97:846]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.556641\n",
            "Epoch 3/5:  30% 81/267 [01:38<03:21,  1.09s/it, loss=0.6936, lr=0.000019]Text tokens shape: torch.Size([2, 104])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 887, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 887, 1024])\n",
            "Speech logits slice: [138:887]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.923106\n",
            "Epoch 3/5:  31% 82/267 [01:39<03:29,  1.13s/it, loss=0.6936, lr=0.000019]Text tokens shape: torch.Size([2, 77])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 860, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 860, 1024])\n",
            "Speech logits slice: [111:860]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.614966\n",
            "Epoch 3/5:  31% 83/267 [01:41<03:49,  1.25s/it, loss=0.6936, lr=0.000019]Text tokens shape: torch.Size([2, 99])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 882, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 882, 1024])\n",
            "Speech logits slice: [133:882]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.563847\n",
            "Epoch 3/5:  31% 84/267 [01:42<03:36,  1.18s/it, loss=0.6874, lr=0.000019]Text tokens shape: torch.Size([2, 206])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 989, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 989, 1024])\n",
            "Speech logits slice: [240:989]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.409006\n",
            "Epoch 3/5:  32% 85/267 [01:43<03:50,  1.27s/it, loss=0.6874, lr=0.000019]Text tokens shape: torch.Size([2, 62])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 845, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 845, 1024])\n",
            "Speech logits slice: [96:845]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.831761\n",
            "Epoch 3/5:  32% 86/267 [01:45<03:53,  1.29s/it, loss=0.6874, lr=0.000019]Text tokens shape: torch.Size([2, 65])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 848, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 848, 1024])\n",
            "Speech logits slice: [99:848]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.687234\n",
            "Epoch 3/5:  33% 87/267 [01:46<03:33,  1.19s/it, loss=0.6874, lr=0.000019]Text tokens shape: torch.Size([2, 133])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 916, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 916, 1024])\n",
            "Speech logits slice: [167:916]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.926602\n",
            "Epoch 3/5:  33% 88/267 [01:47<03:27,  1.16s/it, loss=0.6983, lr=0.000019]Text tokens shape: torch.Size([2, 58])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 841, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 841, 1024])\n",
            "Speech logits slice: [92:841]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.457469\n",
            "Epoch 3/5:  33% 89/267 [01:47<03:12,  1.08s/it, loss=0.6983, lr=0.000019]Text tokens shape: torch.Size([2, 90])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 873, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 873, 1024])\n",
            "Speech logits slice: [124:873]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.907078\n",
            "Epoch 3/5:  34% 90/267 [01:49<03:39,  1.24s/it, loss=0.6983, lr=0.000019]Text tokens shape: torch.Size([2, 96])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 879, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 879, 1024])\n",
            "Speech logits slice: [130:879]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.762306\n",
            "Epoch 3/5:  34% 91/267 [01:51<03:56,  1.34s/it, loss=0.6983, lr=0.000019]Text tokens shape: torch.Size([2, 61])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 844, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 844, 1024])\n",
            "Speech logits slice: [95:844]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.661270\n",
            "Epoch 3/5:  34% 92/267 [01:52<03:37,  1.24s/it, loss=0.6967, lr=0.000019]Text tokens shape: torch.Size([2, 145])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 928, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 928, 1024])\n",
            "Speech logits slice: [179:928]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.089268\n",
            "Epoch 3/5:  35% 93/267 [01:53<03:35,  1.24s/it, loss=0.6967, lr=0.000019]Text tokens shape: torch.Size([2, 49])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 832, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 832, 1024])\n",
            "Speech logits slice: [83:832]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.456322\n",
            "Epoch 3/5:  35% 94/267 [01:54<03:47,  1.32s/it, loss=0.6967, lr=0.000019]Text tokens shape: torch.Size([2, 85])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 868, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 868, 1024])\n",
            "Speech logits slice: [119:868]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.651453\n",
            "Epoch 3/5:  36% 95/267 [01:55<03:27,  1.20s/it, loss=0.6967, lr=0.000019]Text tokens shape: torch.Size([2, 78])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 861, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 861, 1024])\n",
            "Speech logits slice: [112:861]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.592191\n",
            "Epoch 3/5:  36% 96/267 [01:56<03:17,  1.15s/it, loss=0.6923, lr=0.000019]Text tokens shape: torch.Size([2, 72])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 855, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 855, 1024])\n",
            "Speech logits slice: [106:855]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.554584\n",
            "Epoch 3/5:  36% 97/267 [01:57<03:04,  1.08s/it, loss=0.6923, lr=0.000019]Text tokens shape: torch.Size([2, 111])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 894, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 894, 1024])\n",
            "Speech logits slice: [145:894]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.735569\n",
            "Epoch 3/5:  37% 98/267 [01:59<03:14,  1.15s/it, loss=0.6923, lr=0.000019]Text tokens shape: torch.Size([2, 70])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 853, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 853, 1024])\n",
            "Speech logits slice: [104:853]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.516195\n",
            "Epoch 3/5:  37% 99/267 [02:00<03:33,  1.27s/it, loss=0.6923, lr=0.000019]Text tokens shape: torch.Size([2, 64])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 847, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 847, 1024])\n",
            "Speech logits slice: [98:847]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.482421\n",
            "Epoch 3/5:  37% 100/267 [02:01<03:19,  1.19s/it, loss=0.6839, lr=0.000019]Text tokens shape: torch.Size([2, 96])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 879, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 879, 1024])\n",
            "Speech logits slice: [130:879]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.696704\n",
            "Epoch 3/5:  38% 101/267 [02:02<03:19,  1.20s/it, loss=0.6839, lr=0.000019]Text tokens shape: torch.Size([2, 73])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 856, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 856, 1024])\n",
            "Speech logits slice: [107:856]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.584974\n",
            "Epoch 3/5:  38% 102/267 [02:04<03:39,  1.33s/it, loss=0.6839, lr=0.000019]Text tokens shape: torch.Size([2, 170])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 953, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 953, 1024])\n",
            "Speech logits slice: [204:953]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.060397\n",
            "Epoch 3/5:  39% 103/267 [02:05<03:23,  1.24s/it, loss=0.6839, lr=0.000019]Text tokens shape: torch.Size([2, 118])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 901, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 901, 1024])\n",
            "Speech logits slice: [152:901]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.069069\n",
            "Epoch 3/5:  39% 104/267 [02:06<03:14,  1.19s/it, loss=0.6987, lr=0.000019]Text tokens shape: torch.Size([2, 194])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 977, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 977, 1024])\n",
            "Speech logits slice: [228:977]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.204754\n",
            "Epoch 3/5:  39% 105/267 [02:07<03:05,  1.14s/it, loss=0.6987, lr=0.000019]Text tokens shape: torch.Size([2, 58])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 841, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 841, 1024])\n",
            "Speech logits slice: [92:841]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.451701\n",
            "Epoch 3/5:  40% 106/267 [02:08<03:08,  1.17s/it, loss=0.6987, lr=0.000019]Text tokens shape: torch.Size([2, 73])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 856, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 856, 1024])\n",
            "Speech logits slice: [107:856]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.478708\n",
            "Epoch 3/5:  40% 107/267 [02:10<03:25,  1.28s/it, loss=0.6987, lr=0.000019]Text tokens shape: torch.Size([2, 85])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 868, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 868, 1024])\n",
            "Speech logits slice: [119:868]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.535803\n",
            "Epoch 3/5:  40% 108/267 [02:11<03:14,  1.22s/it, loss=0.6927, lr=0.000019]Text tokens shape: torch.Size([2, 55])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 838, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 838, 1024])\n",
            "Speech logits slice: [89:838]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.470764\n",
            "Epoch 3/5:  41% 109/267 [02:12<03:10,  1.21s/it, loss=0.6927, lr=0.000019]Text tokens shape: torch.Size([2, 79])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 862, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 862, 1024])\n",
            "Speech logits slice: [113:862]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.473298\n",
            "Epoch 3/5:  41% 110/267 [02:14<03:27,  1.32s/it, loss=0.6927, lr=0.000019]Text tokens shape: torch.Size([2, 56])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 839, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 839, 1024])\n",
            "Speech logits slice: [90:839]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.456168\n",
            "Epoch 3/5:  42% 111/267 [02:15<03:06,  1.20s/it, loss=0.6927, lr=0.000019]Text tokens shape: torch.Size([2, 103])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 886, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 886, 1024])\n",
            "Speech logits slice: [137:886]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.675097\n",
            "Epoch 3/5:  42% 112/267 [02:16<02:58,  1.15s/it, loss=0.6921, lr=0.000019]Text tokens shape: torch.Size([2, 57])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 840, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 840, 1024])\n",
            "Speech logits slice: [91:840]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.551257\n",
            "Epoch 3/5:  42% 113/267 [02:17<02:46,  1.08s/it, loss=0.6921, lr=0.000019]Text tokens shape: torch.Size([2, 91])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 874, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 874, 1024])\n",
            "Speech logits slice: [125:874]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.694648\n",
            "Epoch 3/5:  43% 114/267 [02:18<02:57,  1.16s/it, loss=0.6921, lr=0.000019]Text tokens shape: torch.Size([2, 100])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 883, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 883, 1024])\n",
            "Speech logits slice: [134:883]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.827447\n",
            "Epoch 3/5:  43% 115/267 [02:20<03:14,  1.28s/it, loss=0.6921, lr=0.000019]Text tokens shape: torch.Size([2, 45])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 828, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 828, 1024])\n",
            "Speech logits slice: [79:828]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.462033\n",
            "Epoch 3/5:  43% 116/267 [02:21<02:59,  1.19s/it, loss=0.6841, lr=0.000019]Text tokens shape: torch.Size([2, 134])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 917, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 917, 1024])\n",
            "Speech logits slice: [168:917]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.950807\n",
            "Epoch 3/5:  44% 117/267 [02:22<03:19,  1.33s/it, loss=0.6841, lr=0.000019]Text tokens shape: torch.Size([2, 99])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 882, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 882, 1024])\n",
            "Speech logits slice: [133:882]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.699297\n",
            "Epoch 3/5:  44% 118/267 [02:24<03:36,  1.45s/it, loss=0.6841, lr=0.000019]Text tokens shape: torch.Size([2, 67])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 850, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 850, 1024])\n",
            "Speech logits slice: [101:850]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.550493\n",
            "Epoch 3/5:  45% 119/267 [02:25<03:11,  1.29s/it, loss=0.6841, lr=0.000019]Text tokens shape: torch.Size([2, 187])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 970, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 970, 1024])\n",
            "Speech logits slice: [221:970]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.339820\n",
            "Epoch 3/5:  45% 120/267 [02:26<03:03,  1.25s/it, loss=0.7060, lr=0.000019]Text tokens shape: torch.Size([2, 227])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 1010, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 1010, 1024])\n",
            "Speech logits slice: [261:1010]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.151108\n",
            "Epoch 3/5:  45% 121/267 [02:27<02:54,  1.20s/it, loss=0.7060, lr=0.000019]Text tokens shape: torch.Size([2, 55])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 838, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 838, 1024])\n",
            "Speech logits slice: [89:838]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.644246\n",
            "Epoch 3/5:  46% 122/267 [02:29<03:06,  1.29s/it, loss=0.7060, lr=0.000019]Text tokens shape: torch.Size([2, 79])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 862, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 862, 1024])\n",
            "Speech logits slice: [113:862]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.780039\n",
            "Epoch 3/5:  46% 123/267 [02:30<03:04,  1.28s/it, loss=0.7060, lr=0.000019]Text tokens shape: torch.Size([2, 97])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 880, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 880, 1024])\n",
            "Speech logits slice: [131:880]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.801507\n",
            "Epoch 3/5:  46% 124/267 [02:31<02:52,  1.21s/it, loss=0.7091, lr=0.000019]Text tokens shape: torch.Size([2, 109])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 892, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 892, 1024])\n",
            "Speech logits slice: [143:892]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.045936\n",
            "Epoch 3/5:  47% 125/267 [02:32<03:01,  1.27s/it, loss=0.7091, lr=0.000019]Text tokens shape: torch.Size([2, 115])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 898, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 898, 1024])\n",
            "Speech logits slice: [149:898]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.123397\n",
            "Epoch 3/5:  47% 126/267 [02:34<02:59,  1.27s/it, loss=0.7091, lr=0.000019]Text tokens shape: torch.Size([2, 58])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 841, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 841, 1024])\n",
            "Speech logits slice: [92:841]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.519547\n",
            "Epoch 3/5:  48% 127/267 [02:35<02:43,  1.17s/it, loss=0.7091, lr=0.000019]Text tokens shape: torch.Size([2, 97])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 880, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 880, 1024])\n",
            "Speech logits slice: [131:880]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.729719\n",
            "Epoch 3/5:  48% 128/267 [02:36<02:37,  1.13s/it, loss=0.7097, lr=0.000019]Text tokens shape: torch.Size([2, 114])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 897, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 897, 1024])\n",
            "Speech logits slice: [148:897]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.855360\n",
            "Epoch 3/5:  48% 129/267 [02:37<02:30,  1.09s/it, loss=0.7097, lr=0.000019]Text tokens shape: torch.Size([2, 141])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 924, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 924, 1024])\n",
            "Speech logits slice: [175:924]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.880230\n",
            "Epoch 3/5:  49% 130/267 [02:38<02:47,  1.22s/it, loss=0.7097, lr=0.000019]Text tokens shape: torch.Size([2, 116])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 899, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 899, 1024])\n",
            "Speech logits slice: [150:899]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.775508\n",
            "Epoch 3/5:  49% 131/267 [02:39<02:48,  1.24s/it, loss=0.7097, lr=0.000019]Text tokens shape: torch.Size([2, 86])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 869, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 869, 1024])\n",
            "Speech logits slice: [120:869]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.527808\n",
            "Epoch 3/5:  49% 132/267 [02:40<02:37,  1.17s/it, loss=0.7042, lr=0.000019]Text tokens shape: torch.Size([2, 241])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 1024, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 1024, 1024])\n",
            "Speech logits slice: [275:1024]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.215789\n",
            "Epoch 3/5:  50% 133/267 [02:42<02:51,  1.28s/it, loss=0.7042, lr=0.000019]Text tokens shape: torch.Size([2, 51])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 834, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 834, 1024])\n",
            "Speech logits slice: [85:834]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.575359\n",
            "Epoch 3/5:  50% 134/267 [02:43<02:47,  1.26s/it, loss=0.7042, lr=0.000019]Text tokens shape: torch.Size([2, 63])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 846, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 846, 1024])\n",
            "Speech logits slice: [97:846]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.474558\n",
            "Epoch 3/5:  51% 135/267 [02:44<02:32,  1.15s/it, loss=0.7042, lr=0.000019]Text tokens shape: torch.Size([2, 95])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 878, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 878, 1024])\n",
            "Speech logits slice: [129:878]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.853596\n",
            "Epoch 3/5:  51% 136/267 [02:45<02:27,  1.13s/it, loss=0.7086, lr=0.000019]Text tokens shape: torch.Size([2, 71])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 854, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 854, 1024])\n",
            "Speech logits slice: [105:854]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.551351\n",
            "Epoch 3/5:  51% 137/267 [02:46<02:18,  1.06s/it, loss=0.7086, lr=0.000019]Text tokens shape: torch.Size([2, 67])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 850, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 850, 1024])\n",
            "Speech logits slice: [101:850]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.517944\n",
            "Epoch 3/5:  52% 138/267 [02:47<02:23,  1.11s/it, loss=0.7086, lr=0.000019]Text tokens shape: torch.Size([2, 78])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 861, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 861, 1024])\n",
            "Speech logits slice: [112:861]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.614411\n",
            "Epoch 3/5:  52% 139/267 [02:49<02:42,  1.27s/it, loss=0.7086, lr=0.000019]Text tokens shape: torch.Size([2, 100])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 883, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 883, 1024])\n",
            "Speech logits slice: [134:883]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.651880\n",
            "Epoch 3/5:  52% 140/267 [02:50<02:32,  1.20s/it, loss=0.7070, lr=0.000019]Text tokens shape: torch.Size([2, 101])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 884, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 884, 1024])\n",
            "Speech logits slice: [135:884]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.637739\n",
            "Epoch 3/5:  53% 141/267 [02:51<02:33,  1.22s/it, loss=0.7070, lr=0.000019]Text tokens shape: torch.Size([2, 111])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 894, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 894, 1024])\n",
            "Speech logits slice: [145:894]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.894914\n",
            "Epoch 3/5:  53% 142/267 [02:53<02:43,  1.31s/it, loss=0.7070, lr=0.000019]Text tokens shape: torch.Size([2, 112])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 895, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 895, 1024])\n",
            "Speech logits slice: [146:895]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.759101\n",
            "Epoch 3/5:  54% 143/267 [02:54<02:30,  1.22s/it, loss=0.7070, lr=0.000019]Text tokens shape: torch.Size([2, 104])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 887, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 887, 1024])\n",
            "Speech logits slice: [138:887]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.634371\n",
            "Epoch 3/5:  54% 144/267 [02:55<02:25,  1.18s/it, loss=0.7050, lr=0.000019]Text tokens shape: torch.Size([2, 61])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 844, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 844, 1024])\n",
            "Speech logits slice: [95:844]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.468118\n",
            "Epoch 3/5:  54% 145/267 [02:56<02:13,  1.09s/it, loss=0.7050, lr=0.000019]Text tokens shape: torch.Size([2, 87])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 870, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 870, 1024])\n",
            "Speech logits slice: [121:870]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.721096\n",
            "Epoch 3/5:  55% 146/267 [02:57<02:17,  1.14s/it, loss=0.7050, lr=0.000019]Text tokens shape: torch.Size([2, 169])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 952, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 952, 1024])\n",
            "Speech logits slice: [203:952]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.956439\n",
            "Epoch 3/5:  55% 147/267 [02:59<02:35,  1.30s/it, loss=0.7050, lr=0.000019]Text tokens shape: torch.Size([2, 64])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 847, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 847, 1024])\n",
            "Speech logits slice: [98:847]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.500211\n",
            "Epoch 3/5:  55% 148/267 [03:00<02:24,  1.22s/it, loss=0.6994, lr=0.000019]Text tokens shape: torch.Size([2, 109])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 892, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 892, 1024])\n",
            "Speech logits slice: [143:892]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.755977\n",
            "Epoch 3/5:  56% 149/267 [03:01<02:45,  1.40s/it, loss=0.6994, lr=0.000019]Text tokens shape: torch.Size([2, 62])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 845, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 845, 1024])\n",
            "Speech logits slice: [96:845]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.506625\n",
            "Epoch 3/5:  56% 150/267 [03:03<02:38,  1.36s/it, loss=0.6994, lr=0.000019]Text tokens shape: torch.Size([2, 92])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 875, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 875, 1024])\n",
            "Speech logits slice: [126:875]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.830358\n",
            "Epoch 3/5:  57% 151/267 [03:04<02:23,  1.24s/it, loss=0.6994, lr=0.000019]Text tokens shape: torch.Size([2, 101])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 884, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 884, 1024])\n",
            "Speech logits slice: [135:884]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.602001\n",
            "Epoch 3/5:  57% 152/267 [03:05<02:16,  1.18s/it, loss=0.6969, lr=0.000019]Text tokens shape: torch.Size([2, 115])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 898, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 898, 1024])\n",
            "Speech logits slice: [149:898]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.912713\n",
            "Epoch 3/5:  57% 153/267 [03:06<02:08,  1.12s/it, loss=0.6969, lr=0.000019]Text tokens shape: torch.Size([2, 95])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 878, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 878, 1024])\n",
            "Speech logits slice: [129:878]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.750241\n",
            "Epoch 3/5:  58% 154/267 [03:07<02:10,  1.15s/it, loss=0.6969, lr=0.000019]Text tokens shape: torch.Size([2, 56])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 839, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 839, 1024])\n",
            "Speech logits slice: [90:839]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.473388\n",
            "Epoch 3/5:  58% 155/267 [03:08<02:21,  1.27s/it, loss=0.6969, lr=0.000019]Text tokens shape: torch.Size([2, 73])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 856, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 856, 1024])\n",
            "Speech logits slice: [107:856]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.589764\n",
            "Epoch 3/5:  58% 156/267 [03:09<02:12,  1.19s/it, loss=0.6941, lr=0.000019]Text tokens shape: torch.Size([2, 47])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 830, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 830, 1024])\n",
            "Speech logits slice: [81:830]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.396344\n",
            "Epoch 3/5:  59% 157/267 [03:11<02:10,  1.19s/it, loss=0.6941, lr=0.000019]Text tokens shape: torch.Size([2, 59])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 842, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 842, 1024])\n",
            "Speech logits slice: [93:842]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.492401\n",
            "Epoch 3/5:  59% 158/267 [03:12<02:23,  1.31s/it, loss=0.6941, lr=0.000019]Text tokens shape: torch.Size([2, 243])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 1026, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 1026, 1024])\n",
            "Speech logits slice: [277:1026]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.820598\n",
            "Epoch 3/5:  60% 159/267 [03:13<02:15,  1.26s/it, loss=0.6941, lr=0.000019]Text tokens shape: torch.Size([2, 122])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 905, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 905, 1024])\n",
            "Speech logits slice: [156:905]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.038867\n",
            "Epoch 3/5:  60% 160/267 [03:14<02:08,  1.20s/it, loss=0.7027, lr=0.000019]Text tokens shape: torch.Size([2, 69])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 852, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 852, 1024])\n",
            "Speech logits slice: [103:852]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.679685\n",
            "Epoch 3/5:  60% 161/267 [03:15<01:58,  1.12s/it, loss=0.7027, lr=0.000019]Text tokens shape: torch.Size([2, 172])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 955, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 955, 1024])\n",
            "Speech logits slice: [206:955]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.360874\n",
            "Epoch 3/5:  61% 162/267 [03:17<02:03,  1.17s/it, loss=0.7027, lr=0.000019]Text tokens shape: torch.Size([2, 70])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 853, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 853, 1024])\n",
            "Speech logits slice: [104:853]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.761662\n",
            "Epoch 3/5:  61% 163/267 [03:18<02:11,  1.27s/it, loss=0.7027, lr=0.000019]Text tokens shape: torch.Size([2, 54])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 837, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 837, 1024])\n",
            "Speech logits slice: [88:837]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.508183\n",
            "Epoch 3/5:  61% 164/267 [03:19<02:02,  1.19s/it, loss=0.6980, lr=0.000019]Text tokens shape: torch.Size([2, 207])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 990, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 990, 1024])\n",
            "Speech logits slice: [241:990]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.811454\n",
            "Epoch 3/5:  62% 165/267 [03:21<02:14,  1.32s/it, loss=0.6980, lr=0.000019]Text tokens shape: torch.Size([2, 115])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 898, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 898, 1024])\n",
            "Speech logits slice: [149:898]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.667219\n",
            "Epoch 3/5:  62% 166/267 [03:22<02:12,  1.31s/it, loss=0.6980, lr=0.000019]Text tokens shape: torch.Size([2, 62])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 845, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 845, 1024])\n",
            "Speech logits slice: [96:845]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.579703\n",
            "Epoch 3/5:  63% 167/267 [03:23<02:00,  1.20s/it, loss=0.6980, lr=0.000019]Text tokens shape: torch.Size([2, 61])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 844, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 844, 1024])\n",
            "Speech logits slice: [95:844]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.447714\n",
            "Epoch 3/5:  63% 168/267 [03:24<01:53,  1.15s/it, loss=0.6920, lr=0.000019]Text tokens shape: torch.Size([2, 139])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 922, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 922, 1024])\n",
            "Speech logits slice: [173:922]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.061447\n",
            "Epoch 3/5:  63% 169/267 [03:25<01:49,  1.12s/it, loss=0.6920, lr=0.000019]Text tokens shape: torch.Size([2, 142])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 925, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 925, 1024])\n",
            "Speech logits slice: [176:925]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.954470\n",
            "Epoch 3/5:  64% 170/267 [03:27<02:04,  1.28s/it, loss=0.6920, lr=0.000019]Text tokens shape: torch.Size([2, 75])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 858, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 858, 1024])\n",
            "Speech logits slice: [109:858]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.521067\n",
            "Epoch 3/5:  64% 171/267 [03:28<02:00,  1.26s/it, loss=0.6920, lr=0.000019]Text tokens shape: torch.Size([2, 61])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 844, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 844, 1024])\n",
            "Speech logits slice: [95:844]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.521924\n",
            "Epoch 3/5:  64% 172/267 [03:29<01:52,  1.19s/it, loss=0.6881, lr=0.000019]Text tokens shape: torch.Size([2, 122])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 905, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 905, 1024])\n",
            "Speech logits slice: [156:905]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.880933\n",
            "Epoch 3/5:  65% 173/267 [03:31<02:01,  1.29s/it, loss=0.6881, lr=0.000019]Text tokens shape: torch.Size([2, 97])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 880, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 880, 1024])\n",
            "Speech logits slice: [131:880]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.714139\n",
            "Epoch 3/5:  65% 174/267 [03:32<01:57,  1.26s/it, loss=0.6881, lr=0.000019]Text tokens shape: torch.Size([2, 135])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 918, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 918, 1024])\n",
            "Speech logits slice: [169:918]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.890075\n",
            "Epoch 3/5:  66% 175/267 [03:33<01:49,  1.19s/it, loss=0.6881, lr=0.000019]Text tokens shape: torch.Size([2, 74])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 857, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 857, 1024])\n",
            "Speech logits slice: [108:857]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.601718\n",
            "Epoch 3/5:  66% 176/267 [03:34<01:45,  1.15s/it, loss=0.6861, lr=0.000019]Text tokens shape: torch.Size([2, 54])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 837, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 837, 1024])\n",
            "Speech logits slice: [88:837]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.453987\n",
            "Epoch 3/5:  66% 177/267 [03:35<01:36,  1.07s/it, loss=0.6861, lr=0.000019]Text tokens shape: torch.Size([2, 127])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 910, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 910, 1024])\n",
            "Speech logits slice: [161:910]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.882766\n",
            "Epoch 3/5:  67% 178/267 [03:37<01:56,  1.30s/it, loss=0.6861, lr=0.000019]Text tokens shape: torch.Size([2, 86])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 869, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 869, 1024])\n",
            "Speech logits slice: [120:869]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.656253\n",
            "Epoch 3/5:  67% 179/267 [03:38<01:54,  1.30s/it, loss=0.6861, lr=0.000019]Text tokens shape: torch.Size([2, 72])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 855, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 855, 1024])\n",
            "Speech logits slice: [106:855]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.590885\n",
            "Epoch 3/5:  67% 180/267 [03:39<01:46,  1.22s/it, loss=0.6840, lr=0.000019]Text tokens shape: torch.Size([2, 88])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 871, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 871, 1024])\n",
            "Speech logits slice: [122:871]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.782761\n",
            "Epoch 3/5:  68% 181/267 [03:40<01:51,  1.30s/it, loss=0.6840, lr=0.000019]Text tokens shape: torch.Size([2, 101])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 884, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 884, 1024])\n",
            "Speech logits slice: [135:884]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.840038\n",
            "Epoch 3/5:  68% 182/267 [03:42<01:49,  1.29s/it, loss=0.6840, lr=0.000019]Text tokens shape: torch.Size([2, 59])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 842, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 842, 1024])\n",
            "Speech logits slice: [93:842]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.522063\n",
            "Epoch 3/5:  69% 183/267 [03:43<01:39,  1.18s/it, loss=0.6840, lr=0.000019]Text tokens shape: torch.Size([2, 91])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 874, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 874, 1024])\n",
            "Speech logits slice: [125:874]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.780587\n",
            "Epoch 3/5:  69% 184/267 [03:44<01:35,  1.15s/it, loss=0.6861, lr=0.000019]Text tokens shape: torch.Size([2, 102])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 885, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 885, 1024])\n",
            "Speech logits slice: [136:885]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.688724\n",
            "Epoch 3/5:  69% 185/267 [03:45<01:29,  1.09s/it, loss=0.6861, lr=0.000019]Text tokens shape: torch.Size([2, 55])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 838, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 838, 1024])\n",
            "Speech logits slice: [89:838]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.464232\n",
            "Epoch 3/5:  70% 186/267 [03:46<01:31,  1.13s/it, loss=0.6861, lr=0.000019]Text tokens shape: torch.Size([2, 47])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 830, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 830, 1024])\n",
            "Speech logits slice: [81:830]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.532945\n",
            "Epoch 3/5:  70% 187/267 [03:47<01:40,  1.25s/it, loss=0.6861, lr=0.000019]Text tokens shape: torch.Size([2, 125])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 908, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 908, 1024])\n",
            "Speech logits slice: [159:908]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.839967\n",
            "Epoch 3/5:  70% 188/267 [03:48<01:34,  1.20s/it, loss=0.6894, lr=0.000019]Text tokens shape: torch.Size([2, 78])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 861, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 861, 1024])\n",
            "Speech logits slice: [112:861]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.482215\n",
            "Epoch 3/5:  71% 189/267 [03:50<01:33,  1.20s/it, loss=0.6894, lr=0.000019]Text tokens shape: torch.Size([2, 108])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 891, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 891, 1024])\n",
            "Speech logits slice: [142:891]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.676951\n",
            "Epoch 3/5:  71% 190/267 [03:51<01:42,  1.34s/it, loss=0.6894, lr=0.000019]Text tokens shape: torch.Size([2, 131])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 914, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 914, 1024])\n",
            "Speech logits slice: [165:914]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.028517\n",
            "Epoch 3/5:  72% 191/267 [03:52<01:34,  1.24s/it, loss=0.6894, lr=0.000019]Text tokens shape: torch.Size([2, 90])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 873, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 873, 1024])\n",
            "Speech logits slice: [124:873]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.538617\n",
            "Epoch 3/5:  72% 192/267 [03:53<01:28,  1.19s/it, loss=0.6862, lr=0.000019]Text tokens shape: torch.Size([2, 77])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 860, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 860, 1024])\n",
            "Speech logits slice: [111:860]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.584885\n",
            "Epoch 3/5:  72% 193/267 [03:54<01:22,  1.12s/it, loss=0.6862, lr=0.000019]Text tokens shape: torch.Size([2, 44])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 827, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 827, 1024])\n",
            "Speech logits slice: [78:827]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.365600\n",
            "Epoch 3/5:  73% 194/267 [03:56<01:22,  1.14s/it, loss=0.6862, lr=0.000019]Text tokens shape: torch.Size([2, 104])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 887, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 887, 1024])\n",
            "Speech logits slice: [138:887]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.650591\n",
            "Epoch 3/5:  73% 195/267 [03:57<01:32,  1.28s/it, loss=0.6862, lr=0.000019]Text tokens shape: torch.Size([2, 72])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 855, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 855, 1024])\n",
            "Speech logits slice: [106:855]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.555486\n",
            "Epoch 3/5:  73% 196/267 [03:58<01:25,  1.21s/it, loss=0.6836, lr=0.000019]Text tokens shape: torch.Size([2, 89])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 872, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 872, 1024])\n",
            "Speech logits slice: [123:872]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.667941\n",
            "Epoch 3/5:  74% 197/267 [03:59<01:24,  1.21s/it, loss=0.6836, lr=0.000019]Text tokens shape: torch.Size([2, 125])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 908, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 908, 1024])\n",
            "Speech logits slice: [159:908]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.102237\n",
            "Epoch 3/5:  74% 198/267 [04:01<01:31,  1.33s/it, loss=0.6836, lr=0.000019]Text tokens shape: torch.Size([2, 86])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 869, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 869, 1024])\n",
            "Speech logits slice: [120:869]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 0.530317\n",
            "Epoch 3/5:  75% 199/267 [04:02<01:23,  1.23s/it, loss=0.6836, lr=0.000019]Text tokens shape: torch.Size([2, 152])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 935, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 935, 1024])\n",
            "Speech logits slice: [186:935]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.012988\n",
            "Epoch 3/5:  75% 200/267 [04:03<01:20,  1.21s/it, loss=0.6902, lr=0.000019]Text tokens shape: torch.Size([2, 118])\n",
            "Target tokens shape: torch.Size([2, 750])\n",
            "Batch size: 2\n",
            "Embeds shape: torch.Size([4, 901, 1024])\n",
            "Conditioning length: 34\n",
            "Hidden states shape: torch.Size([4, 901, 1024])\n",
            "Speech logits slice: [152:901]\n",
            "Speech logits shape: torch.Size([4, 749, 8194])\n",
            "Target shifted shape: torch.Size([4, 749])\n",
            "Final shapes - logits: torch.Size([4, 749, 8194]), targets: torch.Size([4, 749])\n",
            "Computed loss: 1.088101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/chatterbox-lora\n",
        "!python loadandmergecheckpoint.py\n",
        "!python gradio_tts_app.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r59frC45XFtd",
        "outputId": "3e4c9f7e-af5a-4cd7-cad3-1ea446bcbfcd"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/chatterbox-lora\n",
            "Loading and merging checkpoint from: ./checkpoints_lora/checkpoint_epoch5_step612.pt\n",
            "Device: cuda\n",
            "Output directory: ./checkpoints_lora/merged_model\n",
            "--------------------------------------------------\n",
            "Loading checkpoint...\n",
            "/content/chatterbox-lora/loadandmergecheckpoint.py:141: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n",
            "Checkpoint info:\n",
            "  - Epoch: 5\n",
            "  - Step: 612\n",
            "  - Loss: 0.8042\n",
            "  - LoRA weights found: 420\n",
            "\n",
            "Loading base Chatterbox model...\n",
            "/content/chatterbox-lora/src/chatterbox/tts.py:152: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  torch.load(ckpt_dir / \"ve.pt\", map_location=map_location)\n",
            "/content/chatterbox-lora/src/chatterbox/tts.py:157: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  t3_state = torch.load(ckpt_dir / \"t3_cfg.pt\", map_location=map_location)\n",
            "/usr/local/lib/python3.12/dist-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.\n",
            "  deprecate(\"LoRACompatibleLinear\", \"1.0.0\", deprecation_message)\n",
            "/content/chatterbox-lora/src/chatterbox/tts.py:165: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  torch.load(ckpt_dir / \"s3gen.pt\", map_location=map_location), strict=False\n",
            "/usr/local/lib/python3.12/dist-packages/perth/perth_net/perth_net_implicit/checkpoint_manager.py:36: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(ckpts[-1], map_location=\"cpu\")\n",
            "loaded PerthNet (Implicit) at step 250,000\n",
            "\n",
            "Injecting LoRA layers...\n",
            "Injected 210 LoRA layers\n",
            "\n",
            "Loading LoRA weights from checkpoint...\n",
            "Loaded 420 LoRA parameters\n",
            "\n",
            "Merging LoRA weights into base model...\n",
            "\n",
            "Saving merged model to checkpoints_lora/merged_model...\n",
            "Saving model components...\n",
            "Saved merged model to checkpoints_lora/merged_model\n",
            "\n",
            "==================================================\n",
            "SUCCESS! Merged model saved.\n",
            "\n",
            "To use the merged model:\n",
            "  model = ChatterboxTTS.from_local('./checkpoints_lora/merged_model', device='cuda')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from safetensors.torch import save_file\n",
        "import os\n",
        "\n",
        "# ================= Cáº¤U HÃŒNH =================\n",
        "# ÄÆ°á»ng dáº«n Ä‘áº¿n thÆ° má»¥c chá»©a model (nhá»› sá»­a náº¿u báº¡n Ä‘á»•i tÃªn thÆ° má»¥c)\n",
        "model_dir = \"/content/drive/MyDrive/checkpoints_lora/merged_model\"\n",
        "\n",
        "# Danh sÃ¡ch cÃ¡c file cáº§n convert\n",
        "components = [\"e1\", \"e2\", \"e3\", \"e4\", \"e9\",\"t3_cfg\"]\n",
        "\n",
        "print(f\"ğŸ”„ Báº¯t Ä‘áº§u convert PT sang SAFETENSORS trong: {model_dir}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "for name in components:\n",
        "    pt_path = os.path.join(model_dir, f\"{name}.pt\")\n",
        "    safetensors_path = os.path.join(model_dir, f\"{name}.safetensors\")\n",
        "\n",
        "    # Chá»‰ xá»­ lÃ½ náº¿u file .pt tá»“n táº¡i\n",
        "    if os.path.exists(pt_path):\n",
        "        try:\n",
        "            print(f\"ğŸ“– Äang Ä‘á»c: {name}.pt ...\")\n",
        "\n",
        "            # 1. Load file .pt lÃªn CPU (Ä‘á»ƒ Ä‘á»¡ tá»‘n VRAM vÃ  trÃ¡nh lá»—i device)\n",
        "            # DÃ¹ng weights_only=False Ä‘á»ƒ load Ä‘Æ°á»£c háº¿t cÃ¡c cáº¥u trÃºc cÅ© náº¿u cÃ³\n",
        "            state_dict = torch.load(pt_path, map_location=\"cpu\", weights_only=False)\n",
        "\n",
        "            # 2. Kiá»ƒm tra xem dá»¯ liá»‡u load lÃªn cÃ³ Ä‘Ãºng chuáº©n dictionary khÃ´ng\n",
        "            if isinstance(state_dict, dict):\n",
        "                # Lá»c bá» cÃ¡c key khÃ´ng pháº£i lÃ  Tensor (safetensors chá»‰ há»— trá»£ lÆ°u Tensor)\n",
        "                # VÃ­ dá»¥: Ä‘Ã´i khi file pt lÆ°u cáº£ config dáº¡ng string/int, safetensors sáº½ lá»—i náº¿u lÆ°u cÃ¡i Ä‘Ã³\n",
        "                clean_state_dict = {k: v for k, v in state_dict.items() if isinstance(v, torch.Tensor)}\n",
        "\n",
        "                # Náº¿u lá»c xong mÃ  bá»‹ máº¥t dá»¯ liá»‡u (vÃ­ dá»¥ s3gen.pt chá»©a biáº¿n non-tensor)\n",
        "                if len(clean_state_dict) < len(state_dict):\n",
        "                    print(f\"âš ï¸ Cáº£nh bÃ¡o: ÄÃ£ loáº¡i bá» {len(state_dict) - len(clean_state_dict)} key khÃ´ng pháº£i Tensor trong {name}.\")\n",
        "\n",
        "                # 3. LÆ°u sang .safetensors\n",
        "                print(f\"ğŸ’¾ Äang lÆ°u: {name}.safetensors ...\")\n",
        "                save_file(clean_state_dict, safetensors_path)\n",
        "                print(f\"âœ… Xong: {safetensors_path}\")\n",
        "            else:\n",
        "                print(f\"âŒ Lá»—i: File {name}.pt khÃ´ng chá»©a state_dict (dictionary), khÃ´ng thá»ƒ convert sang safetensors.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Lá»—i khi xá»­ lÃ½ {name}: {e}\")\n",
        "    else:\n",
        "        print(f\"ğŸš« Bá» qua: KhÃ´ng tÃ¬m tháº¥y file {name}.pt\")\n",
        "\n",
        "print(\"-\" * 50)\n",
        "print(\"ğŸ‰ HoÃ n táº¥t quÃ¡ trÃ¬nh chuyá»ƒn Ä‘á»•i!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcgHwL_GdQQt",
        "outputId": "494ce677-cc5a-4698-c451-3a8b85ae92cd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”„ Báº¯t Ä‘áº§u convert PT sang SAFETENSORS trong: /content/drive/MyDrive/checkpoints_lora/merged_model\n",
            "--------------------------------------------------\n",
            "ğŸ“– Äang Ä‘á»c: e1.pt ...\n",
            "ğŸ’¾ Äang lÆ°u: e1.safetensors ...\n",
            "âœ… Xong: /content/drive/MyDrive/checkpoints_lora/merged_model/e1.safetensors\n",
            "ğŸ“– Äang Ä‘á»c: e2.pt ...\n",
            "ğŸ’¾ Äang lÆ°u: e2.safetensors ...\n",
            "âœ… Xong: /content/drive/MyDrive/checkpoints_lora/merged_model/e2.safetensors\n",
            "ğŸ“– Äang Ä‘á»c: e3.pt ...\n",
            "ğŸ’¾ Äang lÆ°u: e3.safetensors ...\n",
            "âœ… Xong: /content/drive/MyDrive/checkpoints_lora/merged_model/e3.safetensors\n",
            "ğŸ“– Äang Ä‘á»c: e4.pt ...\n",
            "ğŸ’¾ Äang lÆ°u: e4.safetensors ...\n",
            "âœ… Xong: /content/drive/MyDrive/checkpoints_lora/merged_model/e4.safetensors\n",
            "ğŸ“– Äang Ä‘á»c: e9.pt ...\n",
            "ğŸ’¾ Äang lÆ°u: e9.safetensors ...\n",
            "âœ… Xong: /content/drive/MyDrive/checkpoints_lora/merged_model/e9.safetensors\n",
            "ğŸ“– Äang Ä‘á»c: t3_cfg.pt ...\n",
            "ğŸ’¾ Äang lÆ°u: t3_cfg.safetensors ...\n",
            "âœ… Xong: /content/drive/MyDrive/checkpoints_lora/merged_model/t3_cfg.safetensors\n",
            "--------------------------------------------------\n",
            "ğŸ‰ HoÃ n táº¥t quÃ¡ trÃ¬nh chuyá»ƒn Ä‘á»•i!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell cháº¡y finetune (copy-paste nguyÃªn khá»‘i nÃ y vÃ o Colab)\n",
        "%cd /content/chatterbox-finetuning\n",
        "!python src/finetune_t3.py \\\n",
        "  --output_dir \"/content/drive/MyDrive/checkpoints/chatterbox_vietnamese_multispeaker_v3\" \\\n",
        "  --local_model_dir /content/chatterbox-finetuning/viterbox \\\n",
        "  \\\n",
        "  --dataset_dir \"/content/drive/MyDrive/Thien/splitthienfinal\" \\\n",
        "  --metadata_file  \"/content/drive/MyDrive/Thien/splitthienfinal/cluster_1.csv\" \\\n",
        "  \\\n",
        "  --train_split_name train \\\n",
        "  --eval_split_size 0.02 \\\n",
        "  --text_column_name text \\\n",
        "  --audio_column_name audio_file \\\n",
        "  \\\n",
        "  --num_train_epochs 10 \\\n",
        "  --per_device_train_batch_size 8 \\\n",
        "  --per_device_eval_batch_size 32 \\\n",
        "  --gradient_accumulation_steps 1 \\\n",
        "  --learning_rate 5e-5 \\\n",
        "  --weight_decay 0.0 \\\n",
        "  --warmup_steps 1000 \\\n",
        "  --lr_scheduler_type cosine \\\n",
        "  --logging_steps 10 \\\n",
        "  --save_steps 1000 \\\n",
        "  --save_total_limit 5 \\\n",
        "  --eval_steps 1000 \\\n",
        "  --evaluation_strategy steps \\\n",
        "  --save_strategy steps \\\n",
        "  \\\n",
        "  --fp16 True \\\n",
        "  --bf16 False \\\n",
        "  --dataloader_num_workers 8 \\\n",
        "  --dataloader_pin_memory True \\\n",
        "  --preprocessing_num_workers 6 \\\n",
        "  \\\n",
        "  --freeze_voice_encoder True \\\n",
        "  --freeze_s3gen True \\\n",
        "  \\\n",
        "  --max_text_len 280 \\\n",
        "  --max_speech_len 950 \\\n",
        "  --audio_prompt_duration_s 3.0 \\\n",
        "  \\\n",
        "  --report_to tensorboard \\\n",
        "  --seed 42 \\\n",
        "  --do_train True \\\n",
        "  --do_eval True \\\n",
        "  --early_stopping_patience 8 \\\n",
        "  --load_best_model_at_end True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dq205tAhGWqF",
        "outputId": "65485c1e-0099-4c96-9fa0-eceda10022d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/chatterbox-finetuning\n",
            "2025-12-09 04:31:17.769393: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765254677.791441   44778 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765254677.798216   44778 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765254677.815242   44778 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765254677.815277   44778 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765254677.815280   44778 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765254677.815283   44778 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "12/09/2025 04:31:27 - INFO - __main__ - Training/evaluation parameters CustomTrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=8,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "early_stopping_patience=8,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=1000,\n",
            "eval_strategy=IntervalStrategy.STEPS,\n",
            "eval_use_gather_object=False,\n",
            "evaluation_strategy=steps,\n",
            "fp16=True,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/content/drive/MyDrive/checkpoints/chatterbox_vietnamese_multispeaker_v3/runs/Dec09_04-31-27_f3f3f36cdfd2,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=10,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=SchedulerType.COSINE,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=10.0,\n",
            "optim=OptimizerNames.ADAMW_TORCH,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=/content/drive/MyDrive/checkpoints/chatterbox_vietnamese_multispeaker_v3,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=32,\n",
            "per_device_train_batch_size=8,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=/content/drive/MyDrive/checkpoints/chatterbox_vietnamese_multispeaker_v3,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=1000,\n",
            "save_strategy=IntervalStrategy.STEPS,\n",
            "save_total_limit=5,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=1000,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "12/09/2025 04:31:27 - INFO - __main__ - Model parameters ModelArguments(model_name_or_path=None, local_model_dir='/content/chatterbox-finetuning/viterbox', cache_dir=None, freeze_voice_encoder=True, freeze_s3gen=True)\n",
            "12/09/2025 04:31:27 - INFO - __main__ - Data parameters DataArguments(dataset_dir='/content/drive/MyDrive/Thien/splitthienfinal', metadata_file='/content/drive/MyDrive/Thien/splitthienfinal/cluster_1.csv', dataset_name=None, dataset_config_name=None, train_split_name='train', eval_split_name='validation', text_column_name='text', audio_column_name='audio_file', max_text_len=280, max_speech_len=950, audio_prompt_duration_s=3.0, eval_split_size=0.02, preprocessing_num_workers=6, ignore_verifications=False)\n",
            "12/09/2025 04:31:27 - INFO - __main__ - !!! DETECTED LOCAL MODEL - APPLYING VOCAB SIZE PATCH !!!\n",
            "12/09/2025 04:31:27 - INFO - __main__ - Forced T3Config.text_tokens_dict_size to 2549\n",
            "12/09/2025 04:31:27 - INFO - __main__ - Loading ChatterboxTTS model...\n",
            "12/09/2025 04:31:27 - INFO - __main__ - Loading model from local directory: /content/chatterbox-finetuning/viterbox\n",
            "/usr/local/lib/python3.12/dist-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.\n",
            "  deprecate(\"LoRACompatibleLinear\", \"1.0.0\", deprecation_message)\n",
            "12/09/2025 04:31:38 - INFO - root - input frame rate=25\n",
            "/usr/local/lib/python3.12/dist-packages/perth/perth_net/perth_net_implicit/checkpoint_manager.py:36: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(ckpts[-1], map_location=\"cpu\")\n",
            "loaded PerthNet (Implicit) at step 250,000\n",
            "12/09/2025 04:31:38 - INFO - __main__ - Voice Encoder frozen.\n",
            "12/09/2025 04:31:38 - INFO - __main__ - S3Gen model frozen.\n",
            "12/09/2025 04:31:38 - INFO - __main__ - T3 model set to trainable.\n",
            "12/09/2025 04:31:38 - INFO - __main__ - Loading and processing dataset...\n",
            "12/09/2025 04:31:39 - WARNING - __main__ - Audio file not found: /content/drive/MyDrive/Thien/splitthienfinal/audio_file (line 1). Skipping.\n",
            "12/09/2025 04:31:43 - INFO - __main__ - *** Training T3 model ***\n",
            "  0% 0/18320 [00:00<?, ?it/s]/usr/lib/python3.12/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
            "  self.gen = func(*args, **kwds)\n",
            "{'loss': 10.0151, 'grad_norm': 30.5674991607666, 'learning_rate': 4.5e-07, 'epoch': 0.01}\n",
            "{'loss': 9.5695, 'grad_norm': 28.93320083618164, 'learning_rate': 9e-07, 'epoch': 0.01}\n",
            "{'loss': 8.9886, 'grad_norm': 27.996322631835938, 'learning_rate': 1.4000000000000001e-06, 'epoch': 0.02}\n",
            "{'loss': 8.451, 'grad_norm': 22.4848575592041, 'learning_rate': 1.9e-06, 'epoch': 0.02}\n",
            "{'loss': 7.7315, 'grad_norm': 15.507763862609863, 'learning_rate': 2.4000000000000003e-06, 'epoch': 0.03}\n",
            "{'loss': 7.2396, 'grad_norm': 11.179933547973633, 'learning_rate': 2.9e-06, 'epoch': 0.03}\n",
            "{'loss': 7.0938, 'grad_norm': 19.049562454223633, 'learning_rate': 3.4000000000000005e-06, 'epoch': 0.04}\n",
            "{'loss': 6.3482, 'grad_norm': 8.28913402557373, 'learning_rate': 3.9e-06, 'epoch': 0.04}\n",
            "{'loss': 6.3479, 'grad_norm': 11.842058181762695, 'learning_rate': 4.35e-06, 'epoch': 0.05}\n",
            "{'loss': 6.502, 'grad_norm': 12.418188095092773, 'learning_rate': 4.85e-06, 'epoch': 0.05}\n",
            "{'loss': 5.8523, 'grad_norm': 15.536820411682129, 'learning_rate': 5.3500000000000004e-06, 'epoch': 0.06}\n",
            "{'loss': 5.5926, 'grad_norm': 7.0545268058776855, 'learning_rate': 5.850000000000001e-06, 'epoch': 0.07}\n",
            "{'loss': 5.8951, 'grad_norm': 16.8601016998291, 'learning_rate': 6.35e-06, 'epoch': 0.07}\n",
            "{'loss': 5.8831, 'grad_norm': 10.196013450622559, 'learning_rate': 6.8500000000000005e-06, 'epoch': 0.08}\n",
            "{'loss': 5.2255, 'grad_norm': 19.987581253051758, 'learning_rate': 7.35e-06, 'epoch': 0.08}\n",
            "{'loss': 5.1765, 'grad_norm': 12.37791919708252, 'learning_rate': 7.850000000000001e-06, 'epoch': 0.09}\n",
            "{'loss': 5.1227, 'grad_norm': 13.296717643737793, 'learning_rate': 8.350000000000001e-06, 'epoch': 0.09}\n",
            "{'loss': 5.5943, 'grad_norm': 9.715102195739746, 'learning_rate': 8.85e-06, 'epoch': 0.1}\n",
            "{'loss': 5.6943, 'grad_norm': 16.502273559570312, 'learning_rate': 9.35e-06, 'epoch': 0.1}\n",
            "{'loss': 5.0265, 'grad_norm': 12.62193775177002, 'learning_rate': 9.85e-06, 'epoch': 0.11}\n",
            "{'loss': 5.0556, 'grad_norm': 6.764039039611816, 'learning_rate': 1.035e-05, 'epoch': 0.11}\n",
            "{'loss': 4.9985, 'grad_norm': 10.212555885314941, 'learning_rate': 1.0850000000000001e-05, 'epoch': 0.12}\n",
            "{'loss': 4.4582, 'grad_norm': 21.72930908203125, 'learning_rate': 1.1350000000000001e-05, 'epoch': 0.13}\n",
            "{'loss': 5.3336, 'grad_norm': 13.206860542297363, 'learning_rate': 1.185e-05, 'epoch': 0.13}\n",
            "{'loss': 4.5964, 'grad_norm': 15.889683723449707, 'learning_rate': 1.235e-05, 'epoch': 0.14}\n",
            "{'loss': 4.6431, 'grad_norm': 10.94765853881836, 'learning_rate': 1.285e-05, 'epoch': 0.14}\n",
            "{'loss': 4.929, 'grad_norm': 13.774492263793945, 'learning_rate': 1.3350000000000001e-05, 'epoch': 0.15}\n",
            "{'loss': 5.0927, 'grad_norm': 16.496009826660156, 'learning_rate': 1.3850000000000001e-05, 'epoch': 0.15}\n",
            "{'loss': 5.0117, 'grad_norm': 9.15996265411377, 'learning_rate': 1.435e-05, 'epoch': 0.16}\n",
            "{'loss': 4.5251, 'grad_norm': 16.390483856201172, 'learning_rate': 1.485e-05, 'epoch': 0.16}\n",
            "{'loss': 5.0212, 'grad_norm': 14.554242134094238, 'learning_rate': 1.535e-05, 'epoch': 0.17}\n",
            "{'loss': 4.5394, 'grad_norm': 16.04909896850586, 'learning_rate': 1.5850000000000002e-05, 'epoch': 0.17}\n",
            "{'loss': 4.7114, 'grad_norm': 12.271923065185547, 'learning_rate': 1.635e-05, 'epoch': 0.18}\n",
            "{'loss': 4.9596, 'grad_norm': 12.128900527954102, 'learning_rate': 1.6850000000000003e-05, 'epoch': 0.19}\n",
            "{'loss': 5.2445, 'grad_norm': 9.41102409362793, 'learning_rate': 1.7349999999999998e-05, 'epoch': 0.19}\n",
            "{'loss': 4.7681, 'grad_norm': 13.970725059509277, 'learning_rate': 1.785e-05, 'epoch': 0.2}\n",
            "{'loss': 4.5093, 'grad_norm': 5.760333061218262, 'learning_rate': 1.8350000000000002e-05, 'epoch': 0.2}\n",
            "{'loss': 4.4652, 'grad_norm': 8.403614044189453, 'learning_rate': 1.885e-05, 'epoch': 0.21}\n",
            "{'loss': 4.4237, 'grad_norm': 9.230603218078613, 'learning_rate': 1.9350000000000003e-05, 'epoch': 0.21}\n",
            "{'loss': 4.9199, 'grad_norm': 11.371415138244629, 'learning_rate': 1.985e-05, 'epoch': 0.22}\n",
            "{'loss': 4.5764, 'grad_norm': 11.409435272216797, 'learning_rate': 2.035e-05, 'epoch': 0.22}\n",
            "{'loss': 4.4465, 'grad_norm': 10.357040405273438, 'learning_rate': 2.085e-05, 'epoch': 0.23}\n",
            "{'loss': 4.5155, 'grad_norm': 29.517990112304688, 'learning_rate': 2.135e-05, 'epoch': 0.23}\n",
            "{'loss': 5.4157, 'grad_norm': 6.929537296295166, 'learning_rate': 2.1850000000000003e-05, 'epoch': 0.24}\n",
            "{'loss': 4.9284, 'grad_norm': 11.640800476074219, 'learning_rate': 2.235e-05, 'epoch': 0.25}\n",
            "{'loss': 4.7174, 'grad_norm': 7.823597431182861, 'learning_rate': 2.2850000000000003e-05, 'epoch': 0.25}\n",
            "{'loss': 4.9376, 'grad_norm': 9.402119636535645, 'learning_rate': 2.3350000000000002e-05, 'epoch': 0.26}\n",
            "{'loss': 4.479, 'grad_norm': 14.050817489624023, 'learning_rate': 2.385e-05, 'epoch': 0.26}\n",
            "{'loss': 4.7185, 'grad_norm': 10.191329956054688, 'learning_rate': 2.435e-05, 'epoch': 0.27}\n",
            "{'loss': 4.4037, 'grad_norm': 9.397204399108887, 'learning_rate': 2.485e-05, 'epoch': 0.27}\n",
            "{'loss': 4.6243, 'grad_norm': 14.481667518615723, 'learning_rate': 2.5350000000000003e-05, 'epoch': 0.28}\n",
            "{'loss': 5.0983, 'grad_norm': 15.794512748718262, 'learning_rate': 2.585e-05, 'epoch': 0.28}\n",
            "{'loss': 4.3725, 'grad_norm': 7.675095558166504, 'learning_rate': 2.6350000000000004e-05, 'epoch': 0.29}\n",
            "{'loss': 4.5151, 'grad_norm': 8.529963493347168, 'learning_rate': 2.6850000000000002e-05, 'epoch': 0.29}\n",
            "{'loss': 4.7276, 'grad_norm': 13.976667404174805, 'learning_rate': 2.7350000000000004e-05, 'epoch': 0.3}\n",
            "{'loss': 4.5818, 'grad_norm': 7.73676061630249, 'learning_rate': 2.7850000000000003e-05, 'epoch': 0.31}\n",
            "{'loss': 4.6208, 'grad_norm': 11.03590202331543, 'learning_rate': 2.8349999999999998e-05, 'epoch': 0.31}\n",
            "{'loss': 4.3939, 'grad_norm': 9.56251335144043, 'learning_rate': 2.885e-05, 'epoch': 0.32}\n",
            "{'loss': 4.9314, 'grad_norm': 13.127801895141602, 'learning_rate': 2.935e-05, 'epoch': 0.32}\n",
            "{'loss': 4.9103, 'grad_norm': 12.919090270996094, 'learning_rate': 2.985e-05, 'epoch': 0.33}\n",
            "{'loss': 5.0681, 'grad_norm': 10.221813201904297, 'learning_rate': 3.035e-05, 'epoch': 0.33}\n",
            "{'loss': 5.0696, 'grad_norm': 9.44868278503418, 'learning_rate': 3.0850000000000004e-05, 'epoch': 0.34}\n",
            "{'loss': 4.4503, 'grad_norm': 12.62839126586914, 'learning_rate': 3.135e-05, 'epoch': 0.34}\n",
            "{'loss': 4.367, 'grad_norm': 16.916507720947266, 'learning_rate': 3.185e-05, 'epoch': 0.35}\n",
            "{'loss': 4.6567, 'grad_norm': 16.11443328857422, 'learning_rate': 3.235e-05, 'epoch': 0.35}\n",
            "{'loss': 4.9613, 'grad_norm': 12.692509651184082, 'learning_rate': 3.2850000000000006e-05, 'epoch': 0.36}\n",
            "{'loss': 4.7068, 'grad_norm': 15.440051078796387, 'learning_rate': 3.3350000000000004e-05, 'epoch': 0.37}\n",
            "{'loss': 4.2366, 'grad_norm': 13.383485794067383, 'learning_rate': 3.385e-05, 'epoch': 0.37}\n",
            "{'loss': 4.5362, 'grad_norm': 10.675542831420898, 'learning_rate': 3.435e-05, 'epoch': 0.38}\n",
            "{'loss': 4.3981, 'grad_norm': 9.262401580810547, 'learning_rate': 3.485e-05, 'epoch': 0.38}\n",
            "{'loss': 4.8775, 'grad_norm': 7.735817909240723, 'learning_rate': 3.535e-05, 'epoch': 0.39}\n",
            "{'loss': 5.2577, 'grad_norm': 7.048430442810059, 'learning_rate': 3.585e-05, 'epoch': 0.39}\n",
            "{'loss': 4.8144, 'grad_norm': 10.545140266418457, 'learning_rate': 3.635e-05, 'epoch': 0.4}\n",
            "{'loss': 4.7369, 'grad_norm': 8.837725639343262, 'learning_rate': 3.685e-05, 'epoch': 0.4}\n",
            "{'loss': 4.922, 'grad_norm': 9.218345642089844, 'learning_rate': 3.735e-05, 'epoch': 0.41}\n",
            "{'loss': 3.8956, 'grad_norm': 24.58729362487793, 'learning_rate': 3.7850000000000005e-05, 'epoch': 0.41}\n",
            "{'loss': 4.6627, 'grad_norm': 10.028022766113281, 'learning_rate': 3.8350000000000004e-05, 'epoch': 0.42}\n",
            "{'loss': 5.2345, 'grad_norm': 11.489256858825684, 'learning_rate': 3.885e-05, 'epoch': 0.43}\n",
            "{'loss': 4.0618, 'grad_norm': 4.71713924407959, 'learning_rate': 3.935e-05, 'epoch': 0.43}\n",
            "{'loss': 5.1084, 'grad_norm': 15.05477237701416, 'learning_rate': 3.9850000000000006e-05, 'epoch': 0.44}\n",
            "{'loss': 4.3722, 'grad_norm': 10.616214752197266, 'learning_rate': 4.0350000000000005e-05, 'epoch': 0.44}\n",
            "{'loss': 4.6933, 'grad_norm': 7.06890869140625, 'learning_rate': 4.085e-05, 'epoch': 0.45}\n",
            "{'loss': 4.4818, 'grad_norm': 8.485182762145996, 'learning_rate': 4.135e-05, 'epoch': 0.45}\n",
            "{'loss': 5.3216, 'grad_norm': 5.430094242095947, 'learning_rate': 4.185e-05, 'epoch': 0.46}\n",
            "{'loss': 4.3321, 'grad_norm': 11.110535621643066, 'learning_rate': 4.235e-05, 'epoch': 0.46}\n",
            "{'loss': 3.3305, 'grad_norm': 33.84062576293945, 'learning_rate': 4.285e-05, 'epoch': 0.47}\n",
            "{'loss': 4.6658, 'grad_norm': 13.024904251098633, 'learning_rate': 4.335e-05, 'epoch': 0.47}\n",
            "{'loss': 4.0118, 'grad_norm': 10.722946166992188, 'learning_rate': 4.385e-05, 'epoch': 0.48}\n",
            "{'loss': 4.7453, 'grad_norm': 21.844833374023438, 'learning_rate': 4.435e-05, 'epoch': 0.49}\n",
            "{'loss': 5.3455, 'grad_norm': 13.680692672729492, 'learning_rate': 4.4850000000000006e-05, 'epoch': 0.49}\n",
            "{'loss': 5.3769, 'grad_norm': 10.305989265441895, 'learning_rate': 4.5350000000000005e-05, 'epoch': 0.5}\n",
            "{'loss': 4.5939, 'grad_norm': 9.708149909973145, 'learning_rate': 4.585e-05, 'epoch': 0.5}\n",
            "{'loss': 5.235, 'grad_norm': 18.723236083984375, 'learning_rate': 4.635e-05, 'epoch': 0.51}\n",
            "{'loss': 4.2886, 'grad_norm': 4.267135143280029, 'learning_rate': 4.685000000000001e-05, 'epoch': 0.51}\n",
            "{'loss': 4.2832, 'grad_norm': 10.963831901550293, 'learning_rate': 4.735e-05, 'epoch': 0.52}\n",
            "{'loss': 4.5029, 'grad_norm': 6.894502639770508, 'learning_rate': 4.785e-05, 'epoch': 0.52}\n",
            "{'loss': 5.0039, 'grad_norm': 8.797431945800781, 'learning_rate': 4.835e-05, 'epoch': 0.53}\n",
            "{'loss': 4.9521, 'grad_norm': 9.63923454284668, 'learning_rate': 4.885e-05, 'epoch': 0.53}\n",
            "{'loss': 4.3156, 'grad_norm': 9.137103080749512, 'learning_rate': 4.935e-05, 'epoch': 0.54}\n",
            "{'loss': 5.0527, 'grad_norm': 9.1873197555542, 'learning_rate': 4.9850000000000006e-05, 'epoch': 0.55}\n",
            "  5% 1000/18320 [24:25<3:05:59,  1.55it/s]\n",
            "  0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            " 20% 2/10 [00:00<00:00,  8.96it/s]\u001b[A\n",
            " 30% 3/10 [00:00<00:00,  8.02it/s]\u001b[A\n",
            " 40% 4/10 [00:00<00:00,  7.19it/s]\u001b[A\n",
            " 50% 5/10 [00:00<00:00,  6.68it/s]\u001b[A\n",
            " 60% 6/10 [00:00<00:00,  6.12it/s]\u001b[A\n",
            " 70% 7/10 [00:01<00:00,  5.85it/s]\u001b[A\n",
            " 80% 8/10 [00:23<00:14,  7.10s/it]\u001b[A\n",
            " 90% 9/10 [00:23<00:04,  4.95s/it]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 5.2046403884887695, 'eval_runtime': 83.2482, 'eval_samples_per_second': 3.604, 'eval_steps_per_second': 0.12, 'epoch': 0.55}\n",
            "  5% 1000/18320 [25:49<3:05:59,  1.55it/s]\n",
            "100% 10/10 [00:23<00:00,  3.50s/it]\u001b[A\n",
            "                                   \u001b[A/usr/lib/python3.12/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
            "  self.gen = func(*args, **kwds)\n",
            "{'loss': 4.202, 'grad_norm': 14.312390327453613, 'learning_rate': 4.999997984837816e-05, 'epoch': 0.55}\n",
            "{'loss': 5.2521, 'grad_norm': 6.9807329177856445, 'learning_rate': 4.999988114663511e-05, 'epoch': 0.56}\n",
            "{'loss': 4.3353, 'grad_norm': 21.283729553222656, 'learning_rate': 4.9999700193776874e-05, 'epoch': 0.56}\n",
            "{'loss': 4.845, 'grad_norm': 15.59638500213623, 'learning_rate': 4.9999436990398816e-05, 'epoch': 0.57}\n",
            "{'loss': 4.5485, 'grad_norm': 8.590072631835938, 'learning_rate': 4.999909153736687e-05, 'epoch': 0.57}\n",
            "{'loss': 4.5398, 'grad_norm': 11.111745834350586, 'learning_rate': 4.9998663835817606e-05, 'epoch': 0.58}\n",
            "{'loss': 4.6617, 'grad_norm': 7.792832851409912, 'learning_rate': 4.9998153887158196e-05, 'epoch': 0.58}\n",
            "{'loss': 4.4546, 'grad_norm': 8.82963752746582, 'learning_rate': 4.999756169306638e-05, 'epoch': 0.59}\n",
            "{'loss': 5.0873, 'grad_norm': 7.5953288078308105, 'learning_rate': 4.999688725549054e-05, 'epoch': 0.59}\n",
            "{'loss': 4.7238, 'grad_norm': 7.870885372161865, 'learning_rate': 4.9996130576649605e-05, 'epoch': 0.6}\n",
            "{'loss': 4.9408, 'grad_norm': 8.767759323120117, 'learning_rate': 4.999529165903308e-05, 'epoch': 0.61}\n",
            "{'loss': 5.2652, 'grad_norm': 9.000356674194336, 'learning_rate': 4.999437050540107e-05, 'epoch': 0.61}\n",
            "{'loss': 4.7285, 'grad_norm': 10.900090217590332, 'learning_rate': 4.999336711878422e-05, 'epoch': 0.62}\n",
            "{'loss': 4.552, 'grad_norm': 8.531817436218262, 'learning_rate': 4.999228150248374e-05, 'epoch': 0.62}\n",
            "{'loss': 4.3836, 'grad_norm': 6.4564666748046875, 'learning_rate': 4.999111366007136e-05, 'epoch': 0.63}\n",
            "{'loss': 4.9465, 'grad_norm': 8.816758155822754, 'learning_rate': 4.9989863595389365e-05, 'epoch': 0.63}\n",
            "{'loss': 5.1689, 'grad_norm': 12.43761920928955, 'learning_rate': 4.998853131255053e-05, 'epoch': 0.64}\n",
            "{'loss': 4.7438, 'grad_norm': 8.068570137023926, 'learning_rate': 4.998711681593817e-05, 'epoch': 0.64}\n",
            "{'loss': 5.1648, 'grad_norm': 19.674869537353516, 'learning_rate': 4.998562011020603e-05, 'epoch': 0.65}\n",
            "{'loss': 5.0031, 'grad_norm': 8.190468788146973, 'learning_rate': 4.9984041200278386e-05, 'epoch': 0.66}\n",
            "{'loss': 4.272, 'grad_norm': 7.2784247398376465, 'learning_rate': 4.9982380091349945e-05, 'epoch': 0.66}\n",
            "{'loss': 4.6764, 'grad_norm': 10.191502571105957, 'learning_rate': 4.998063678888585e-05, 'epoch': 0.67}\n",
            "{'loss': 4.4618, 'grad_norm': 16.399686813354492, 'learning_rate': 4.997881129862166e-05, 'epoch': 0.67}\n",
            "{'loss': 4.1335, 'grad_norm': 10.762618064880371, 'learning_rate': 4.997690362656337e-05, 'epoch': 0.68}\n",
            "{'loss': 4.1307, 'grad_norm': 5.50780725479126, 'learning_rate': 4.9974913778987325e-05, 'epoch': 0.68}\n",
            "{'loss': 5.0312, 'grad_norm': 8.646710395812988, 'learning_rate': 4.9972841762440244e-05, 'epoch': 0.69}\n",
            "{'loss': 4.9295, 'grad_norm': 3.5264875888824463, 'learning_rate': 4.997068758373918e-05, 'epoch': 0.69}\n",
            "{'loss': 4.6483, 'grad_norm': 6.140043258666992, 'learning_rate': 4.9968451249971526e-05, 'epoch': 0.7}\n",
            "{'loss': 4.9723, 'grad_norm': 7.585393905639648, 'learning_rate': 4.9966132768494945e-05, 'epoch': 0.7}\n",
            "{'loss': 5.2848, 'grad_norm': 11.191919326782227, 'learning_rate': 4.996373214693738e-05, 'epoch': 0.71}\n",
            "{'loss': 5.0041, 'grad_norm': 5.979341506958008, 'learning_rate': 4.996124939319702e-05, 'epoch': 0.72}\n",
            "{'loss': 4.1141, 'grad_norm': 3.7727296352386475, 'learning_rate': 4.995868451544228e-05, 'epoch': 0.72}\n",
            "{'loss': 4.3962, 'grad_norm': 7.666863441467285, 'learning_rate': 4.9956037522111754e-05, 'epoch': 0.73}\n",
            "{'loss': 4.4188, 'grad_norm': 11.330422401428223, 'learning_rate': 4.9953308421914216e-05, 'epoch': 0.73}\n",
            "{'loss': 4.8555, 'grad_norm': 13.560159683227539, 'learning_rate': 4.9950497223828565e-05, 'epoch': 0.74}\n",
            "{'loss': 4.3632, 'grad_norm': 7.059351444244385, 'learning_rate': 4.9947603937103826e-05, 'epoch': 0.74}\n",
            "{'loss': 4.9744, 'grad_norm': 9.79247760772705, 'learning_rate': 4.994462857125907e-05, 'epoch': 0.75}\n",
            "{'loss': 4.7823, 'grad_norm': 3.3031833171844482, 'learning_rate': 4.994157113608343e-05, 'epoch': 0.75}\n",
            "{'loss': 5.3948, 'grad_norm': 7.846823215484619, 'learning_rate': 4.993843164163607e-05, 'epoch': 0.76}\n",
            "{'loss': 4.6899, 'grad_norm': 8.985222816467285, 'learning_rate': 4.99352100982461e-05, 'epoch': 0.76}\n",
            "{'loss': 3.9767, 'grad_norm': 15.34499454498291, 'learning_rate': 4.993190651651259e-05, 'epoch': 0.77}\n",
            "{'loss': 4.7263, 'grad_norm': 9.495234489440918, 'learning_rate': 4.9928520907304535e-05, 'epoch': 0.78}\n",
            "{'loss': 5.3296, 'grad_norm': 7.940848350524902, 'learning_rate': 4.992505328176079e-05, 'epoch': 0.78}\n",
            "{'loss': 4.6595, 'grad_norm': 6.989585876464844, 'learning_rate': 4.9921503651290045e-05, 'epoch': 0.79}\n",
            "{'loss': 4.592, 'grad_norm': 2.9992270469665527, 'learning_rate': 4.99178720275708e-05, 'epoch': 0.79}\n",
            "{'loss': 4.8945, 'grad_norm': 8.001864433288574, 'learning_rate': 4.991415842255132e-05, 'epoch': 0.8}\n",
            "{'loss': 4.9821, 'grad_norm': 7.994268894195557, 'learning_rate': 4.9910362848449585e-05, 'epoch': 0.8}\n",
            "{'loss': 4.4573, 'grad_norm': 9.636749267578125, 'learning_rate': 4.990648531775327e-05, 'epoch': 0.81}\n",
            "{'loss': 4.7147, 'grad_norm': 11.459405899047852, 'learning_rate': 4.990252584321968e-05, 'epoch': 0.81}\n",
            "{'loss': 3.9853, 'grad_norm': 9.138761520385742, 'learning_rate': 4.989848443787572e-05, 'epoch': 0.82}\n",
            "{'loss': 4.6418, 'grad_norm': 6.399325847625732, 'learning_rate': 4.989436111501786e-05, 'epoch': 0.82}\n",
            "{'loss': 4.0795, 'grad_norm': 9.555757522583008, 'learning_rate': 4.9890155888212087e-05, 'epoch': 0.83}\n",
            "{'loss': 4.3197, 'grad_norm': 18.95699691772461, 'learning_rate': 4.9885868771293845e-05, 'epoch': 0.84}\n",
            "{'loss': 4.2451, 'grad_norm': 2.6624131202697754, 'learning_rate': 4.9881499778368e-05, 'epoch': 0.84}\n",
            "{'loss': 4.8141, 'grad_norm': 3.5097098350524902, 'learning_rate': 4.987704892380881e-05, 'epoch': 0.85}\n",
            "{'loss': 4.3552, 'grad_norm': 11.690054893493652, 'learning_rate': 4.987251622225986e-05, 'epoch': 0.85}\n",
            "{'loss': 4.9924, 'grad_norm': 8.433269500732422, 'learning_rate': 4.9867901688634e-05, 'epoch': 0.86}\n",
            "{'loss': 4.4848, 'grad_norm': 11.08530044555664, 'learning_rate': 4.9863205338113334e-05, 'epoch': 0.86}\n",
            "{'loss': 5.2117, 'grad_norm': 8.288612365722656, 'learning_rate': 4.985842718614913e-05, 'epoch': 0.87}\n",
            "{'loss': 3.4832, 'grad_norm': 11.940629005432129, 'learning_rate': 4.98535672484618e-05, 'epoch': 0.87}\n",
            "{'loss': 5.0945, 'grad_norm': 12.366598129272461, 'learning_rate': 4.984862554104083e-05, 'epoch': 0.88}\n",
            "{'loss': 5.0841, 'grad_norm': 9.519591331481934, 'learning_rate': 4.984360208014474e-05, 'epoch': 0.88}\n",
            "{'loss': 4.7775, 'grad_norm': 10.676669120788574, 'learning_rate': 4.9838496882301003e-05, 'epoch': 0.89}\n",
            "{'loss': 4.7618, 'grad_norm': 13.106365203857422, 'learning_rate': 4.983330996430605e-05, 'epoch': 0.9}\n",
            "{'loss': 4.9178, 'grad_norm': 9.759515762329102, 'learning_rate': 4.982804134322513e-05, 'epoch': 0.9}\n",
            "{'loss': 3.9684, 'grad_norm': 7.047935962677002, 'learning_rate': 4.982269103639235e-05, 'epoch': 0.91}\n",
            "{'loss': 4.5832, 'grad_norm': 42.89775848388672, 'learning_rate': 4.981725906141053e-05, 'epoch': 0.91}\n",
            "{'loss': 5.3659, 'grad_norm': 10.083741188049316, 'learning_rate': 4.981174543615118e-05, 'epoch': 0.92}\n",
            "{'loss': 4.6977, 'grad_norm': 9.462592124938965, 'learning_rate': 4.9806150178754487e-05, 'epoch': 0.92}\n",
            "{'loss': 5.167, 'grad_norm': 9.218806266784668, 'learning_rate': 4.980047330762916e-05, 'epoch': 0.93}\n",
            "{'loss': 4.1794, 'grad_norm': 9.279716491699219, 'learning_rate': 4.979471484145246e-05, 'epoch': 0.93}\n",
            "{'loss': 5.1445, 'grad_norm': 6.765872955322266, 'learning_rate': 4.9788874799170086e-05, 'epoch': 0.94}\n",
            "{'loss': 4.6028, 'grad_norm': 17.524295806884766, 'learning_rate': 4.9782953199996126e-05, 'epoch': 0.94}\n",
            "{'loss': 4.6401, 'grad_norm': 10.44527530670166, 'learning_rate': 4.977695006341301e-05, 'epoch': 0.95}\n",
            "{'loss': 4.7471, 'grad_norm': 2.903377056121826, 'learning_rate': 4.97708654091714e-05, 'epoch': 0.96}\n",
            "{'loss': 4.4861, 'grad_norm': 6.922353744506836, 'learning_rate': 4.9764699257290193e-05, 'epoch': 0.96}\n",
            "{'loss': 4.7959, 'grad_norm': 8.749610900878906, 'learning_rate': 4.9758451628056384e-05, 'epoch': 0.97}\n",
            "{'loss': 2.9492, 'grad_norm': 7.554588317871094, 'learning_rate': 4.975212254202506e-05, 'epoch': 0.97}\n",
            "{'loss': 4.5998, 'grad_norm': 8.388688087463379, 'learning_rate': 4.974571202001929e-05, 'epoch': 0.98}\n",
            "{'loss': 4.1855, 'grad_norm': 3.16343092918396, 'learning_rate': 4.9739220083130085e-05, 'epoch': 0.98}\n",
            "{'loss': 4.4462, 'grad_norm': 11.30028247833252, 'learning_rate': 4.97326467527163e-05, 'epoch': 0.99}\n",
            "{'loss': 4.8332, 'grad_norm': 6.840768337249756, 'learning_rate': 4.972599205040459e-05, 'epoch': 0.99}\n",
            "{'loss': 4.4681, 'grad_norm': 3.0275022983551025, 'learning_rate': 4.9719255998089334e-05, 'epoch': 1.0}\n",
            "{'loss': 4.5904, 'grad_norm': 6.576897144317627, 'learning_rate': 4.9712438617932544e-05, 'epoch': 1.0}\n",
            "{'loss': 4.0077, 'grad_norm': 6.9002556800842285, 'learning_rate': 4.970553993236381e-05, 'epoch': 1.01}\n",
            "{'loss': 4.0991, 'grad_norm': 2.707737922668457, 'learning_rate': 4.969855996408022e-05, 'epoch': 1.02}\n",
            "{'loss': 4.4367, 'grad_norm': 3.537130117416382, 'learning_rate': 4.9691498736046306e-05, 'epoch': 1.02}\n",
            "{'loss': 3.838, 'grad_norm': 3.3791415691375732, 'learning_rate': 4.9684356271493915e-05, 'epoch': 1.03}\n",
            "{'loss': 3.9937, 'grad_norm': 12.996623039245605, 'learning_rate': 4.9677132593922196e-05, 'epoch': 1.03}\n",
            "{'loss': 4.3099, 'grad_norm': 9.744306564331055, 'learning_rate': 4.966982772709747e-05, 'epoch': 1.04}\n",
            "{'loss': 4.5194, 'grad_norm': 11.066889762878418, 'learning_rate': 4.966244169505322e-05, 'epoch': 1.04}\n",
            "{'loss': 4.0695, 'grad_norm': 11.501896858215332, 'learning_rate': 4.9654974522089906e-05, 'epoch': 1.05}\n",
            "{'loss': 3.6943, 'grad_norm': 10.191195487976074, 'learning_rate': 4.964742623277499e-05, 'epoch': 1.05}\n",
            "{'loss': 4.337, 'grad_norm': 6.884282112121582, 'learning_rate': 4.9639796851942785e-05, 'epoch': 1.06}\n",
            "{'loss': 3.4127, 'grad_norm': 8.117586135864258, 'learning_rate': 4.9632086404694436e-05, 'epoch': 1.06}\n",
            "{'loss': 3.433, 'grad_norm': 15.672459602355957, 'learning_rate': 4.9624294916397765e-05, 'epoch': 1.07}\n",
            "{'loss': 4.0274, 'grad_norm': 15.11746883392334, 'learning_rate': 4.9616422412687234e-05, 'epoch': 1.08}\n",
            "{'loss': 3.9621, 'grad_norm': 6.14378547668457, 'learning_rate': 4.960846891946387e-05, 'epoch': 1.08}\n",
            "{'loss': 3.4565, 'grad_norm': 8.736824035644531, 'learning_rate': 4.960043446289513e-05, 'epoch': 1.09}\n",
            "{'loss': 3.4241, 'grad_norm': 8.6072998046875, 'learning_rate': 4.9592319069414867e-05, 'epoch': 1.09}\n",
            " 11% 2000/18320 [50:20<6:37:06,  1.46s/it]\n",
            "  0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            " 20% 2/10 [00:00<00:00,  9.05it/s]\u001b[A\n",
            " 30% 3/10 [00:00<00:00,  8.05it/s]\u001b[A\n",
            " 40% 4/10 [00:00<00:00,  7.19it/s]\u001b[A\n",
            " 50% 5/10 [00:00<00:00,  6.69it/s]\u001b[A\n",
            " 60% 6/10 [00:00<00:00,  6.10it/s]\u001b[A\n",
            " 70% 7/10 [00:01<00:00,  5.86it/s]\u001b[A\n",
            " 80% 8/10 [00:24<00:14,  7.39s/it]\u001b[A\n",
            " 90% 9/10 [00:24<00:05,  5.16s/it]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 5.16682767868042, 'eval_runtime': 83.0324, 'eval_samples_per_second': 3.613, 'eval_steps_per_second': 0.12, 'epoch': 1.09}\n",
            " 11% 2000/18320 [51:43<6:37:06,  1.46s/it]\n",
            "100% 10/10 [00:24<00:00,  3.64s/it]\u001b[A\n",
            "                                   \u001b[A/usr/lib/python3.12/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
            "  self.gen = func(*args, **kwds)\n",
            "{'loss': 4.2444, 'grad_norm': 16.234424591064453, 'learning_rate': 4.958412276572321e-05, 'epoch': 1.1}\n",
            "{'loss': 4.2651, 'grad_norm': 11.68077564239502, 'learning_rate': 4.957584557878651e-05, 'epoch': 1.1}\n",
            "{'loss': 3.6651, 'grad_norm': 13.524856567382812, 'learning_rate': 4.9567487535837176e-05, 'epoch': 1.11}\n",
            "{'loss': 4.4801, 'grad_norm': 5.874415874481201, 'learning_rate': 4.955904866437371e-05, 'epoch': 1.11}\n",
            "{'loss': 3.973, 'grad_norm': 9.787975311279297, 'learning_rate': 4.955052899216048e-05, 'epoch': 1.12}\n",
            "{'loss': 4.0305, 'grad_norm': 12.281425476074219, 'learning_rate': 4.9541928547227734e-05, 'epoch': 1.12}\n",
            "{'loss': 3.7045, 'grad_norm': 8.360868453979492, 'learning_rate': 4.953324735787145e-05, 'epoch': 1.13}\n",
            "{'loss': 4.5154, 'grad_norm': 3.528988838195801, 'learning_rate': 4.952448545265327e-05, 'epoch': 1.14}\n",
            "{'loss': 4.4027, 'grad_norm': 8.08195686340332, 'learning_rate': 4.951564286040038e-05, 'epoch': 1.14}\n",
            "{'loss': 4.1233, 'grad_norm': 5.436433792114258, 'learning_rate': 4.9506719610205446e-05, 'epoch': 1.15}\n",
            "{'loss': 3.8334, 'grad_norm': 3.045555353164673, 'learning_rate': 4.949771573142651e-05, 'epoch': 1.15}\n",
            "{'loss': 4.5384, 'grad_norm': 11.416128158569336, 'learning_rate': 4.948863125368686e-05, 'epoch': 1.16}\n",
            "{'loss': 3.7022, 'grad_norm': 7.310249328613281, 'learning_rate': 4.947946620687497e-05, 'epoch': 1.16}\n",
            "{'loss': 4.1375, 'grad_norm': 6.2398505210876465, 'learning_rate': 4.947022062114441e-05, 'epoch': 1.17}\n",
            "{'loss': 3.9526, 'grad_norm': 9.900139808654785, 'learning_rate': 4.946089452691373e-05, 'epoch': 1.17}\n",
            "{'loss': 3.513, 'grad_norm': 8.595610618591309, 'learning_rate': 4.94514879548663e-05, 'epoch': 1.18}\n",
            "{'loss': 3.1545, 'grad_norm': 10.605183601379395, 'learning_rate': 4.944200093595034e-05, 'epoch': 1.18}\n",
            "{'loss': 4.3378, 'grad_norm': 3.0263478755950928, 'learning_rate': 4.9432433501378705e-05, 'epoch': 1.19}\n",
            "{'loss': 4.133, 'grad_norm': 14.105582237243652, 'learning_rate': 4.942278568262882e-05, 'epoch': 1.2}\n",
            "{'loss': 4.2423, 'grad_norm': 14.449403762817383, 'learning_rate': 4.941305751144262e-05, 'epoch': 1.2}\n",
            "{'loss': 4.597, 'grad_norm': 8.640861511230469, 'learning_rate': 4.940324901982635e-05, 'epoch': 1.21}\n",
            "{'loss': 3.8565, 'grad_norm': 16.83595085144043, 'learning_rate': 4.939336024005054e-05, 'epoch': 1.21}\n",
            "{'loss': 3.5634, 'grad_norm': 9.71105670928955, 'learning_rate': 4.938339120464987e-05, 'epoch': 1.22}\n",
            "{'loss': 4.35, 'grad_norm': 6.94359827041626, 'learning_rate': 4.937334194642308e-05, 'epoch': 1.22}\n",
            "{'loss': 3.7217, 'grad_norm': 7.615842342376709, 'learning_rate': 4.936321249843282e-05, 'epoch': 1.23}\n",
            "{'loss': 3.9881, 'grad_norm': 13.311284065246582, 'learning_rate': 4.93530028940056e-05, 'epoch': 1.23}\n",
            "{'loss': 3.9735, 'grad_norm': 4.939170837402344, 'learning_rate': 4.934271316673162e-05, 'epoch': 1.24}\n",
            "{'loss': 4.2434, 'grad_norm': 7.763564109802246, 'learning_rate': 4.9332343350464706e-05, 'epoch': 1.24}\n",
            "{'loss': 4.2893, 'grad_norm': 7.795178413391113, 'learning_rate': 4.932189347932218e-05, 'epoch': 1.25}\n",
            "{'loss': 4.0944, 'grad_norm': 9.159876823425293, 'learning_rate': 4.9311363587684756e-05, 'epoch': 1.26}\n",
            "{'loss': 3.8503, 'grad_norm': 13.831526756286621, 'learning_rate': 4.930075371019639e-05, 'epoch': 1.26}\n",
            "{'loss': 3.5435, 'grad_norm': 7.572299957275391, 'learning_rate': 4.929006388176425e-05, 'epoch': 1.27}\n",
            "{'loss': 4.5361, 'grad_norm': 11.161019325256348, 'learning_rate': 4.927929413755849e-05, 'epoch': 1.27}\n",
            "{'loss': 4.2677, 'grad_norm': 10.834210395812988, 'learning_rate': 4.926844451301221e-05, 'epoch': 1.28}\n",
            "{'loss': 3.599, 'grad_norm': 11.211950302124023, 'learning_rate': 4.925751504382135e-05, 'epoch': 1.28}\n",
            "{'loss': 4.0526, 'grad_norm': 10.45518970489502, 'learning_rate': 4.924650576594453e-05, 'epoch': 1.29}\n",
            "{'loss': 4.6182, 'grad_norm': 6.406182289123535, 'learning_rate': 4.9235416715602914e-05, 'epoch': 1.29}\n",
            "{'loss': 4.2035, 'grad_norm': 9.881319046020508, 'learning_rate': 4.922424792928014e-05, 'epoch': 1.3}\n",
            "{'loss': 4.4526, 'grad_norm': 6.865966796875, 'learning_rate': 4.9212999443722216e-05, 'epoch': 1.3}\n",
            "{'loss': 4.1484, 'grad_norm': 3.220479726791382, 'learning_rate': 4.920167129593732e-05, 'epoch': 1.31}\n",
            "{'loss': 4.1519, 'grad_norm': 10.398018836975098, 'learning_rate': 4.919026352319575e-05, 'epoch': 1.32}\n",
            "{'loss': 4.4316, 'grad_norm': 11.05334186553955, 'learning_rate': 4.917877616302976e-05, 'epoch': 1.32}\n",
            "{'loss': 3.3375, 'grad_norm': 17.47182273864746, 'learning_rate': 4.9167209253233446e-05, 'epoch': 1.33}\n",
            "{'loss': 4.1315, 'grad_norm': 14.127762794494629, 'learning_rate': 4.915556283186266e-05, 'epoch': 1.33}\n",
            "{'loss': 3.5095, 'grad_norm': 15.136677742004395, 'learning_rate': 4.914383693723481e-05, 'epoch': 1.34}\n",
            "{'loss': 3.6328, 'grad_norm': 7.366793632507324, 'learning_rate': 4.913203160792881e-05, 'epoch': 1.34}\n",
            "{'loss': 4.8403, 'grad_norm': 5.8595991134643555, 'learning_rate': 4.9120146882784904e-05, 'epoch': 1.35}\n",
            "{'loss': 3.3369, 'grad_norm': 8.432151794433594, 'learning_rate': 4.910818280090454e-05, 'epoch': 1.35}\n",
            "{'loss': 4.0342, 'grad_norm': 10.023183822631836, 'learning_rate': 4.9096139401650277e-05, 'epoch': 1.36}\n",
            "{'loss': 3.5598, 'grad_norm': 6.46884298324585, 'learning_rate': 4.9084016724645635e-05, 'epoch': 1.36}\n",
            "{'loss': 4.3998, 'grad_norm': 8.931963920593262, 'learning_rate': 4.907181480977493e-05, 'epoch': 1.37}\n",
            "{'loss': 3.8327, 'grad_norm': 10.260453224182129, 'learning_rate': 4.9059533697183214e-05, 'epoch': 1.38}\n",
            "{'loss': 3.9162, 'grad_norm': 8.826225280761719, 'learning_rate': 4.904717342727608e-05, 'epoch': 1.38}\n",
            "{'loss': 4.6355, 'grad_norm': 6.038553714752197, 'learning_rate': 4.9034734040719564e-05, 'epoch': 1.39}\n",
            "{'loss': 3.6034, 'grad_norm': 9.730173110961914, 'learning_rate': 4.9022215578439986e-05, 'epoch': 1.39}\n",
            "{'loss': 3.3513, 'grad_norm': 15.857398986816406, 'learning_rate': 4.9009618081623864e-05, 'epoch': 1.4}\n",
            "{'loss': 3.6516, 'grad_norm': 11.575706481933594, 'learning_rate': 4.8996941591717705e-05, 'epoch': 1.4}\n",
            "{'loss': 4.2483, 'grad_norm': 7.769551753997803, 'learning_rate': 4.898418615042792e-05, 'epoch': 1.41}\n",
            "{'loss': 4.3732, 'grad_norm': 10.57073974609375, 'learning_rate': 4.89713517997207e-05, 'epoch': 1.41}\n",
            "{'loss': 4.0362, 'grad_norm': 10.905253410339355, 'learning_rate': 4.895843858182181e-05, 'epoch': 1.42}\n",
            "{'loss': 4.0384, 'grad_norm': 6.8926239013671875, 'learning_rate': 4.8945446539216526e-05, 'epoch': 1.42}\n",
            "{'loss': 4.351, 'grad_norm': 15.164331436157227, 'learning_rate': 4.893237571464945e-05, 'epoch': 1.43}\n",
            "{'loss': 4.592, 'grad_norm': 6.998665809631348, 'learning_rate': 4.891922615112438e-05, 'epoch': 1.44}\n",
            "{'loss': 3.7172, 'grad_norm': 5.6978559494018555, 'learning_rate': 4.890599789190417e-05, 'epoch': 1.44}\n",
            "{'loss': 3.941, 'grad_norm': 4.742093563079834, 'learning_rate': 4.88926909805106e-05, 'epoch': 1.45}\n",
            "{'loss': 4.1311, 'grad_norm': 7.005824565887451, 'learning_rate': 4.8879305460724203e-05, 'epoch': 1.45}\n",
            "{'loss': 4.6802, 'grad_norm': 8.311542510986328, 'learning_rate': 4.886584137658414e-05, 'epoch': 1.46}\n",
            "{'loss': 4.3709, 'grad_norm': 8.619510650634766, 'learning_rate': 4.8852298772388075e-05, 'epoch': 1.46}\n",
            "{'loss': 4.5049, 'grad_norm': 9.449679374694824, 'learning_rate': 4.883867769269197e-05, 'epoch': 1.47}\n",
            "{'loss': 3.9836, 'grad_norm': 11.835256576538086, 'learning_rate': 4.882497818231002e-05, 'epoch': 1.47}\n",
            "{'loss': 4.5921, 'grad_norm': 6.7877960205078125, 'learning_rate': 4.881120028631442e-05, 'epoch': 1.48}\n",
            "{'loss': 4.3502, 'grad_norm': 9.525306701660156, 'learning_rate': 4.8797344050035295e-05, 'epoch': 1.48}\n",
            "{'loss': 4.0746, 'grad_norm': 3.237440586090088, 'learning_rate': 4.8783409519060485e-05, 'epoch': 1.49}\n",
            "{'loss': 3.7988, 'grad_norm': 9.173598289489746, 'learning_rate': 4.876939673923544e-05, 'epoch': 1.5}\n",
            "{'loss': 4.5244, 'grad_norm': 6.811056137084961, 'learning_rate': 4.875530575666305e-05, 'epoch': 1.5}\n",
            "{'loss': 4.4977, 'grad_norm': 8.495736122131348, 'learning_rate': 4.87411366177035e-05, 'epoch': 1.51}\n",
            "{'loss': 3.0418, 'grad_norm': 12.99510669708252, 'learning_rate': 4.8726889368974104e-05, 'epoch': 1.51}\n",
            "{'loss': 4.5595, 'grad_norm': 7.693224906921387, 'learning_rate': 4.871256405734918e-05, 'epoch': 1.52}\n",
            "{'loss': 3.8715, 'grad_norm': 11.888484001159668, 'learning_rate': 4.869816072995985e-05, 'epoch': 1.52}\n",
            "{'loss': 4.1902, 'grad_norm': 12.543906211853027, 'learning_rate': 4.868367943419395e-05, 'epoch': 1.53}\n",
            "{'loss': 3.4872, 'grad_norm': 3.1255788803100586, 'learning_rate': 4.8669120217695795e-05, 'epoch': 1.53}\n",
            "{'loss': 4.3855, 'grad_norm': 7.133281707763672, 'learning_rate': 4.8654483128366095e-05, 'epoch': 1.54}\n",
            "{'loss': 3.9003, 'grad_norm': 9.9346923828125, 'learning_rate': 4.863976821436176e-05, 'epoch': 1.54}\n",
            "{'loss': 3.8325, 'grad_norm': 6.492159366607666, 'learning_rate': 4.862497552409573e-05, 'epoch': 1.55}\n",
            "{'loss': 4.1751, 'grad_norm': 14.644205093383789, 'learning_rate': 4.8610105106236855e-05, 'epoch': 1.56}\n",
            "{'loss': 4.3881, 'grad_norm': 8.937383651733398, 'learning_rate': 4.85951570097097e-05, 'epoch': 1.56}\n",
            "{'loss': 3.3636, 'grad_norm': 9.2742280960083, 'learning_rate': 4.858013128369442e-05, 'epoch': 1.57}\n",
            "{'loss': 3.939, 'grad_norm': 10.92658805847168, 'learning_rate': 4.856502797762654e-05, 'epoch': 1.57}\n",
            "{'loss': 3.427, 'grad_norm': 8.819816589355469, 'learning_rate': 4.854984714119686e-05, 'epoch': 1.58}\n",
            "{'loss': 3.4297, 'grad_norm': 8.737266540527344, 'learning_rate': 4.8534588824351236e-05, 'epoch': 1.58}\n",
            "{'loss': 4.2903, 'grad_norm': 10.526420593261719, 'learning_rate': 4.852079013492022e-05, 'epoch': 1.59}\n",
            "{'loss': 4.3402, 'grad_norm': 7.050591945648193, 'learning_rate': 4.850538474379803e-05, 'epoch': 1.59}\n",
            "{'loss': 3.7371, 'grad_norm': 12.533121109008789, 'learning_rate': 4.848990201854385e-05, 'epoch': 1.6}\n",
            "{'loss': 3.7519, 'grad_norm': 8.130191802978516, 'learning_rate': 4.847434201009681e-05, 'epoch': 1.6}\n",
            "{'loss': 4.3473, 'grad_norm': 8.717411041259766, 'learning_rate': 4.845870476965025e-05, 'epoch': 1.61}\n",
            "{'loss': 4.5783, 'grad_norm': 7.22452974319458, 'learning_rate': 4.844299034865165e-05, 'epoch': 1.62}\n",
            "{'loss': 4.1376, 'grad_norm': 6.4558892250061035, 'learning_rate': 4.8427198798802394e-05, 'epoch': 1.62}\n",
            "{'loss': 3.499, 'grad_norm': 8.691047668457031, 'learning_rate': 4.841133017205764e-05, 'epoch': 1.63}\n",
            "{'loss': 3.6155, 'grad_norm': 7.4836201667785645, 'learning_rate': 4.839538452062611e-05, 'epoch': 1.63}\n",
            "{'loss': 3.9103, 'grad_norm': 9.145692825317383, 'learning_rate': 4.837936189696998e-05, 'epoch': 1.64}\n",
            " 16% 3000/18320 [1:16:05<4:12:37,  1.01it/s]\n",
            "  0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            " 20% 2/10 [00:00<00:00,  9.03it/s]\u001b[A\n",
            " 30% 3/10 [00:00<00:00,  8.03it/s]\u001b[A\n",
            " 40% 4/10 [00:00<00:00,  7.19it/s]\u001b[A\n",
            " 50% 5/10 [00:00<00:00,  6.70it/s]\u001b[A\n",
            " 60% 6/10 [00:00<00:00,  6.14it/s]\u001b[A\n",
            " 70% 7/10 [00:01<00:00,  5.88it/s]\u001b[A\n",
            " 80% 8/10 [00:24<00:14,  7.38s/it]\u001b[A\n",
            " 90% 9/10 [00:24<00:05,  5.15s/it]\u001b[A\n",
            "                                            \n",
            "\u001b[A{'eval_loss': 5.048901081085205, 'eval_runtime': 83.1566, 'eval_samples_per_second': 3.608, 'eval_steps_per_second': 0.12, 'epoch': 1.64}\n",
            " 16% 3000/18320 [1:17:28<4:12:37,  1.01it/s]\n",
            "100% 10/10 [00:24<00:00,  3.64s/it]\u001b[A\n",
            "                                   \u001b[A/usr/lib/python3.12/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
            "  self.gen = func(*args, **kwds)\n",
            "{'loss': 4.306, 'grad_norm': 7.995177745819092, 'learning_rate': 4.836326235380462e-05, 'epoch': 1.64}\n",
            "{'loss': 4.1641, 'grad_norm': 8.314191818237305, 'learning_rate': 4.834708594409853e-05, 'epoch': 1.65}\n",
            "{'loss': 3.7185, 'grad_norm': 8.487178802490234, 'learning_rate': 4.8330832721073045e-05, 'epoch': 1.65}\n",
            "{'loss': 4.4096, 'grad_norm': 10.497888565063477, 'learning_rate': 4.831450273820226e-05, 'epoch': 1.66}\n",
            "{'loss': 3.589, 'grad_norm': 8.162257194519043, 'learning_rate': 4.8298096049212804e-05, 'epoch': 1.66}\n",
            "{'loss': 4.3938, 'grad_norm': 8.128913879394531, 'learning_rate': 4.8281612708083665e-05, 'epoch': 1.67}\n",
            "{'loss': 4.5482, 'grad_norm': 9.315220832824707, 'learning_rate': 4.8265052769046036e-05, 'epoch': 1.68}\n",
            "{'loss': 4.5077, 'grad_norm': 10.355792045593262, 'learning_rate': 4.824841628658311e-05, 'epoch': 1.68}\n",
            "{'loss': 3.9533, 'grad_norm': 7.581211090087891, 'learning_rate': 4.823170331542991e-05, 'epoch': 1.69}\n",
            "{'loss': 3.3335, 'grad_norm': 10.263712882995605, 'learning_rate': 4.821491391057313e-05, 'epoch': 1.69}\n",
            "{'loss': 4.4834, 'grad_norm': 9.369418144226074, 'learning_rate': 4.8198048127250925e-05, 'epoch': 1.7}\n",
            "{'loss': 3.8411, 'grad_norm': 13.586919784545898, 'learning_rate': 4.8181106020952724e-05, 'epoch': 1.7}\n",
            "{'loss': 4.5181, 'grad_norm': 15.586202621459961, 'learning_rate': 4.816408764741909e-05, 'epoch': 1.71}\n",
            "{'loss': 4.0484, 'grad_norm': 8.510455131530762, 'learning_rate': 4.8146993062641494e-05, 'epoch': 1.71}\n",
            "{'loss': 3.9635, 'grad_norm': 9.381351470947266, 'learning_rate': 4.812982232286214e-05, 'epoch': 1.72}\n",
            "{'loss': 3.9388, 'grad_norm': 3.6534438133239746, 'learning_rate': 4.8112575484573816e-05, 'epoch': 1.72}\n",
            "{'loss': 4.3619, 'grad_norm': 14.5466890335083, 'learning_rate': 4.809525260451964e-05, 'epoch': 1.73}\n",
            "{'loss': 4.0764, 'grad_norm': 15.000365257263184, 'learning_rate': 4.807785373969295e-05, 'epoch': 1.74}\n",
            "{'loss': 4.2262, 'grad_norm': 8.54166030883789, 'learning_rate': 4.806037894733703e-05, 'epoch': 1.74}\n",
            "{'loss': 4.5242, 'grad_norm': 10.115619659423828, 'learning_rate': 4.804282828494503e-05, 'epoch': 1.75}\n",
            "{'loss': 4.5887, 'grad_norm': 8.710189819335938, 'learning_rate': 4.8025201810259674e-05, 'epoch': 1.75}\n",
            "{'loss': 3.7867, 'grad_norm': 4.711921691894531, 'learning_rate': 4.800749958127313e-05, 'epoch': 1.76}\n",
            "{'loss': 3.7198, 'grad_norm': 17.63377571105957, 'learning_rate': 4.7989721656226785e-05, 'epoch': 1.76}\n",
            "{'loss': 4.4513, 'grad_norm': 7.718013286590576, 'learning_rate': 4.79718680936111e-05, 'epoch': 1.77}\n",
            "{'loss': 4.2834, 'grad_norm': 8.432358741760254, 'learning_rate': 4.795393895216537e-05, 'epoch': 1.77}\n",
            "{'loss': 3.5717, 'grad_norm': 2.43100905418396, 'learning_rate': 4.7935934290877534e-05, 'epoch': 1.78}\n",
            "{'loss': 4.0519, 'grad_norm': 9.70727825164795, 'learning_rate': 4.791785416898403e-05, 'epoch': 1.78}\n",
            "{'loss': 4.164, 'grad_norm': 6.129217624664307, 'learning_rate': 4.789969864596954e-05, 'epoch': 1.79}\n",
            "{'loss': 4.3557, 'grad_norm': 10.295248031616211, 'learning_rate': 4.788146778156682e-05, 'epoch': 1.8}\n",
            "{'loss': 3.9085, 'grad_norm': 9.717355728149414, 'learning_rate': 4.786316163575654e-05, 'epoch': 1.8}\n",
            "{'loss': 3.712, 'grad_norm': 9.353144645690918, 'learning_rate': 4.7844780268766995e-05, 'epoch': 1.81}\n",
            "{'loss': 3.7593, 'grad_norm': 9.416420936584473, 'learning_rate': 4.782632374107401e-05, 'epoch': 1.81}\n",
            "{'loss': 3.8292, 'grad_norm': 10.86849594116211, 'learning_rate': 4.7807792113400654e-05, 'epoch': 1.82}\n",
            "{'loss': 4.2138, 'grad_norm': 6.005674839019775, 'learning_rate': 4.778918544671712e-05, 'epoch': 1.82}\n",
            "{'loss': 3.6303, 'grad_norm': 7.852198123931885, 'learning_rate': 4.777050380224044e-05, 'epoch': 1.83}\n",
            "{'loss': 2.9981, 'grad_norm': 15.275181770324707, 'learning_rate': 4.775174724143436e-05, 'epoch': 1.83}\n",
            "{'loss': 3.9326, 'grad_norm': 5.337770462036133, 'learning_rate': 4.7732915826009094e-05, 'epoch': 1.84}\n",
            "{'loss': 3.7562, 'grad_norm': 10.48132038116455, 'learning_rate': 4.771400961792114e-05, 'epoch': 1.84}\n",
            "{'loss': 4.365, 'grad_norm': 10.04825210571289, 'learning_rate': 4.7695028679373055e-05, 'epoch': 1.85}\n",
            "{'loss': 3.9158, 'grad_norm': 3.190713882446289, 'learning_rate': 4.767597307281327e-05, 'epoch': 1.86}\n",
            "{'loss': 3.9032, 'grad_norm': 6.478304386138916, 'learning_rate': 4.765684286093588e-05, 'epoch': 1.86}\n",
            "{'loss': 4.4316, 'grad_norm': 6.520474433898926, 'learning_rate': 4.7637638106680435e-05, 'epoch': 1.87}\n",
            "{'loss': 4.2393, 'grad_norm': 6.529873847961426, 'learning_rate': 4.761835887323174e-05, 'epoch': 1.87}\n",
            "{'loss': 3.5622, 'grad_norm': 7.224449157714844, 'learning_rate': 4.7599005224019625e-05, 'epoch': 1.88}\n",
            "{'loss': 4.5096, 'grad_norm': 6.048650741577148, 'learning_rate': 4.757957722271876e-05, 'epoch': 1.88}\n",
            "{'loss': 4.0491, 'grad_norm': 7.504873752593994, 'learning_rate': 4.756007493324845e-05, 'epoch': 1.89}\n",
            "{'loss': 4.3195, 'grad_norm': 7.613368988037109, 'learning_rate': 4.7540498419772396e-05, 'epoch': 1.89}\n",
            "{'loss': 4.268, 'grad_norm': 9.069400787353516, 'learning_rate': 4.75208477466985e-05, 'epoch': 1.9}\n",
            "{'loss': 4.2912, 'grad_norm': 9.98737621307373, 'learning_rate': 4.750112297867868e-05, 'epoch': 1.91}\n",
            "{'loss': 3.669, 'grad_norm': 11.64489459991455, 'learning_rate': 4.74813241806086e-05, 'epoch': 1.91}\n",
            "{'loss': 4.009, 'grad_norm': 9.331368446350098, 'learning_rate': 4.7461451417627486e-05, 'epoch': 1.92}\n",
            "{'loss': 3.8497, 'grad_norm': 7.133777618408203, 'learning_rate': 4.744150475511795e-05, 'epoch': 1.92}\n",
            "{'loss': 4.2812, 'grad_norm': 15.475276947021484, 'learning_rate': 4.74214842587057e-05, 'epoch': 1.93}\n",
            "{'loss': 4.2471, 'grad_norm': 5.701748371124268, 'learning_rate': 4.740138999425937e-05, 'epoch': 1.93}\n",
            "{'loss': 4.273, 'grad_norm': 8.203360557556152, 'learning_rate': 4.738122202789031e-05, 'epoch': 1.94}\n",
            "{'loss': 3.5889, 'grad_norm': 18.17998504638672, 'learning_rate': 4.736098042595234e-05, 'epoch': 1.94}\n",
            "{'loss': 4.3888, 'grad_norm': 10.875128746032715, 'learning_rate': 4.734066525504155e-05, 'epoch': 1.95}\n",
            "{'loss': 3.5731, 'grad_norm': 11.866538047790527, 'learning_rate': 4.732027658199608e-05, 'epoch': 1.95}\n",
            "{'loss': 4.1894, 'grad_norm': 5.020517826080322, 'learning_rate': 4.7299814473895895e-05, 'epoch': 1.96}\n",
            "{'loss': 4.4539, 'grad_norm': 10.405022621154785, 'learning_rate': 4.727927899806255e-05, 'epoch': 1.97}\n",
            "{'loss': 4.3728, 'grad_norm': 14.07209300994873, 'learning_rate': 4.725867022205901e-05, 'epoch': 1.97}\n",
            "{'loss': 4.1763, 'grad_norm': 7.020249843597412, 'learning_rate': 4.723798821368939e-05, 'epoch': 1.98}\n",
            "{'loss': 3.5059, 'grad_norm': 5.834787368774414, 'learning_rate': 4.721723304099873e-05, 'epoch': 1.98}\n",
            "{'loss': 4.195, 'grad_norm': 10.003996849060059, 'learning_rate': 4.7196404772272815e-05, 'epoch': 1.99}\n",
            "{'loss': 3.5344, 'grad_norm': 9.115177154541016, 'learning_rate': 4.717550347603791e-05, 'epoch': 1.99}\n",
            "{'loss': 3.7411, 'grad_norm': 11.178520202636719, 'learning_rate': 4.7154529221060505e-05, 'epoch': 2.0}\n",
            "{'loss': 4.1808, 'grad_norm': 2.5144729614257812, 'learning_rate': 4.7133482076347195e-05, 'epoch': 2.0}\n",
            "{'loss': 2.7961, 'grad_norm': 12.500166893005371, 'learning_rate': 4.7112362111144345e-05, 'epoch': 2.01}\n",
            "{'loss': 3.1946, 'grad_norm': 10.51263427734375, 'learning_rate': 4.70911693949379e-05, 'epoch': 2.01}\n",
            "{'loss': 3.1141, 'grad_norm': 15.788180351257324, 'learning_rate': 4.7069903997453195e-05, 'epoch': 2.02}\n",
            "{'loss': 2.8183, 'grad_norm': 17.4859676361084, 'learning_rate': 4.704856598865466e-05, 'epoch': 2.03}\n",
            "{'loss': 3.6357, 'grad_norm': 8.505609512329102, 'learning_rate': 4.702715543874562e-05, 'epoch': 2.03}\n",
            "{'loss': 3.5688, 'grad_norm': 6.416975975036621, 'learning_rate': 4.700567241816808e-05, 'epoch': 2.04}\n",
            "{'loss': 3.1458, 'grad_norm': 13.108043670654297, 'learning_rate': 4.698411699760248e-05, 'epoch': 2.04}\n",
            "{'loss': 3.1992, 'grad_norm': 6.899946212768555, 'learning_rate': 4.6962489247967445e-05, 'epoch': 2.05}\n",
            "{'loss': 3.2758, 'grad_norm': 8.430527687072754, 'learning_rate': 4.694078924041957e-05, 'epoch': 2.05}\n",
            "{'loss': 3.4433, 'grad_norm': 10.036237716674805, 'learning_rate': 4.6919017046353196e-05, 'epoch': 2.06}\n",
            "{'loss': 3.0587, 'grad_norm': 9.730833053588867, 'learning_rate': 4.689717273740015e-05, 'epoch': 2.06}\n",
            "{'loss': 3.1798, 'grad_norm': 2.918363571166992, 'learning_rate': 4.687525638542953e-05, 'epoch': 2.07}\n",
            "{'loss': 3.0557, 'grad_norm': 9.638163566589355, 'learning_rate': 4.685326806254744e-05, 'epoch': 2.07}\n",
            "{'loss': 3.4863, 'grad_norm': 10.7142972946167, 'learning_rate': 4.6831207841096804e-05, 'epoch': 2.08}\n",
            "{'loss': 3.3319, 'grad_norm': 17.60857391357422, 'learning_rate': 4.680907579365706e-05, 'epoch': 2.09}\n",
            "{'loss': 2.4257, 'grad_norm': 15.762566566467285, 'learning_rate': 4.6786871993044004e-05, 'epoch': 2.09}\n",
            "{'loss': 2.5299, 'grad_norm': 12.331122398376465, 'learning_rate': 4.676459651230946e-05, 'epoch': 2.1}\n",
            "{'loss': 2.9235, 'grad_norm': 15.592211723327637, 'learning_rate': 4.674224942474109e-05, 'epoch': 2.1}\n",
            "{'loss': 3.3591, 'grad_norm': 9.984536170959473, 'learning_rate': 4.671983080386219e-05, 'epoch': 2.11}\n",
            "{'loss': 2.8021, 'grad_norm': 9.764451026916504, 'learning_rate': 4.6697340723431345e-05, 'epoch': 2.11}\n",
            "{'loss': 3.6105, 'grad_norm': 6.348601341247559, 'learning_rate': 4.667477925744229e-05, 'epoch': 2.12}\n",
            "{'loss': 3.3597, 'grad_norm': 6.614389896392822, 'learning_rate': 4.6652146480123603e-05, 'epoch': 2.12}\n",
            "{'loss': 3.0089, 'grad_norm': 26.409006118774414, 'learning_rate': 4.662944246593849e-05, 'epoch': 2.13}\n",
            "{'loss': 2.6728, 'grad_norm': 8.652103424072266, 'learning_rate': 4.6606667289584524e-05, 'epoch': 2.13}\n",
            "{'loss': 2.955, 'grad_norm': 2.9098212718963623, 'learning_rate': 4.658382102599339e-05, 'epoch': 2.14}\n",
            "{'loss': 3.3533, 'grad_norm': 7.35139799118042, 'learning_rate': 4.65609037503307e-05, 'epoch': 2.15}\n",
            "{'loss': 2.8809, 'grad_norm': 6.504572868347168, 'learning_rate': 4.653791553799565e-05, 'epoch': 2.15}\n",
            "{'loss': 3.4019, 'grad_norm': 14.050235748291016, 'learning_rate': 4.651485646462085e-05, 'epoch': 2.16}\n",
            "{'loss': 3.4474, 'grad_norm': 23.851282119750977, 'learning_rate': 4.649172660607205e-05, 'epoch': 2.16}\n",
            "{'loss': 2.7362, 'grad_norm': 10.19949722290039, 'learning_rate': 4.6468526038447864e-05, 'epoch': 2.17}\n",
            "{'loss': 3.3837, 'grad_norm': 7.896324634552002, 'learning_rate': 4.6445254838079567e-05, 'epoch': 2.17}\n",
            "{'loss': 3.5014, 'grad_norm': 13.618067741394043, 'learning_rate': 4.6421913081530796e-05, 'epoch': 2.18}\n",
            "{'loss': 3.2596, 'grad_norm': 12.062119483947754, 'learning_rate': 4.639850084559736e-05, 'epoch': 2.18}\n",
            " 22% 4000/18320 [1:41:56<14:06:02,  3.54s/it]\n",
            "  0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            " 20% 2/10 [00:00<00:00,  9.09it/s]\u001b[A\n",
            " 30% 3/10 [00:00<00:00,  7.71it/s]\u001b[A\n",
            " 40% 4/10 [00:00<00:00,  7.06it/s]\u001b[A\n",
            " 50% 5/10 [00:00<00:00,  6.61it/s]\u001b[A\n",
            " 60% 6/10 [00:00<00:00,  6.08it/s]\u001b[A\n",
            " 70% 7/10 [00:01<00:00,  5.84it/s]\u001b[A\n",
            " 80% 8/10 [00:24<00:14,  7.35s/it]\u001b[A\n",
            " 90% 9/10 [00:24<00:05,  5.12s/it]\u001b[A\n",
            "                                             \n",
            "\u001b[A{'eval_loss': 5.085759162902832, 'eval_runtime': 77.9776, 'eval_samples_per_second': 3.847, 'eval_steps_per_second': 0.128, 'epoch': 2.18}\n",
            " 22% 4000/18320 [1:43:14<14:06:02,  3.54s/it]\n",
            "100% 10/10 [00:24<00:00,  3.62s/it]\u001b[A\n",
            "                                   \u001b[A/usr/lib/python3.12/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
            "  self.gen = func(*args, **kwds)\n",
            "{'loss': 3.3247, 'grad_norm': 32.43272018432617, 'learning_rate': 4.637501820730691e-05, 'epoch': 2.19}\n",
            "{'loss': 3.4751, 'grad_norm': 12.254097938537598, 'learning_rate': 4.635146524391873e-05, 'epoch': 2.19}\n",
            "{'loss': 3.5068, 'grad_norm': 9.971795082092285, 'learning_rate': 4.6327842032923515e-05, 'epoch': 2.2}\n",
            "{'loss': 3.0621, 'grad_norm': 6.35650110244751, 'learning_rate': 4.630414865204304e-05, 'epoch': 2.21}\n",
            "{'loss': 2.9905, 'grad_norm': 12.051290512084961, 'learning_rate': 4.628038517922996e-05, 'epoch': 2.21}\n",
            "{'loss': 3.001, 'grad_norm': 13.017715454101562, 'learning_rate': 4.6256551692667514e-05, 'epoch': 2.22}\n",
            "{'loss': 3.2985, 'grad_norm': 12.212968826293945, 'learning_rate': 4.6232648270769335e-05, 'epoch': 2.22}\n",
            "{'loss': 3.0287, 'grad_norm': 18.634037017822266, 'learning_rate': 4.62086749921791e-05, 'epoch': 2.23}\n",
            "{'loss': 2.5931, 'grad_norm': 14.623151779174805, 'learning_rate': 4.618463193577035e-05, 'epoch': 2.23}\n",
            "{'loss': 3.1021, 'grad_norm': 7.365750789642334, 'learning_rate': 4.6160519180646186e-05, 'epoch': 2.24}\n",
            "{'loss': 2.9626, 'grad_norm': 7.536611557006836, 'learning_rate': 4.6136336806139036e-05, 'epoch': 2.24}\n",
            "{'loss': 2.6966, 'grad_norm': 8.852835655212402, 'learning_rate': 4.6112084891810346e-05, 'epoch': 2.25}\n",
            "{'loss': 3.4939, 'grad_norm': 11.31553840637207, 'learning_rate': 4.60877635174504e-05, 'epoch': 2.25}\n",
            "{'loss': 3.0482, 'grad_norm': 16.813690185546875, 'learning_rate': 4.606337276307797e-05, 'epoch': 2.26}\n",
            "{'loss': 3.5643, 'grad_norm': 9.315206527709961, 'learning_rate': 4.6038912708940105e-05, 'epoch': 2.27}\n",
            "{'loss': 3.3068, 'grad_norm': 14.271262168884277, 'learning_rate': 4.601438343551187e-05, 'epoch': 2.27}\n",
            "{'loss': 3.5537, 'grad_norm': 8.553573608398438, 'learning_rate': 4.598978502349605e-05, 'epoch': 2.28}\n",
            "{'loss': 2.9805, 'grad_norm': 11.506141662597656, 'learning_rate': 4.596511755382289e-05, 'epoch': 2.28}\n",
            "{'loss': 3.4493, 'grad_norm': 6.922532081604004, 'learning_rate': 4.594038110764986e-05, 'epoch': 2.29}\n",
            "{'loss': 3.4149, 'grad_norm': 6.282650947570801, 'learning_rate': 4.591557576636135e-05, 'epoch': 2.29}\n",
            "{'loss': 2.9653, 'grad_norm': 3.218151092529297, 'learning_rate': 4.589070161156845e-05, 'epoch': 2.3}\n",
            "{'loss': 3.3086, 'grad_norm': 15.147083282470703, 'learning_rate': 4.586575872510861e-05, 'epoch': 2.3}\n",
            "{'loss': 3.1143, 'grad_norm': 7.002793312072754, 'learning_rate': 4.5840747189045426e-05, 'epoch': 2.31}\n",
            "{'loss': 3.3061, 'grad_norm': 8.100918769836426, 'learning_rate': 4.581566708566837e-05, 'epoch': 2.31}\n",
            "{'loss': 3.533, 'grad_norm': 13.632323265075684, 'learning_rate': 4.5790518497492486e-05, 'epoch': 2.32}\n",
            "{'loss': 3.1685, 'grad_norm': 13.522956848144531, 'learning_rate': 4.576530150725814e-05, 'epoch': 2.33}\n",
            "{'loss': 3.0482, 'grad_norm': 7.218270301818848, 'learning_rate': 4.5740016197930766e-05, 'epoch': 2.33}\n",
            "{'loss': 3.2383, 'grad_norm': 7.673846244812012, 'learning_rate': 4.571466265270054e-05, 'epoch': 2.34}\n",
            "{'loss': 3.6777, 'grad_norm': 13.498421669006348, 'learning_rate': 4.568924095498215e-05, 'epoch': 2.34}\n",
            "{'loss': 2.8577, 'grad_norm': 7.725238800048828, 'learning_rate': 4.566375118841453e-05, 'epoch': 2.35}\n",
            "{'loss': 3.1603, 'grad_norm': 7.472168922424316, 'learning_rate': 4.5638193436860536e-05, 'epoch': 2.35}\n",
            "{'loss': 3.2816, 'grad_norm': 10.066742897033691, 'learning_rate': 4.561256778440672e-05, 'epoch': 2.36}\n",
            "{'loss': 3.042, 'grad_norm': 3.3205745220184326, 'learning_rate': 4.5586874315363e-05, 'epoch': 2.36}\n",
            "{'loss': 3.3395, 'grad_norm': 8.985321044921875, 'learning_rate': 4.556111311426246e-05, 'epoch': 2.37}\n",
            "{'loss': 3.2814, 'grad_norm': 8.247344970703125, 'learning_rate': 4.5535284265861e-05, 'epoch': 2.37}\n",
            "{'loss': 3.1776, 'grad_norm': 12.344021797180176, 'learning_rate': 4.550938785513709e-05, 'epoch': 2.38}\n",
            "{'loss': 3.2736, 'grad_norm': 2.753364324569702, 'learning_rate': 4.548342396729146e-05, 'epoch': 2.39}\n",
            "{'loss': 3.4263, 'grad_norm': 8.15782356262207, 'learning_rate': 4.545739268774689e-05, 'epoch': 2.39}\n",
            "{'loss': 2.8141, 'grad_norm': 8.332881927490234, 'learning_rate': 4.543129410214785e-05, 'epoch': 2.4}\n",
            "{'loss': 2.9134, 'grad_norm': 9.777841567993164, 'learning_rate': 4.540512829636025e-05, 'epoch': 2.4}\n",
            "{'loss': 3.3363, 'grad_norm': 10.755291938781738, 'learning_rate': 4.537889535647117e-05, 'epoch': 2.41}\n",
            "{'loss': 3.2196, 'grad_norm': 14.074565887451172, 'learning_rate': 4.535259536878859e-05, 'epoch': 2.41}\n",
            "{'loss': 3.0612, 'grad_norm': 7.9071831703186035, 'learning_rate': 4.532622841984101e-05, 'epoch': 2.42}\n",
            "{'loss': 3.1555, 'grad_norm': 12.484006881713867, 'learning_rate': 4.529979459637731e-05, 'epoch': 2.42}\n",
            "{'loss': 3.6259, 'grad_norm': 9.032787322998047, 'learning_rate': 4.5273293985366357e-05, 'epoch': 2.43}\n",
            "{'loss': 3.4218, 'grad_norm': 9.944448471069336, 'learning_rate': 4.524672667399675e-05, 'epoch': 2.43}\n",
            "{'loss': 3.0449, 'grad_norm': 3.2424068450927734, 'learning_rate': 4.5220092749676555e-05, 'epoch': 2.44}\n",
            "{'loss': 2.4007, 'grad_norm': 10.084725379943848, 'learning_rate': 4.519339230003298e-05, 'epoch': 2.45}\n",
            "{'loss': 3.1305, 'grad_norm': 9.406137466430664, 'learning_rate': 4.516662541291211e-05, 'epoch': 2.45}\n",
            "{'loss': 3.0452, 'grad_norm': 8.236249923706055, 'learning_rate': 4.513979217637863e-05, 'epoch': 2.46}\n",
            "{'loss': 3.6064, 'grad_norm': 11.872323989868164, 'learning_rate': 4.5112892678715484e-05, 'epoch': 2.46}\n",
            "{'loss': 2.8219, 'grad_norm': 15.600250244140625, 'learning_rate': 4.5085927008423657e-05, 'epoch': 2.47}\n",
            "{'loss': 3.4487, 'grad_norm': 7.968250751495361, 'learning_rate': 4.505889525422183e-05, 'epoch': 2.47}\n",
            "{'loss': 3.115, 'grad_norm': 8.220418930053711, 'learning_rate': 4.5031797505046095e-05, 'epoch': 2.48}\n",
            "{'loss': 3.4216, 'grad_norm': 8.816493034362793, 'learning_rate': 4.500463385004967e-05, 'epoch': 2.48}\n",
            "{'loss': 2.8853, 'grad_norm': 7.253147602081299, 'learning_rate': 4.497740437860264e-05, 'epoch': 2.49}\n",
            "{'loss': 3.3542, 'grad_norm': 2.5030789375305176, 'learning_rate': 4.4950109180291586e-05, 'epoch': 2.49}\n",
            "{'loss': 3.3296, 'grad_norm': 13.128094673156738, 'learning_rate': 4.4922748344919366e-05, 'epoch': 2.5}\n",
            "{'loss': 3.2944, 'grad_norm': 8.571666717529297, 'learning_rate': 4.4895321962504776e-05, 'epoch': 2.51}\n",
            "{'loss': 3.0766, 'grad_norm': 9.07516098022461, 'learning_rate': 4.4867830123282264e-05, 'epoch': 2.51}\n",
            "{'loss': 2.8151, 'grad_norm': 13.437971115112305, 'learning_rate': 4.484027291770164e-05, 'epoch': 2.52}\n",
            "{'loss': 2.8021, 'grad_norm': 16.020227432250977, 'learning_rate': 4.481265043642776e-05, 'epoch': 2.52}\n",
            "{'loss': 3.154, 'grad_norm': 3.284749984741211, 'learning_rate': 4.4784962770340275e-05, 'epoch': 2.53}\n",
            "{'loss': 3.117, 'grad_norm': 8.330474853515625, 'learning_rate': 4.475721001053325e-05, 'epoch': 2.53}\n",
            "{'loss': 2.9478, 'grad_norm': 3.4267027378082275, 'learning_rate': 4.472939224831494e-05, 'epoch': 2.54}\n",
            "{'loss': 3.4507, 'grad_norm': 2.7915613651275635, 'learning_rate': 4.470150957520748e-05, 'epoch': 2.54}\n",
            "{'loss': 2.7811, 'grad_norm': 7.655200004577637, 'learning_rate': 4.4673562082946516e-05, 'epoch': 2.55}\n",
            "{'loss': 3.6104, 'grad_norm': 12.112536430358887, 'learning_rate': 4.4645549863481004e-05, 'epoch': 2.55}\n",
            "{'loss': 3.1986, 'grad_norm': 3.1213295459747314, 'learning_rate': 4.461747300897282e-05, 'epoch': 2.56}\n",
            "{'loss': 3.215, 'grad_norm': 23.714370727539062, 'learning_rate': 4.458933161179652e-05, 'epoch': 2.57}\n",
            "{'loss': 2.7164, 'grad_norm': 8.443913459777832, 'learning_rate': 4.456112576453898e-05, 'epoch': 2.57}\n",
            "{'loss': 3.4001, 'grad_norm': 10.534028053283691, 'learning_rate': 4.453285555999914e-05, 'epoch': 2.58}\n",
            "{'loss': 2.6716, 'grad_norm': 14.279951095581055, 'learning_rate': 4.450452109118769e-05, 'epoch': 2.58}\n",
            "{'loss': 3.5119, 'grad_norm': 12.71181869506836, 'learning_rate': 4.4476122451326726e-05, 'epoch': 2.59}\n",
            "{'loss': 3.3849, 'grad_norm': 2.9033100605010986, 'learning_rate': 4.44476597338495e-05, 'epoch': 2.59}\n",
            "{'loss': 3.1885, 'grad_norm': 12.127031326293945, 'learning_rate': 4.441913303240004e-05, 'epoch': 2.6}\n",
            "{'loss': 3.2693, 'grad_norm': 6.7125773429870605, 'learning_rate': 4.439054244083294e-05, 'epoch': 2.6}\n",
            "{'loss': 3.1586, 'grad_norm': 8.43826961517334, 'learning_rate': 4.436188805321295e-05, 'epoch': 2.61}\n",
            "{'loss': 3.1151, 'grad_norm': 8.293089866638184, 'learning_rate': 4.4333169963814734e-05, 'epoch': 2.61}\n",
            "{'loss': 3.2546, 'grad_norm': 9.467005729675293, 'learning_rate': 4.4304388267122556e-05, 'epoch': 2.62}\n",
            "{'loss': 3.5349, 'grad_norm': 7.7348833084106445, 'learning_rate': 4.4275543057829905e-05, 'epoch': 2.63}\n",
            "{'loss': 3.4119, 'grad_norm': 10.830376625061035, 'learning_rate': 4.4246634430839274e-05, 'epoch': 2.63}\n",
            "{'loss': 3.476, 'grad_norm': 9.131633758544922, 'learning_rate': 4.421766248126178e-05, 'epoch': 2.64}\n",
            "{'loss': 3.0666, 'grad_norm': 7.858376502990723, 'learning_rate': 4.4188627304416885e-05, 'epoch': 2.64}\n",
            "{'loss': 3.5087, 'grad_norm': 6.912994384765625, 'learning_rate': 4.415952899583208e-05, 'epoch': 2.65}\n",
            "{'loss': 3.0248, 'grad_norm': 9.914210319519043, 'learning_rate': 4.413036765124254e-05, 'epoch': 2.65}\n",
            "{'loss': 3.2148, 'grad_norm': 11.078811645507812, 'learning_rate': 4.4101143366590846e-05, 'epoch': 2.66}\n",
            "{'loss': 2.8721, 'grad_norm': 20.546348571777344, 'learning_rate': 4.407185623802666e-05, 'epoch': 2.66}\n",
            "{'loss': 3.3844, 'grad_norm': 3.449199914932251, 'learning_rate': 4.40425063619064e-05, 'epoch': 2.67}\n",
            "{'loss': 3.5597, 'grad_norm': 8.240789413452148, 'learning_rate': 4.401309383479293e-05, 'epoch': 2.67}\n",
            "{'loss': 3.4096, 'grad_norm': 8.714143753051758, 'learning_rate': 4.398361875345523e-05, 'epoch': 2.68}\n",
            "{'loss': 3.4356, 'grad_norm': 3.5099294185638428, 'learning_rate': 4.3954081214868096e-05, 'epoch': 2.69}\n",
            "{'loss': 3.3887, 'grad_norm': 5.808768272399902, 'learning_rate': 4.3924481316211796e-05, 'epoch': 2.69}\n",
            "{'loss': 3.0684, 'grad_norm': 3.081413984298706, 'learning_rate': 4.3894819154871806e-05, 'epoch': 2.7}\n",
            "{'loss': 3.5168, 'grad_norm': 9.499734878540039, 'learning_rate': 4.3865094828438404e-05, 'epoch': 2.7}\n",
            "{'loss': 2.4713, 'grad_norm': 11.430883407592773, 'learning_rate': 4.383530843470642e-05, 'epoch': 2.71}\n",
            "{'loss': 2.5997, 'grad_norm': 9.260655403137207, 'learning_rate': 4.3805460071674894e-05, 'epoch': 2.71}\n",
            "{'loss': 3.3712, 'grad_norm': 15.760049819946289, 'learning_rate': 4.377554983754672e-05, 'epoch': 2.72}\n",
            "{'loss': 3.3316, 'grad_norm': 9.6769380569458, 'learning_rate': 4.374557783072839e-05, 'epoch': 2.72}\n",
            "{'loss': 3.132, 'grad_norm': 15.462899208068848, 'learning_rate': 4.3715544149829604e-05, 'epoch': 2.73}\n",
            " 27% 5000/18320 [2:08:12<2:44:49,  1.35it/s]\n",
            "  0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            " 20% 2/10 [00:00<00:00,  8.84it/s]\u001b[A\n",
            " 30% 3/10 [00:00<00:00,  7.98it/s]\u001b[A\n",
            " 40% 4/10 [00:00<00:00,  7.16it/s]\u001b[A\n",
            " 50% 5/10 [00:00<00:00,  6.68it/s]\u001b[A\n",
            " 60% 6/10 [00:00<00:00,  6.11it/s]\u001b[A\n",
            " 70% 7/10 [00:01<00:00,  5.86it/s]\u001b[A\n",
            " 80% 8/10 [00:26<00:16,  8.09s/it]\u001b[A\n",
            " 90% 9/10 [00:26<00:05,  5.64s/it]\u001b[A\n",
            "                                            \n",
            "\u001b[A{'eval_loss': 5.135639667510986, 'eval_runtime': 84.6718, 'eval_samples_per_second': 3.543, 'eval_steps_per_second': 0.118, 'epoch': 2.73}\n",
            " 27% 5000/18320 [2:09:36<2:44:49,  1.35it/s]\n",
            "100% 10/10 [00:26<00:00,  3.98s/it]\u001b[A\n",
            "                                   \u001b[A/usr/lib/python3.12/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
            "  self.gen = func(*args, **kwds)\n",
            "{'loss': 3.1498, 'grad_norm': 8.200979232788086, 'learning_rate': 4.368846118734634e-05, 'epoch': 2.73}\n",
            "{'loss': 3.3196, 'grad_norm': 7.2804975509643555, 'learning_rate': 4.365831059809089e-05, 'epoch': 2.74}\n",
            "{'loss': 2.9058, 'grad_norm': 7.335143089294434, 'learning_rate': 4.362809862186944e-05, 'epoch': 2.75}\n",
            "{'loss': 2.9645, 'grad_norm': 17.087587356567383, 'learning_rate': 4.35978253580812e-05, 'epoch': 2.75}\n",
            "{'loss': 3.2532, 'grad_norm': 3.0101613998413086, 'learning_rate': 4.356749090632705e-05, 'epoch': 2.76}\n",
            "{'loss': 3.5273, 'grad_norm': 8.291031837463379, 'learning_rate': 4.353709536640914e-05, 'epoch': 2.76}\n",
            "{'loss': 2.9034, 'grad_norm': 2.97839617729187, 'learning_rate': 4.350663883833065e-05, 'epoch': 2.77}\n",
            "{'loss': 3.3402, 'grad_norm': 13.150704383850098, 'learning_rate': 4.347612142229538e-05, 'epoch': 2.77}\n",
            "{'loss': 3.2733, 'grad_norm': 18.702648162841797, 'learning_rate': 4.344554321870747e-05, 'epoch': 2.78}\n",
            "{'loss': 3.5988, 'grad_norm': 8.410017013549805, 'learning_rate': 4.341490432817106e-05, 'epoch': 2.78}\n",
            "{'loss': 3.7631, 'grad_norm': 11.066145896911621, 'learning_rate': 4.338420485148993e-05, 'epoch': 2.79}\n",
            "{'loss': 3.0576, 'grad_norm': 10.378173828125, 'learning_rate': 4.335344488966722e-05, 'epoch': 2.79}\n",
            "{'loss': 3.8901, 'grad_norm': 3.2224957942962646, 'learning_rate': 4.332262454390505e-05, 'epoch': 2.8}\n",
            "{'loss': 3.8097, 'grad_norm': 12.457277297973633, 'learning_rate': 4.329174391560423e-05, 'epoch': 2.81}\n",
            "{'loss': 3.4983, 'grad_norm': 6.116281986236572, 'learning_rate': 4.3260803106363864e-05, 'epoch': 2.81}\n",
            "{'loss': 3.1086, 'grad_norm': 10.119214057922363, 'learning_rate': 4.32298022179811e-05, 'epoch': 2.82}\n",
            "{'loss': 3.556, 'grad_norm': 10.185574531555176, 'learning_rate': 4.319874135245071e-05, 'epoch': 2.82}\n",
            "{'loss': 3.3574, 'grad_norm': 13.093194007873535, 'learning_rate': 4.316762061196483e-05, 'epoch': 2.83}\n",
            "{'loss': 2.6651, 'grad_norm': 16.99491310119629, 'learning_rate': 4.3136440098912556e-05, 'epoch': 2.83}\n",
            "{'loss': 3.343, 'grad_norm': 4.12143087387085, 'learning_rate': 4.310519991587966e-05, 'epoch': 2.84}\n",
            "{'loss': 3.3546, 'grad_norm': 14.5204496383667, 'learning_rate': 4.307390016564824e-05, 'epoch': 2.84}\n",
            "{'loss': 3.3289, 'grad_norm': 12.44344711303711, 'learning_rate': 4.304254095119634e-05, 'epoch': 2.85}\n",
            "{'loss': 3.0288, 'grad_norm': 9.121047019958496, 'learning_rate': 4.3011122375697675e-05, 'epoch': 2.85}\n",
            "{'loss': 3.7925, 'grad_norm': 7.081158638000488, 'learning_rate': 4.2979644542521246e-05, 'epoch': 2.86}\n",
            "{'loss': 3.1152, 'grad_norm': 8.919923782348633, 'learning_rate': 4.2948107555231034e-05, 'epoch': 2.87}\n",
            "{'loss': 3.1994, 'grad_norm': 9.758336067199707, 'learning_rate': 4.291651151758561e-05, 'epoch': 2.87}\n",
            "{'loss': 3.0621, 'grad_norm': 12.408148765563965, 'learning_rate': 4.288485653353785e-05, 'epoch': 2.88}\n",
            "{'loss': 2.9664, 'grad_norm': 10.907857894897461, 'learning_rate': 4.285314270723456e-05, 'epoch': 2.88}\n",
            "{'loss': 2.444, 'grad_norm': 8.421929359436035, 'learning_rate': 4.2821370143016134e-05, 'epoch': 2.89}\n",
            "{'loss': 3.3973, 'grad_norm': 8.514857292175293, 'learning_rate': 4.278953894541622e-05, 'epoch': 2.89}\n",
            "{'loss': 3.4125, 'grad_norm': 3.3203561305999756, 'learning_rate': 4.2757649219161385e-05, 'epoch': 2.9}\n",
            "{'loss': 3.4319, 'grad_norm': 7.605794906616211, 'learning_rate': 4.2725701069170756e-05, 'epoch': 2.9}\n",
            "{'loss': 3.3876, 'grad_norm': 10.606403350830078, 'learning_rate': 4.269369460055565e-05, 'epoch': 2.91}\n",
            "{'loss': 2.6966, 'grad_norm': 15.586112022399902, 'learning_rate': 4.26616299186193e-05, 'epoch': 2.91}\n",
            "{'loss': 3.2113, 'grad_norm': 9.676798820495605, 'learning_rate': 4.262950712885641e-05, 'epoch': 2.92}\n",
            "{'loss': 2.6146, 'grad_norm': 3.6181588172912598, 'learning_rate': 4.259732633695292e-05, 'epoch': 2.93}\n",
            "{'loss': 3.233, 'grad_norm': 7.157515048980713, 'learning_rate': 4.256508764878558e-05, 'epoch': 2.93}\n",
            "{'loss': 3.4493, 'grad_norm': 8.625004768371582, 'learning_rate': 4.2532791170421595e-05, 'epoch': 2.94}\n",
            "{'loss': 3.2586, 'grad_norm': 6.345137596130371, 'learning_rate': 4.2500437008118335e-05, 'epoch': 2.94}\n",
            "{'loss': 3.5429, 'grad_norm': 14.17061710357666, 'learning_rate': 4.2468025268322944e-05, 'epoch': 2.95}\n",
            "{'loss': 3.4572, 'grad_norm': 6.3590192794799805, 'learning_rate': 4.243555605767199e-05, 'epoch': 2.95}\n",
            "{'loss': 2.9218, 'grad_norm': 2.819390058517456, 'learning_rate': 4.240302948299114e-05, 'epoch': 2.96}\n",
            "{'loss': 2.8679, 'grad_norm': 7.656721115112305, 'learning_rate': 4.237044565129479e-05, 'epoch': 2.96}\n",
            "{'loss': 2.9923, 'grad_norm': 3.3306446075439453, 'learning_rate': 4.2337804669785696e-05, 'epoch': 2.97}\n",
            "{'loss': 3.3847, 'grad_norm': 7.468463897705078, 'learning_rate': 4.2305106645854666e-05, 'epoch': 2.97}\n",
            "{'loss': 2.9485, 'grad_norm': 3.159531831741333, 'learning_rate': 4.227235168708016e-05, 'epoch': 2.98}\n",
            "{'loss': 3.1372, 'grad_norm': 10.086179733276367, 'learning_rate': 4.2239539901227966e-05, 'epoch': 2.99}\n",
            "{'loss': 3.4951, 'grad_norm': 9.515759468078613, 'learning_rate': 4.220667139625084e-05, 'epoch': 2.99}\n",
            "{'loss': 3.539, 'grad_norm': 11.886652946472168, 'learning_rate': 4.2173746280288154e-05, 'epoch': 3.0}\n",
            "{'loss': 3.0124, 'grad_norm': 7.851611614227295, 'learning_rate': 4.21407646616655e-05, 'epoch': 3.0}\n",
            "{'loss': 2.5567, 'grad_norm': 10.599871635437012, 'learning_rate': 4.2107726648894405e-05, 'epoch': 3.01}\n",
            "{'loss': 2.0506, 'grad_norm': 18.195005416870117, 'learning_rate': 4.207463235067192e-05, 'epoch': 3.01}\n",
            "{'loss': 1.9979, 'grad_norm': 9.92290210723877, 'learning_rate': 4.2041481875880276e-05, 'epoch': 3.02}\n",
            "{'loss': 2.0054, 'grad_norm': 9.97235107421875, 'learning_rate': 4.2008275333586546e-05, 'epoch': 3.02}\n",
            "{'loss': 2.1053, 'grad_norm': 7.580631732940674, 'learning_rate': 4.197501283304223e-05, 'epoch': 3.03}\n",
            "{'loss': 2.1989, 'grad_norm': 9.066048622131348, 'learning_rate': 4.194169448368298e-05, 'epoch': 3.03}\n",
            "{'loss': 2.0518, 'grad_norm': 8.026413917541504, 'learning_rate': 4.1908320395128166e-05, 'epoch': 3.04}\n",
            "{'loss': 1.9518, 'grad_norm': 11.041218757629395, 'learning_rate': 4.187489067718055e-05, 'epoch': 3.05}\n",
            "{'loss': 2.1311, 'grad_norm': 13.990070343017578, 'learning_rate': 4.184140543982591e-05, 'epoch': 3.05}\n",
            "{'loss': 2.0304, 'grad_norm': 9.423644065856934, 'learning_rate': 4.180786479323271e-05, 'epoch': 3.06}\n",
            "{'loss': 1.945, 'grad_norm': 9.838655471801758, 'learning_rate': 4.177426884775169e-05, 'epoch': 3.06}\n",
            "{'loss': 2.1, 'grad_norm': 11.782081604003906, 'learning_rate': 4.174061771391554e-05, 'epoch': 3.07}\n",
            "{'loss': 2.2132, 'grad_norm': 17.060789108276367, 'learning_rate': 4.1706911502438506e-05, 'epoch': 3.07}\n",
            "{'loss': 2.0657, 'grad_norm': 10.75558853149414, 'learning_rate': 4.167315032421606e-05, 'epoch': 3.08}\n",
            "{'loss': 2.2155, 'grad_norm': 9.55288028717041, 'learning_rate': 4.163933429032452e-05, 'epoch': 3.08}\n",
            "{'loss': 2.2234, 'grad_norm': 10.163376808166504, 'learning_rate': 4.160546351202066e-05, 'epoch': 3.09}\n",
            "{'loss': 2.5358, 'grad_norm': 16.175630569458008, 'learning_rate': 4.157153810074139e-05, 'epoch': 3.09}\n",
            "{'loss': 1.5211, 'grad_norm': 9.301365852355957, 'learning_rate': 4.153755816810337e-05, 'epoch': 3.1}\n",
            "{'loss': 1.9536, 'grad_norm': 8.929009437561035, 'learning_rate': 4.15035238259026e-05, 'epoch': 3.11}\n",
            "{'loss': 2.2197, 'grad_norm': 9.3552885055542, 'learning_rate': 4.1469435186114134e-05, 'epoch': 3.11}\n",
            "{'loss': 2.1048, 'grad_norm': 3.6517868041992188, 'learning_rate': 4.1435292360891646e-05, 'epoch': 3.12}\n",
            "{'loss': 2.3783, 'grad_norm': 13.860665321350098, 'learning_rate': 4.140109546256708e-05, 'epoch': 3.12}\n",
            "{'loss': 2.4446, 'grad_norm': 12.168774604797363, 'learning_rate': 4.1366844603650314e-05, 'epoch': 3.13}\n",
            "{'loss': 2.1227, 'grad_norm': 8.684566497802734, 'learning_rate': 4.133253989682872e-05, 'epoch': 3.13}\n",
            "{'loss': 2.0624, 'grad_norm': 6.9366455078125, 'learning_rate': 4.1298181454966846e-05, 'epoch': 3.14}\n",
            "{'loss': 1.9749, 'grad_norm': 16.711698532104492, 'learning_rate': 4.1263769391106043e-05, 'epoch': 3.14}\n",
            "{'loss': 2.311, 'grad_norm': 3.531667709350586, 'learning_rate': 4.1229303818464074e-05, 'epoch': 3.15}\n",
            "{'loss': 2.1124, 'grad_norm': 15.852768898010254, 'learning_rate': 4.119478485043475e-05, 'epoch': 3.16}\n",
            "{'loss': 2.0878, 'grad_norm': 8.621847152709961, 'learning_rate': 4.1160212600587565e-05, 'epoch': 3.16}\n",
            "{'loss': 2.2067, 'grad_norm': 8.697049140930176, 'learning_rate': 4.112558718266729e-05, 'epoch': 3.17}\n",
            "{'loss': 1.856, 'grad_norm': 8.88802719116211, 'learning_rate': 4.109090871059364e-05, 'epoch': 3.17}\n",
            "{'loss': 2.2262, 'grad_norm': 18.189088821411133, 'learning_rate': 4.1056177298460874e-05, 'epoch': 3.18}\n",
            "{'loss': 2.1587, 'grad_norm': 6.536465167999268, 'learning_rate': 4.102139306053743e-05, 'epoch': 3.18}\n",
            "{'loss': 2.2841, 'grad_norm': 9.061592102050781, 'learning_rate': 4.0986556111265555e-05, 'epoch': 3.19}\n",
            "{'loss': 2.0449, 'grad_norm': 13.545992851257324, 'learning_rate': 4.0951666565260915e-05, 'epoch': 3.19}\n",
            "{'loss': 1.4996, 'grad_norm': 8.814797401428223, 'learning_rate': 4.09167245373122e-05, 'epoch': 3.2}\n",
            "{'loss': 2.108, 'grad_norm': 4.103789329528809, 'learning_rate': 4.08817301423808e-05, 'epoch': 3.2}\n",
            "{'loss': 1.7716, 'grad_norm': 14.846336364746094, 'learning_rate': 4.084668349560038e-05, 'epoch': 3.21}\n",
            "{'loss': 2.4618, 'grad_norm': 10.37337589263916, 'learning_rate': 4.081158471227652e-05, 'epoch': 3.22}\n",
            "{'loss': 2.1476, 'grad_norm': 9.40124225616455, 'learning_rate': 4.077643390788633e-05, 'epoch': 3.22}\n",
            "{'loss': 2.1824, 'grad_norm': 18.053342819213867, 'learning_rate': 4.074123119807808e-05, 'epoch': 3.23}\n",
            "{'loss': 1.9005, 'grad_norm': 16.43906021118164, 'learning_rate': 4.07059766986708e-05, 'epoch': 3.23}\n",
            "{'loss': 2.0036, 'grad_norm': 11.636886596679688, 'learning_rate': 4.067067052565392e-05, 'epoch': 3.24}\n",
            "{'loss': 2.0825, 'grad_norm': 11.529162406921387, 'learning_rate': 4.063531279518687e-05, 'epoch': 3.24}\n",
            "{'loss': 2.4089, 'grad_norm': 21.398967742919922, 'learning_rate': 4.059990362359871e-05, 'epoch': 3.25}\n",
            "{'loss': 2.1638, 'grad_norm': 7.445764541625977, 'learning_rate': 4.056444312738778e-05, 'epoch': 3.25}\n",
            "{'loss': 1.9584, 'grad_norm': 11.581225395202637, 'learning_rate': 4.05289314232212e-05, 'epoch': 3.26}\n",
            "{'loss': 1.728, 'grad_norm': 13.97685718536377, 'learning_rate': 4.0493368627934655e-05, 'epoch': 3.26}\n",
            "{'loss': 2.2144, 'grad_norm': 9.589497566223145, 'learning_rate': 4.045775485853187e-05, 'epoch': 3.27}\n",
            "{'loss': 2.1368, 'grad_norm': 7.574192047119141, 'learning_rate': 4.0422090232184294e-05, 'epoch': 3.28}\n",
            " 33% 6000/18320 [2:35:34<9:46:08,  2.85s/it]\n",
            "  0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            " 20% 2/10 [00:00<00:00,  9.04it/s]\u001b[A\n",
            " 30% 3/10 [00:00<00:00,  8.07it/s]\u001b[A\n",
            " 40% 4/10 [00:00<00:00,  7.22it/s]\u001b[A\n",
            " 50% 5/10 [00:00<00:00,  6.70it/s]\u001b[A\n",
            " 60% 6/10 [00:00<00:00,  6.13it/s]\u001b[A\n",
            " 70% 7/10 [00:01<00:00,  5.88it/s]\u001b[A\n",
            " 80% 8/10 [00:25<00:15,  7.75s/it]\u001b[A\n",
            " 90% 9/10 [00:25<00:05,  5.40s/it]\u001b[A\n",
            "                                            \n",
            "\u001b[A{'eval_loss': 5.461409568786621, 'eval_runtime': 81.5745, 'eval_samples_per_second': 3.678, 'eval_steps_per_second': 0.123, 'epoch': 3.28}\n",
            " 33% 6000/18320 [2:36:56<9:46:08,  2.85s/it]\n",
            "100% 10/10 [00:25<00:00,  3.81s/it]\u001b[A\n",
            "                                   \u001b[A/usr/lib/python3.12/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
            "  self.gen = func(*args, **kwds)\n",
            "{'loss': 2.164, 'grad_norm': 11.929725646972656, 'learning_rate': 4.038637486623069e-05, 'epoch': 3.28}\n",
            "{'loss': 2.2565, 'grad_norm': 8.795259475708008, 'learning_rate': 4.035060887817678e-05, 'epoch': 3.29}\n",
            "{'loss': 2.0464, 'grad_norm': 8.988624572753906, 'learning_rate': 4.031479238569479e-05, 'epoch': 3.29}\n",
            "{'loss': 2.0222, 'grad_norm': 8.039687156677246, 'learning_rate': 4.0278925506623165e-05, 'epoch': 3.3}\n",
            "{'loss': 2.0935, 'grad_norm': 12.726484298706055, 'learning_rate': 4.0243008358966094e-05, 'epoch': 3.3}\n",
            "{'loss': 2.1043, 'grad_norm': 8.556843757629395, 'learning_rate': 4.020704106089315e-05, 'epoch': 3.31}\n",
            "{'loss': 2.4308, 'grad_norm': 7.28118371963501, 'learning_rate': 4.017102373073892e-05, 'epoch': 3.31}\n",
            "{'loss': 1.9579, 'grad_norm': 4.054247856140137, 'learning_rate': 4.013495648700257e-05, 'epoch': 3.32}\n",
            "{'loss': 2.3252, 'grad_norm': 9.465849876403809, 'learning_rate': 4.0098839448347525e-05, 'epoch': 3.32}\n",
            "{'loss': 2.3678, 'grad_norm': 13.904882431030273, 'learning_rate': 4.0062672733601014e-05, 'epoch': 3.33}\n",
            "{'loss': 2.1404, 'grad_norm': 4.1509504318237305, 'learning_rate': 4.00264564617537e-05, 'epoch': 3.34}\n",
            "{'loss': 2.0991, 'grad_norm': 13.338075637817383, 'learning_rate': 3.9990190751959314e-05, 'epoch': 3.34}\n",
            "{'loss': 2.1617, 'grad_norm': 7.533310413360596, 'learning_rate': 3.9953875723534204e-05, 'epoch': 3.35}\n",
            "{'loss': 2.3815, 'grad_norm': 8.5891752243042, 'learning_rate': 3.991751149595702e-05, 'epoch': 3.35}\n",
            "{'loss': 2.4884, 'grad_norm': 16.36680030822754, 'learning_rate': 3.988109818886825e-05, 'epoch': 3.36}\n",
            "{'loss': 1.6763, 'grad_norm': 11.265892028808594, 'learning_rate': 3.9844635922069885e-05, 'epoch': 3.36}\n",
            "{'loss': 1.9918, 'grad_norm': 3.6217169761657715, 'learning_rate': 3.980812481552496e-05, 'epoch': 3.37}\n",
            "{'loss': 2.129, 'grad_norm': 10.12528133392334, 'learning_rate': 3.9771564989357215e-05, 'epoch': 3.37}\n",
            "{'loss': 2.0988, 'grad_norm': 10.011048316955566, 'learning_rate': 3.973495656385071e-05, 'epoch': 3.38}\n",
            "{'loss': 2.2012, 'grad_norm': 4.031487941741943, 'learning_rate': 3.969829965944933e-05, 'epoch': 3.38}\n",
            "{'loss': 2.1561, 'grad_norm': 8.670008659362793, 'learning_rate': 3.966159439675653e-05, 'epoch': 3.39}\n",
            "{'loss': 2.2493, 'grad_norm': 10.9827299118042, 'learning_rate': 3.962484089653482e-05, 'epoch': 3.4}\n",
            "{'loss': 2.1166, 'grad_norm': 11.540953636169434, 'learning_rate': 3.958803927970544e-05, 'epoch': 3.4}\n",
            "{'loss': 2.1712, 'grad_norm': 13.41198444366455, 'learning_rate': 3.955118966734791e-05, 'epoch': 3.41}\n",
            "{'loss': 2.2694, 'grad_norm': 12.005912780761719, 'learning_rate': 3.9514292180699694e-05, 'epoch': 3.41}\n",
            "{'loss': 2.2457, 'grad_norm': 8.143156051635742, 'learning_rate': 3.9477346941155745e-05, 'epoch': 3.42}\n",
            "{'loss': 2.1007, 'grad_norm': 7.871368885040283, 'learning_rate': 3.9440354070268115e-05, 'epoch': 3.42}\n",
            "{'loss': 2.1374, 'grad_norm': 3.6218044757843018, 'learning_rate': 3.940331368974558e-05, 'epoch': 3.43}\n",
            "{'loss': 2.3652, 'grad_norm': 11.707033157348633, 'learning_rate': 3.9366225921453226e-05, 'epoch': 3.43}\n",
            "{'loss': 2.1009, 'grad_norm': 13.108495712280273, 'learning_rate': 3.9329090887412047e-05, 'epoch': 3.44}\n",
            "{'loss': 2.267, 'grad_norm': 6.465857028961182, 'learning_rate': 3.9291908709798544e-05, 'epoch': 3.44}\n",
            "{'loss': 2.0957, 'grad_norm': 9.110549926757812, 'learning_rate': 3.925467951094431e-05, 'epoch': 3.45}\n",
            "{'loss': 1.9865, 'grad_norm': 4.302226543426514, 'learning_rate': 3.921740341333567e-05, 'epoch': 3.46}\n",
            "{'loss': 2.0309, 'grad_norm': 8.531427383422852, 'learning_rate': 3.9180080539613215e-05, 'epoch': 3.46}\n",
            "{'loss': 2.1772, 'grad_norm': 15.205121994018555, 'learning_rate': 3.914271101257146e-05, 'epoch': 3.47}\n",
            "{'loss': 2.2732, 'grad_norm': 10.216451644897461, 'learning_rate': 3.9105294955158394e-05, 'epoch': 3.47}\n",
            "{'loss': 2.1021, 'grad_norm': 43.88572692871094, 'learning_rate': 3.90678324904751e-05, 'epoch': 3.48}\n",
            "{'loss': 1.8178, 'grad_norm': 22.011323928833008, 'learning_rate': 3.903032374177534e-05, 'epoch': 3.48}\n",
            "{'loss': 2.1161, 'grad_norm': 8.781625747680664, 'learning_rate': 3.8992768832465176e-05, 'epoch': 3.49}\n",
            " 35% 6392/18320 [2:46:51<2:00:22,  1.65it/s]Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\", line 3318, in training_step\n",
            "    loss = self.compute_loss(model, inputs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\", line 3363, in compute_loss\n",
            "    outputs = model(**inputs)\n",
            "              ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/utils/operations.py\", line 819, in forward\n",
            "    return model_forward(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/utils/operations.py\", line 807, in __call__\n",
            "    return convert_to_fp32(self.model_forward(*args, **kwargs))\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/amp/autocast_mode.py\", line 44, in decorate_autocast\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/chatterbox-finetuning/src/finetune_t3.py\", line 380, in forward\n",
            "    loss_text, loss_speech, speech_logits = self.t3.loss(\n",
            "                                            ^^^^^^^^^^^^^\n",
            "  File \"/content/chatterbox-finetuning/src/chatterbox/models/t3/t3.py\", line 231, in loss\n",
            "    out = self.forward(\n",
            "          ^^^^^^^^^^^^^\n",
            "  File \"/content/chatterbox-finetuning/src/chatterbox/models/t3/t3.py\", line 136, in forward\n",
            "    tfmr_out = self.tfmr.forward(\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\", line 1001, in forward\n",
            "    layer_outputs = decoder_layer(\n",
            "                    ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\", line 750, in forward\n",
            "    hidden_states = self.mlp(hidden_states)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\", line 309, in forward\n",
            "    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
            "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py\", line 431, in forward\n",
            "    def forward(self, input: Tensor) -> Tensor:\n",
            "\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/chatterbox-finetuning/src/finetune_t3.py\", line 627, in <module>\n",
            "    main()\n",
            "  File \"/content/chatterbox-finetuning/src/finetune_t3.py\", line 592, in main\n",
            "    train_result = trainer_instance.train(resume_from_checkpoint=training_args.resume_from_checkpoint)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\", line 1938, in train\n",
            "    return inner_training_loop(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\", line 2279, in _inner_training_loop\n",
            "    tr_loss_step = self.training_step(model, inputs)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\", line 3317, in training_step\n",
            "    with self.compute_loss_context_manager():\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/contextlib.py\", line 778, in __exit__\n",
            "    def __exit__(self, *excinfo):\n",
            "\n",
            "KeyboardInterrupt\n",
            " 35%|â–ˆâ–ˆâ–ˆâ–      | 6392/18320 [2:47:02<5:11:43,  1.57s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from safetensors.torch import load_file, save_file\n",
        "import os\n",
        "\n",
        "# --- Cáº¤U HÃŒNH ÄÆ¯á»œNG DáºªN ---\n",
        "# Trá» Ä‘áº¿n file t3_cfg.safetensors trong thÆ° má»¥c checkpoint cá»§a báº¡n\n",
        "checkpoint_path = \"/content/drive/MyDrive/checkpoints/chatterbox_vietnamese_multispeaker_v1/checkpoint-2000/model.safetensors\"\n",
        "# --------------------------\n",
        "output_path = \"/content/chatterbox-finetuning/infer/t3_cfg.safetensors\"\n",
        "print(f\"Äang xá»­ lÃ½ file: {checkpoint_path}\")\n",
        "\n",
        "if not os.path.exists(checkpoint_path):\n",
        "    print(\"âŒ Lá»—i: KhÃ´ng tÃ¬m tháº¥y file checkpoint! Kiá»ƒm tra láº¡i Ä‘Æ°á»ng dáº«n.\")\n",
        "else:\n",
        "    # 1. Load file checkpoint hiá»‡n táº¡i\n",
        "    try:\n",
        "        state_dict = load_file(checkpoint_path)\n",
        "    except:\n",
        "        # PhÃ²ng trÆ°á»ng há»£p nÃ³ lÃ  file .pt/.bin chá»© khÃ´ng pháº£i safetensors\n",
        "        state_dict = torch.load(checkpoint_path, map_location=\"cpu\")\n",
        "\n",
        "    # 2. Táº¡o dict má»›i vÃ  sá»­a tÃªn key\n",
        "    new_state_dict = {}\n",
        "    fixed_count = 0\n",
        "    for key, value in state_dict.items():\n",
        "        if key.startswith(\"t3.\"):\n",
        "            # Cáº¯t bá» 3 kÃ½ tá»± Ä‘áº§u (\"t3.\")\n",
        "            new_key = key[3:]\n",
        "            new_state_dict[new_key] = value\n",
        "            fixed_count += 1\n",
        "        else:\n",
        "            new_state_dict[key] = value\n",
        "\n",
        "    # 3. LÆ°u Ä‘Ã¨ láº¡i file cÅ© (hoáº·c lÆ°u ra file má»›i tÃ¹y báº¡n)\n",
        "    if fixed_count > 0:\n",
        "        print(f\"âœ… ÄÃ£ tÃ¬m tháº¥y vÃ  sá»­a {fixed_count} keys bá»‹ thá»«a 't3.'.\")\n",
        "\n",
        "        # Backup file cÅ© cho cháº¯c Äƒn\n",
        "        os.rename(checkpoint_path, checkpoint_path + \".bak\")\n",
        "\n",
        "        # LÆ°u file má»›i Ä‘Ã£ sá»­a\n",
        "        save_file(new_state_dict, output_path)\n",
        "        print(f\"ğŸ‰ ÄÃ£ lÆ°u file Ä‘Ã£ sá»­a táº¡i: {output_path}\")\n",
        "        print(\"ğŸ‘‰ BÃ¢y giá» báº¡n cÃ³ thá»ƒ cháº¡y láº¡i code Gradio!\")\n",
        "    else:\n",
        "        print(\"âš ï¸ File nÃ y cÃ³ váº» Ä‘Ã£ sáº¡ch (khÃ´ng cÃ³ prefix 't3.'), khÃ´ng cáº§n sá»­a.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjna-XsT481l",
        "outputId": "ddda50fd-9cce-4da0-83a4-85c2dd8210c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Äang xá»­ lÃ½ file: /content/chatterbox-finetuning/viterbox/t3_cfg.safetensors\n",
            "âœ… ÄÃ£ tÃ¬m tháº¥y vÃ  sá»­a 292 keys bá»‹ thá»«a 't3.'.\n",
            "ğŸ‰ ÄÃ£ lÆ°u file Ä‘Ã£ sá»­a táº¡i: /content/chatterbox-finetuning/viterbox/t3_cfg.safetensors\n",
            "ğŸ‘‰ BÃ¢y giá» báº¡n cÃ³ thá»ƒ cháº¡y láº¡i code Gradio!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/chatterbox-finetuning/src\n",
        "!python gradio_local.py\n",
        "# Sá»­a chatterbox/models/t3/modules/t3config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnWgDzmt1ivh",
        "outputId": "dc66925f-7fa2-406f-c7ad-a0454c37e27b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/chatterbox-finetuning/src\n",
            "Starting Gradio server...\n",
            "* Running on local URL:  http://0.0.0.0:7860\n",
            "* Running on public URL: https://5300cc6e436dc70e40.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
            ">>> Setting vocab size to 2549 for Vietnamese model...\n",
            "Reloading model inside generate function...\n",
            "/usr/local/lib/python3.12/dist-packages/diffusers/models/lora.py:393: FutureWarning: `LoRACompatibleLinear` is deprecated and will be removed in version 1.0.0. Use of `LoRACompatibleLinear` is deprecated. Please switch to PEFT backend by installing PEFT: `pip install peft`.\n",
            "  deprecate(\"LoRACompatibleLinear\", \"1.0.0\", deprecation_message)\n",
            "/usr/local/lib/python3.12/dist-packages/perth/perth_net/perth_net_implicit/checkpoint_manager.py:36: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(ckpts[-1], map_location=\"cpu\")\n",
            "loaded PerthNet (Implicit) at step 250,000\n",
            "Model loaded successfully on: cuda\n",
            "/usr/local/lib/python3.12/dist-packages/perth/perth_net/perth_net_implicit/checkpoint_manager.py:36: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(ckpts[-1], map_location=\"cpu\")\n",
            "loaded PerthNet (Implicit) at step 250,000\n",
            "WARNING:root:Reference mel length is not equal to 2 * reference token length.\n",
            "\n",
            "/usr/lib/python3.12/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
            "  self.gen = func(*args, **kwds)\n",
            "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
            "LlamaModel is using LlamaSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n",
            "Sampling:   9% 90/1000 [00:02<00:26, 33.87it/s]\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/processing_utils.py:777: UserWarning: Trying to convert audio automatically from float32 to 16-bit int format.\n",
            "  warnings.warn(warning.format(data.dtype))\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 3158, in block_thread\n",
            "    time.sleep(0.1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/chatterbox-finetuning/src/gradio_local.py\", line 105, in <module>\n",
            "    ).launch(share=True, server_name=\"0.0.0.0\", debug=True)\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 3055, in launch\n",
            "    self.block_thread()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 3162, in block_thread\n",
            "    self.server.close()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/http_server.py\", line 64, in close\n",
            "    def close(self):\n",
            "\n",
            "KeyboardInterrupt\n",
            "Killing tunnel 0.0.0.0:7860 <> https://5300cc6e436dc70e40.gradio.live\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/chatterbox-finetuning/src/gradio_local.py\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import gradio as gr\n",
        "from chatterbox.tts import ChatterboxTTS\n",
        "# [QUAN TRá»ŒNG] Import class config Ä‘á»ƒ hack size\n",
        "from chatterbox.models.t3.modules.t3_config import T3Config\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# --- HACK Cáº¤U HÃŒNH NGAY Tá»ª Äáº¦U FILE ---\n",
        "# DÃ²ng nÃ y cá»±c ká»³ quan trá»ng, nÃ³ Ã©p toÃ n bá»™ model khá»Ÿi táº¡o vá»›i size 2549\n",
        "print(\">>> FORCING VOCAB SIZE TO 2549 <<<\")\n",
        "T3Config.text_tokens_dict_size = 2549\n",
        "# --------------------------------------\n",
        "\n",
        "def set_seed(seed: int):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "def load_model():\n",
        "    print(\"Loading model from /content/chatterbox-finetuning/infer ...\")\n",
        "    # Äáº£m báº£o folder infer Ä‘Ã£ cÃ³ Ä‘á»§: t3_cfg.safetensors, tokenizer.json, ve, s3gen\n",
        "    model = ChatterboxTTS.from_local(ckpt_dir=str(\"/content/chatterbox-finetuning/infer\"), device=DEVICE)\n",
        "    print(f\"Model loaded successfully on: {DEVICE}\")\n",
        "    print(f\"Current Vocab Size in Model: {model.t3.text_emb.weight.shape[0]}\")\n",
        "    return model\n",
        "\n",
        "def generate(model, text, audio_prompt_path, exaggeration, temperature, seed_num, cfgw):\n",
        "    if model is None:\n",
        "        T3Config.text_tokens_dict_size = 2549 # Hack láº¡i láº§n ná»¯a cho cháº¯c\n",
        "        model = ChatterboxTTS.from_local(ckpt_dir=str(\"/content/chatterbox-finetuning/infer\"), device=DEVICE)\n",
        "\n",
        "    if seed_num != 0:\n",
        "        set_seed(int(seed_num))\n",
        "\n",
        "    # Xá»­ lÃ½ náº¿u khÃ´ng cÃ³ file máº«u (Reference Audio)\n",
        "    if audio_prompt_path is None:\n",
        "        print(\"Warning: No reference audio provided!\")\n",
        "        # Tráº£ vá» lá»—i hoáº·c im láº·ng tÃ¹y báº¡n\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        wav = model.generate(\n",
        "            text,\n",
        "            audio_prompt_path=audio_prompt_path,\n",
        "            exaggeration=exaggeration,\n",
        "            temperature=temperature,\n",
        "            cfg_weight=cfgw,\n",
        "        )\n",
        "        return (model.sr, wav.squeeze(0).cpu().numpy())\n",
        "    except Exception as e:\n",
        "        print(f\"Error generation: {e}\")\n",
        "        return None\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    model_state = gr.State(None)\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            text = gr.Textbox(\n",
        "                value=\"Xin chÃ o, tÃ´i lÃ  trÃ­ tuá»‡ nhÃ¢n táº¡o nÃ³i tiáº¿ng Viá»‡t.\",\n",
        "                label=\"Text Input\",\n",
        "                max_lines=5\n",
        "            )\n",
        "            # Input Audio (Báº¯t buá»™c pháº£i cÃ³ Ä‘á»ƒ clone giá»ng)\n",
        "            ref_wav = gr.Audio(sources=[\"upload\", \"microphone\"], type=\"filepath\", label=\"Reference Audio (Voice Clone)\", value=None)\n",
        "\n",
        "            exaggeration = gr.Slider(0.25, 2, step=.05, label=\"Exaggeration\", value=.5)\n",
        "            cfg_weight = gr.Slider(0.0, 1, step=.05, label=\"CFG/Pace\", value=0.5)\n",
        "\n",
        "            with gr.Accordion(\"More options\", open=False):\n",
        "                seed_num = gr.Number(value=0, label=\"Random seed\")\n",
        "                temp = gr.Slider(0.05, 5, step=.05, label=\"Temperature\", value=.8)\n",
        "\n",
        "            run_btn = gr.Button(\"Generate\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column():\n",
        "            audio_output = gr.Audio(label=\"Output Audio\")\n",
        "\n",
        "    demo.load(fn=load_model, inputs=[], outputs=model_state)\n",
        "\n",
        "    run_btn.click(\n",
        "        fn=generate,\n",
        "        inputs=[model_state, text, ref_wav, exaggeration, temp, seed_num, cfg_weight],\n",
        "        outputs=audio_output,\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Starting Gradio...\")\n",
        "    demo.queue().launch(share=True, server_name=\"0.0.0.0\", debug=True)"
      ],
      "metadata": {
        "id": "3_QXjIAFGC9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "import torch\n",
        "from tokenizers import Tokenizer\n",
        "\n",
        "\n",
        "# Special tokens\n",
        "SOT = \"[START]\"\n",
        "EOT = \"[STOP]\"\n",
        "UNK = \"[UNK]\"\n",
        "SPACE = \"[SPACE]\"\n",
        "SPECIAL_TOKENS = [SOT, EOT, UNK, SPACE, \"[PAD]\", \"[SEP]\", \"[CLS]\", \"[MASK]\"]\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class EnTokenizer:\n",
        "    def __init__(self, vocab_file_path):\n",
        "        self.tokenizer: Tokenizer = Tokenizer.from_file(vocab_file_path)\n",
        "        self.check_vocabset_sot_eot()\n",
        "\n",
        "    def check_vocabset_sot_eot(self):\n",
        "        voc = self.tokenizer.get_vocab()\n",
        "        assert SOT in voc\n",
        "        assert EOT in voc\n",
        "\n",
        "    def text_to_tokens(self, text: str):\n",
        "        text_tokens = self.encode(text)\n",
        "        text_tokens = torch.IntTensor(text_tokens).unsqueeze(0)\n",
        "        return text_tokens\n",
        "\n",
        "    def encode( self, txt: str, verbose=False):\n",
        "        \"\"\"\n",
        "        clean_text > (append `lang_id`) > replace SPACE > encode text using Tokenizer\n",
        "        \"\"\"\n",
        "        txt = txt.replace(' ', SPACE)\n",
        "        code = self.tokenizer.encode(txt)\n",
        "        ids = code.ids\n",
        "        return ids\n",
        "\n",
        "    def decode(self, seq):\n",
        "        if isinstance(seq, torch.Tensor):\n",
        "            seq = seq.cpu().numpy()\n",
        "\n",
        "        txt: str = self.tokenizer.decode(seq,\n",
        "        skip_special_tokens=False)\n",
        "        txt = txt.replace(' ', '')\n",
        "        txt = txt.replace(SPACE, ' ')\n",
        "        txt = txt.replace(EOT, '')\n",
        "        txt = txt.replace(UNK, '')\n",
        "        return txt\n",
        "\n",
        "\n",
        "class MTLTokenizer(EnTokenizer):\n",
        "    \"\"\"Multilingual tokenizer that handles language_id prefix\"\"\"\n",
        "\n",
        "    def text_to_tokens(self, text: str, language_id: str = None):\n",
        "        \"\"\"Convert text to tokens with optional language prefix\"\"\"\n",
        "        if language_id:\n",
        "            text = f\"[{language_id}] {text}\"\n",
        "        text_tokens = self.encode(text)\n",
        "        text_tokens = torch.IntTensor(text_tokens).unsqueeze(0)\n",
        "        return text_tokens"
      ],
      "metadata": {
        "id": "R3plv3KPtWl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import logging\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Dict, List, Optional, Union, Any\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "import librosa\n",
        "import numpy as np\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from transformers import (\n",
        "    HfArgumentParser,\n",
        "    EarlyStoppingCallback,\n",
        "    set_seed,\n",
        "    TrainerCallback,\n",
        "    Trainer,\n",
        "    PretrainedConfig\n",
        ")\n",
        "from transformers import TrainingArguments as HfTrainingArguments\n",
        "from datasets import load_dataset, DatasetDict, VerificationMode, Audio\n",
        "import datasets\n",
        "\n",
        "from chatterbox.tts import ChatterboxTTS, Conditionals, punc_norm, REPO_ID\n",
        "from chatterbox.models.t3.t3 import T3, T3Cond\n",
        "from chatterbox.models.t3.modules.t3_config import T3Config\n",
        "from chatterbox.models.s3tokenizer import S3_SR, SPEECH_VOCAB_SIZE\n",
        "from chatterbox.models.s3gen import S3GEN_SR\n",
        "\n",
        "#from chatterbox.utils.t3data_arguments import DataArguments\n",
        "#from chatterbox.utils.t3dataset import SpeechFineTuningDataset\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# --- Custom Training Arguments ---\n",
        "@dataclass\n",
        "class CustomTrainingArguments(HfTrainingArguments):\n",
        "    early_stopping_patience: Optional[int] = field(\n",
        "        default=None, metadata={\"help\": \"Enable early stopping with specified patience. Default: None (disabled).\"}\n",
        "    )\n",
        "\n",
        "# --- Argument Classes (ModelArguments, DataArguments) ---\n",
        "@dataclass\n",
        "class ModelArguments:\n",
        "    model_name_or_path: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n",
        "    )\n",
        "    local_model_dir: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\"help\": \"Path to local directory containing ve.safetensors, t3_cfg.safetensors, etc. Overrides model_name_or_path for loading.\"}\n",
        "    )\n",
        "    cache_dir: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\"help\": \"Where do you want to store the pretrained models downloaded from huggingface.co\"},\n",
        "    )\n",
        "    freeze_voice_encoder: bool = field(default=True, metadata={\"help\": \"Freeze the Voice Encoder.\"})\n",
        "    freeze_s3gen: bool = field(default=True, metadata={\"help\": \"Freeze the S3Gen model (speech token to waveform).\"})\n",
        "\n",
        "@dataclass\n",
        "class DataArguments:\n",
        "    dataset_dir: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\"help\": \"Path to the directory containing audio files and text files. Used if dataset_name is not provided.\"}\n",
        "    )\n",
        "    metadata_file: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\"help\": \"Path to a metadata file. Used if dataset_name is not provided.\"}\n",
        "    )\n",
        "    dataset_name: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\"help\": \"The name of the dataset to use (via the Hugging Face datasets library).\"}\n",
        "    )\n",
        "    dataset_config_name: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\"help\": \"The configuration name of the dataset to use (via the Hugging Face datasets library).\"}\n",
        "    )\n",
        "    train_split_name: str = field(default=\"train\", metadata={\"help\": \"The name of the training data set split.\"})\n",
        "    eval_split_name: Optional[str] = field(default=\"validation\", metadata={\"help\": \"The name of the evaluation data set split.\"})\n",
        "    text_column_name: str = field(default=\"text\", metadata={\"help\": \"The name of the text column in the HF dataset.\"})\n",
        "    audio_column_name: str = field(default=\"audio\", metadata={\"help\": \"The name of the audio column in the HF dataset.\"})\n",
        "    max_text_len: int = field(default=256, metadata={\"help\": \"Maximum length of text tokens (including BOS/EOS).\"})\n",
        "    max_speech_len: int = field(default=800, metadata={\"help\": \"Maximum length of speech tokens (including BOS/EOS).\"})\n",
        "    audio_prompt_duration_s: float = field(\n",
        "        default=3.0, metadata={\"help\": \"Duration of audio (from start) to use for T3 conditioning prompt tokens (in seconds).\"}\n",
        "    )\n",
        "    eval_split_size: float = field(\n",
        "        default=0.0005, metadata={\"help\": \"Fraction of data to use for evaluation if splitting manually. Not used if dataset_name provides eval split.\"}\n",
        "    )\n",
        "    preprocessing_num_workers: Optional[int] = field(\n",
        "        default=None,\n",
        "        metadata={\"help\": \"The number of processes to use for the preprocessing.\"},\n",
        "    )\n",
        "    ignore_verifications: bool = field(\n",
        "        default=False, metadata={\"help\":\"Set to true to ignore dataset verifications.\"}\n",
        "    )\n",
        "\n",
        "# --- Dataset Class ---\n",
        "class SpeechFineTuningDataset(Dataset):\n",
        "    def __init__(self,\n",
        "                 data_args: DataArguments,\n",
        "                 chatterbox_model: ChatterboxTTS,\n",
        "                 t3_config: T3Config,\n",
        "                 hf_dataset: Union[datasets.Dataset, List[Dict[str, str]]],\n",
        "                 is_hf_format: bool):\n",
        "        self.data_args = data_args\n",
        "        self.chatterbox_model = chatterbox_model\n",
        "        self.chatterbox_t3_config = t3_config\n",
        "        self.dataset_source = hf_dataset\n",
        "        self.is_hf_format = is_hf_format\n",
        "\n",
        "        self.text_tokenizer = chatterbox_model.tokenizer\n",
        "        self.speech_tokenizer: S3Tokenizer = chatterbox_model.s3gen.tokenizer\n",
        "        self.voice_encoder = chatterbox_model.ve\n",
        "\n",
        "        self.s3_sr = S3_SR\n",
        "        self.enc_cond_audio_len_samples = int(data_args.audio_prompt_duration_s * self.s3_sr)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset_source)\n",
        "\n",
        "    def _load_audio_text_from_item(self, idx):\n",
        "        if self.is_hf_format:\n",
        "            item = self.dataset_source[idx]\n",
        "            text = item[self.data_args.text_column_name]\n",
        "            audio_data = item[self.data_args.audio_column_name]\n",
        "\n",
        "            if isinstance(audio_data, str):\n",
        "                 wav_array, original_sr = librosa.load(audio_data, sr=None, mono=True)\n",
        "            elif isinstance(audio_data, dict) and \"array\" in audio_data and \"sampling_rate\" in audio_data:\n",
        "                wav_array = audio_data[\"array\"]\n",
        "                original_sr = audio_data[\"sampling_rate\"]\n",
        "            else:\n",
        "                logger.error(f\"Unexpected audio data format for item {idx}: {type(audio_data)}. Skipping.\")\n",
        "                return None, None\n",
        "\n",
        "            if not isinstance(wav_array, np.ndarray):\n",
        "                logger.error(f\"Audio array is not numpy for item {idx}: {type(wav_array)}. Skipping.\")\n",
        "                return None, None\n",
        "\n",
        "            if original_sr != self.s3_sr:\n",
        "                wav_16k = librosa.resample(wav_array, orig_sr=original_sr, target_sr=self.s3_sr)\n",
        "            else:\n",
        "                wav_16k = wav_array.copy()\n",
        "\n",
        "            if wav_16k.ndim > 1: wav_16k = librosa.to_mono(wav_16k)\n",
        "            if wav_16k.dtype != np.float32:\n",
        "                wav_16k = wav_16k.astype(np.float32)\n",
        "\n",
        "            item_info_for_log = f\"Item {idx} (text: '{text[:30]}...', audio_len: {len(wav_16k)}, audio_dtype: {wav_16k.dtype})\"\n",
        "\n",
        "            return wav_16k, text\n",
        "        else:\n",
        "            item = self.dataset_source[idx]\n",
        "            audio_path = item[\"audio\"]\n",
        "            text = item[\"text\"]\n",
        "            try:\n",
        "                wav_16k, _ = librosa.load(audio_path, sr=self.s3_sr, mono=True)\n",
        "                return wav_16k, text\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error loading audio {audio_path}: {e}\")\n",
        "                return None, None\n",
        "\n",
        "    def __getitem__(self, idx) -> Optional[Dict[str, Union[torch.Tensor, float]]]:\n",
        "        wav_16k, text = self._load_audio_text_from_item(idx)\n",
        "        if wav_16k is None or text is None or len(wav_16k) == 0:\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            speaker_emb_np = self.voice_encoder.embeds_from_wavs([wav_16k], sample_rate=self.s3_sr)\n",
        "            speaker_emb = torch.from_numpy(speaker_emb_np[0])\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error getting speaker embedding for item {idx}: {e}. Skipping.\")\n",
        "            return None\n",
        "\n",
        "        normalized_text = punc_norm(text)\n",
        "        raw_text_tokens = self.text_tokenizer.text_to_tokens(normalized_text).squeeze(0)\n",
        "        text_tokens = F.pad(raw_text_tokens, (1, 0), value=self.chatterbox_t3_config.start_text_token)\n",
        "        text_tokens = F.pad(text_tokens, (0, 1), value=self.chatterbox_t3_config.stop_text_token)\n",
        "        if len(text_tokens) > self.data_args.max_text_len:\n",
        "            text_tokens = text_tokens[:self.data_args.max_text_len-1]\n",
        "            text_tokens = torch.cat([text_tokens, torch.tensor([self.chatterbox_t3_config.stop_text_token], device=text_tokens.device)])\n",
        "        text_token_len = torch.tensor(len(text_tokens), dtype=torch.long)\n",
        "\n",
        "        try:\n",
        "            raw_speech_tokens_batch, speech_token_lengths_batch = self.speech_tokenizer.forward([wav_16k])\n",
        "            if raw_speech_tokens_batch is None or speech_token_lengths_batch is None:\n",
        "                logger.error(f\"S3Tokenizer returned None for item {idx}. Skipping.\")\n",
        "                return None\n",
        "            raw_speech_tokens = raw_speech_tokens_batch.squeeze(0)[:speech_token_lengths_batch.squeeze(0).item()]\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error getting speech tokens for item {idx}: {e}. Skipping.\")\n",
        "            return None\n",
        "\n",
        "        speech_tokens = F.pad(raw_speech_tokens, (1, 0), value=self.chatterbox_t3_config.start_speech_token)\n",
        "        speech_tokens = F.pad(speech_tokens, (0, 1), value=self.chatterbox_t3_config.stop_speech_token)\n",
        "        if len(speech_tokens) > self.data_args.max_speech_len:\n",
        "            speech_tokens = speech_tokens[:self.data_args.max_speech_len-1]\n",
        "            speech_tokens = torch.cat([speech_tokens, torch.tensor([self.chatterbox_t3_config.stop_speech_token], device=speech_tokens.device)])\n",
        "        speech_token_len = torch.tensor(len(speech_tokens), dtype=torch.long)\n",
        "\n",
        "        cond_audio_segment = wav_16k[:self.enc_cond_audio_len_samples]\n",
        "        if len(cond_audio_segment) == 0 :\n",
        "            cond_prompt_speech_tokens = torch.zeros(self.chatterbox_t3_config.speech_cond_prompt_len, dtype=torch.long)\n",
        "        else:\n",
        "            try:\n",
        "                cond_prompt_tokens_batch, _ = self.speech_tokenizer.forward([cond_audio_segment], max_len=self.chatterbox_t3_config.speech_cond_prompt_len)\n",
        "                if cond_prompt_tokens_batch is None:\n",
        "                    #  logger.error(f\"S3Tokenizer returned None for cond_prompt for item {idx}. Using zeros.\")\n",
        "                     cond_prompt_speech_tokens = torch.zeros(self.chatterbox_t3_config.speech_cond_prompt_len, dtype=torch.long)\n",
        "                else:\n",
        "                    cond_prompt_speech_tokens = cond_prompt_tokens_batch.squeeze(0)\n",
        "            except Exception as e:\n",
        "                # logger.error(f\"Error getting cond prompt tokens for item {idx}: {e}. Using zeros.\")\n",
        "                cond_prompt_speech_tokens = torch.zeros(self.chatterbox_t3_config.speech_cond_prompt_len, dtype=torch.long)\n",
        "\n",
        "        if cond_prompt_speech_tokens.size(0) != self.chatterbox_t3_config.speech_cond_prompt_len:\n",
        "            current_len = cond_prompt_speech_tokens.size(0)\n",
        "            target_len = self.chatterbox_t3_config.speech_cond_prompt_len\n",
        "            if current_len > target_len: cond_prompt_speech_tokens = cond_prompt_speech_tokens[:target_len]\n",
        "            else: cond_prompt_speech_tokens = F.pad(cond_prompt_speech_tokens, (0, target_len - current_len), value=0)\n",
        "\n",
        "        emotion_adv_scalar=0.5\n",
        "        emotion_adv_scalar_tensor = torch.tensor(emotion_adv_scalar, dtype=torch.float)\n",
        "\n",
        "        return_dict = {\n",
        "            \"text_tokens\": text_tokens.long(),\n",
        "            \"text_token_lens\": text_token_len.long(),\n",
        "            \"speech_tokens\": speech_tokens.long(),\n",
        "            \"speech_token_lens\": speech_token_len.long(),\n",
        "            \"t3_cond_speaker_emb\": speaker_emb.float(),\n",
        "            \"t3_cond_prompt_speech_tokens\": cond_prompt_speech_tokens.long(),\n",
        "            \"t3_cond_emotion_adv\": emotion_adv_scalar_tensor,\n",
        "        }\n",
        "\n",
        "        return return_dict\n",
        "\n",
        "# --- Data Collator ---\n",
        "@dataclass\n",
        "class SpeechDataCollator:\n",
        "    t3_config: T3Config  # Chatterbox T3Config\n",
        "    text_pad_token_id: int\n",
        "    speech_pad_token_id: int\n",
        "\n",
        "    def __call__(self, features: List[Optional[Dict[str, Any]]]) -> Dict[str, Any]:\n",
        "        valid_features = [f for f in features if f is not None]\n",
        "\n",
        "        if not valid_features:\n",
        "            logger.warning(\"SpeechDataCollator received no valid features. Returning empty batch.\")\n",
        "            return {}\n",
        "        features = valid_features\n",
        "\n",
        "        batch_size = len(features)\n",
        "        text_tokens_list = [f[\"text_tokens\"] for f in features]\n",
        "        speech_tokens_list = [f[\"speech_tokens\"] for f in features]\n",
        "        max_text_len = max(len(t) for t in text_tokens_list)\n",
        "        max_speech_len = max(len(t) for t in speech_tokens_list)\n",
        "\n",
        "        # Pad text tokens\n",
        "        padded_text_tokens = torch.stack([\n",
        "            F.pad(t, (0, max_text_len - len(t)), value=self.text_pad_token_id)\n",
        "            for t in text_tokens_list\n",
        "        ])  # shape: (B, max_text_len)\n",
        "\n",
        "        # Pad speech tokens\n",
        "        padded_speech_tokens = torch.stack([\n",
        "            F.pad(s, (0, max_speech_len - len(s)), value=self.speech_pad_token_id)\n",
        "            for s in speech_tokens_list\n",
        "        ])  # shape: (B, max_speech_len)\n",
        "\n",
        "        # Collect lengths\n",
        "        text_token_lens = torch.stack([f[\"text_token_lens\"] for f in features])      # (B,)\n",
        "        speech_token_lens = torch.stack([f[\"speech_token_lens\"] for f in features])  # (B,)\n",
        "\n",
        "        # Collect conditionals\n",
        "        t3_cond_speaker_emb = torch.stack([f[\"t3_cond_speaker_emb\"] for f in features])             # (B, D_speaker)\n",
        "        t3_cond_prompt_speech_tokens = torch.stack([f[\"t3_cond_prompt_speech_tokens\"] for f in features])  # (B, prompt_len)\n",
        "        emotion_adv_scalars = torch.stack([f[\"t3_cond_emotion_adv\"] for f in features])  # (B, 1, 1)\n",
        "        t3_cond_emotion_adv = emotion_adv_scalars.view(batch_size, 1, 1)\n",
        "\n",
        "        IGNORE_ID = -100\n",
        "        prompt_len = self.t3_config.speech_cond_prompt_len\n",
        "\n",
        "        # --- Build labels_text ---\n",
        "        # Shift off BOS from padded_text_tokens: new length = max_text_len - 1\n",
        "        shifted_text = padded_text_tokens[:, 1:].contiguous()  # shape: (B, max_text_len - 1)\n",
        "        T_text = shifted_text.size(1)\n",
        "\n",
        "        # Mask positions t >= (text_len - 1)\n",
        "        text_lens_minus_one = (text_token_lens - 1).clamp(min=0)  # (B,)\n",
        "        arange_text = torch.arange(T_text, device=shifted_text.device)  # (T_text,)\n",
        "        mask_pad_text = arange_text[None] >= text_lens_minus_one[:, None]  # (B, T_text)\n",
        "\n",
        "        labels_text = shifted_text.clone()           # (B, T_text)\n",
        "        labels_text[mask_pad_text] = IGNORE_ID       # set pad/beyond to -100\n",
        "\n",
        "        # --- Build labels_speech ---\n",
        "        # Shift off BOS from padded_speech_tokens: new length = max_speech_len - 1\n",
        "        shifted_speech = padded_speech_tokens[:, 1:].contiguous()  # shape: (B, max_speech_len - 1)\n",
        "        T_speech = shifted_speech.size(1)\n",
        "\n",
        "        # Mask positions t >= (speech_len - 1)\n",
        "        speech_lens_minus_one = (speech_token_lens - 1).clamp(min=0)  # (B,)\n",
        "        arange_speech = torch.arange(T_speech, device=shifted_speech.device)  # (T_speech,)\n",
        "        mask_pad_speech = arange_speech[None] >= speech_lens_minus_one[:, None]  # (B, T_speech)\n",
        "\n",
        "        # Mask positions t < prompt_len\n",
        "        mask_prompt = arange_speech[None] < prompt_len  # (1, T_speech) -> broadcast to (B, T_speech)\n",
        "        mask_prompt = mask_prompt.expand(batch_size, T_speech)\n",
        "\n",
        "        # Combine masks\n",
        "        mask_speech_total = mask_pad_speech | mask_prompt  # (B, T_speech)\n",
        "\n",
        "        labels_speech = shifted_speech.clone()          # (B, T_speech)\n",
        "        labels_speech[mask_speech_total] = IGNORE_ID    # set prompt & pad to -100\n",
        "\n",
        "        return {\n",
        "            \"text_tokens\": padded_text_tokens,\n",
        "            \"text_token_lens\": text_token_lens,\n",
        "            \"speech_tokens\": padded_speech_tokens,\n",
        "            \"speech_token_lens\": speech_token_lens,\n",
        "            \"t3_cond_speaker_emb\": t3_cond_speaker_emb,\n",
        "            \"t3_cond_prompt_speech_tokens\": t3_cond_prompt_speech_tokens,\n",
        "            \"t3_cond_emotion_adv\": t3_cond_emotion_adv,\n",
        "            \"labels_text\": labels_text,       # (B, max_text_len - 1) masked with -100\n",
        "            \"labels_speech\": labels_speech,   # (B, max_speech_len - 1) masked with -100\n",
        "        }\n",
        "# --- Model Wrapper ---\n",
        "class T3ForFineTuning(torch.nn.Module):\n",
        "    def __init__(self, t3_model: T3, chatterbox_t3_config: T3Config):\n",
        "        super().__init__()\n",
        "        self.t3 = t3_model\n",
        "        self.chatterbox_t3_config = chatterbox_t3_config\n",
        "\n",
        "        class HFCompatibleConfig(PretrainedConfig):\n",
        "            model_type = \"chatterbox_t3_finetune\"\n",
        "            def __init__(self, **kwargs):\n",
        "                super().__init__(**kwargs)\n",
        "\n",
        "        hf_config_instance = HFCompatibleConfig()\n",
        "        hf_config_instance.llama_config_name = chatterbox_t3_config.llama_config_name\n",
        "        hf_config_instance.text_tokens_dict_size = chatterbox_t3_config.text_tokens_dict_size\n",
        "        hf_config_instance.speech_tokens_dict_size = chatterbox_t3_config.speech_tokens_dict_size\n",
        "        hf_config_instance.max_text_tokens = chatterbox_t3_config.max_text_tokens\n",
        "        hf_config_instance.max_speech_tokens = chatterbox_t3_config.max_speech_tokens\n",
        "        hf_config_instance.speech_cond_prompt_len = chatterbox_t3_config.speech_cond_prompt_len\n",
        "        hf_config_instance.start_text_token = chatterbox_t3_config.start_text_token\n",
        "        hf_config_instance.stop_text_token = chatterbox_t3_config.stop_text_token\n",
        "        hf_config_instance.start_speech_token = chatterbox_t3_config.start_speech_token\n",
        "        hf_config_instance.stop_speech_token = chatterbox_t3_config.stop_speech_token\n",
        "        self.config = hf_config_instance\n",
        "\n",
        "    def forward(self,\n",
        "                text_tokens,\n",
        "                text_token_lens,\n",
        "                speech_tokens,\n",
        "                speech_token_lens,\n",
        "                t3_cond_speaker_emb,\n",
        "                t3_cond_prompt_speech_tokens,\n",
        "                t3_cond_emotion_adv,\n",
        "                labels_text = None,\n",
        "                labels_speech=None):\n",
        "\n",
        "        current_t3_cond = T3Cond(\n",
        "                                speaker_emb=t3_cond_speaker_emb,\n",
        "                                cond_prompt_speech_tokens=t3_cond_prompt_speech_tokens,\n",
        "                                cond_prompt_speech_emb=None,\n",
        "                                emotion_adv=t3_cond_emotion_adv\n",
        "                                ).to(device=self.t3.device)\n",
        "\n",
        "        loss_text, loss_speech, speech_logits = self.t3.loss(\n",
        "                                t3_cond=current_t3_cond,\n",
        "                                text_tokens=text_tokens,\n",
        "                                text_token_lens=text_token_lens,\n",
        "                                speech_tokens=speech_tokens,\n",
        "                                speech_token_lens=speech_token_lens,\n",
        "                                labels_text =labels_text,\n",
        "                                labels_speech=labels_speech\n",
        "                                )\n",
        "\n",
        "        total_loss = loss_text + loss_speech\n",
        "\n",
        "        return total_loss, speech_logits\n",
        "\n",
        "\n",
        "\n",
        "trainer_instance: Optional[Trainer] = None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    global trainer_instance\n",
        "\n",
        "    parser = HfArgumentParser((ModelArguments, DataArguments, CustomTrainingArguments))\n",
        "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
        "\n",
        "    logging.basicConfig(\n",
        "        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
        "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "        level=logging.INFO if training_args.local_rank in [-1, 0] else logging.WARN,\n",
        "    )\n",
        "    logger.info(\"Training/evaluation parameters %s\", training_args)\n",
        "    logger.info(\"Model parameters %s\", model_args)\n",
        "    logger.info(\"Data parameters %s\", data_args)\n",
        "    set_seed(training_args.seed)\n",
        "\n",
        "    # ==============================================================================\n",
        "    # --- FIX 2: HACK Cáº¤U HÃŒNH (QUAN TRá»ŒNG NHáº¤T) ---\n",
        "    # Ã‰p model khá»Ÿi táº¡o vá»›i size 2549 thay vÃ¬ 704\n",
        "    # ==============================================================================\n",
        "    if model_args.local_model_dir:\n",
        "        logger.info(\"!!! DETECTED LOCAL MODEL - APPLYING VOCAB SIZE PATCH !!!\")\n",
        "        # Sá»‘ 2549 láº¥y tá»« lá»—i mismatch cá»§a báº¡n.\n",
        "        # Náº¿u sau nÃ y báº¡n thay Ä‘á»•i bá»™ tá»« Ä‘iá»ƒn, hÃ£y sá»­a sá»‘ nÃ y theo lá»—i bÃ¡o.\n",
        "        NEW_VOCAB_SIZE = 2549\n",
        "\n",
        "        # Can thiá»‡p trá»±c tiáº¿p vÃ o giÃ¡ trá»‹ máº·c Ä‘á»‹nh cá»§a class T3Config\n",
        "        # Äá»ƒ khi ChatterboxTTS.from_local gá»i T3(), nÃ³ sáº½ dÃ¹ng sá»‘ nÃ y.\n",
        "        T3Config.text_tokens_dict_size = NEW_VOCAB_SIZE\n",
        "        logger.info(f\"Forced T3Config.text_tokens_dict_size to {NEW_VOCAB_SIZE}\")\n",
        "    # ==============================================================================\n",
        "\n",
        "    logger.info(\"Loading ChatterboxTTS model...\")\n",
        "\n",
        "    original_model_dir_for_copy: Optional[Path] = None\n",
        "    if model_args.local_model_dir:\n",
        "        logger.info(f\"Loading model from local directory: {model_args.local_model_dir}\")\n",
        "        local_dir_path = Path(model_args.local_model_dir)\n",
        "        chatterbox_model = ChatterboxTTS.from_local(ckpt_dir=str(local_dir_path), device=\"cpu\")\n",
        "        original_model_dir_for_copy = local_dir_path\n",
        "    else:\n",
        "        repo_to_download = model_args.model_name_or_path or REPO_ID\n",
        "        logger.info(f\"Loading model from Hugging Face Hub: {repo_to_download}\")\n",
        "        download_dir = Path(training_args.output_dir) / \"pretrained_model_download\"\n",
        "        download_dir.mkdir(parents=True, exist_ok=True)\n",
        "        files_to_download = [\"ve.safetensors\", \"t3_cfg.safetensors\", \"s3gen.safetensors\", \"tokenizer.json\"]\n",
        "\n",
        "        from huggingface_hub import hf_hub_download as hf_download\n",
        "\n",
        "        for f in files_to_download:\n",
        "            try: hf_download(repo_id=repo_to_download, filename=f, local_dir=download_dir, local_dir_use_symlinks=False, cache_dir=model_args.cache_dir)\n",
        "            except Exception as e: logger.warning(f\"Could not download {f} from {repo_to_download}: {e}.\")\n",
        "\n",
        "        try: hf_download(repo_id=repo_to_download, filename=\"conds.pt\", local_dir=download_dir, local_dir_use_symlinks=False, cache_dir=model_args.cache_dir)\n",
        "        except: logger.info(\"conds.pt not found on Hub or failed to download for this model.\")\n",
        "\n",
        "\n",
        "        chatterbox_model = ChatterboxTTS.from_local(ckpt_dir=download_dir, device=\"cpu\")\n",
        "        original_model_dir_for_copy = download_dir\n",
        "\n",
        "    t3_model = chatterbox_model.t3\n",
        "    chatterbox_t3_config_instance = t3_model.hp\n",
        "\n",
        "    if model_args.freeze_voice_encoder:\n",
        "        for param in chatterbox_model.ve.parameters(): param.requires_grad = False\n",
        "        logger.info(\"Voice Encoder frozen.\")\n",
        "    if model_args.freeze_s3gen:\n",
        "        for param in chatterbox_model.s3gen.parameters(): param.requires_grad = False\n",
        "        logger.info(\"S3Gen model frozen.\")\n",
        "    for param in t3_model.parameters(): param.requires_grad = True\n",
        "    logger.info(\"T3 model set to trainable.\")\n",
        "\n",
        "    logger.info(\"Loading and processing dataset...\")\n",
        "    raw_datasets = DatasetDict()\n",
        "    verification_mode = VerificationMode.NO_CHECKS if data_args.ignore_verifications else VerificationMode.BASIC_CHECKS\n",
        "\n",
        "    train_hf_dataset: Union[datasets.Dataset, List[Dict[str,str]]]\n",
        "    eval_hf_dataset: Optional[Union[datasets.Dataset, List[Dict[str,str]]]] = None\n",
        "\n",
        "    if data_args.dataset_name:\n",
        "        logger.info(f\"Loading dataset '{data_args.dataset_name}' from Hugging Face Hub.\")\n",
        "        raw_datasets_loaded = load_dataset( # Use a different var name to avoid conflict with outer raw_datasets\n",
        "            data_args.dataset_name,\n",
        "            data_args.dataset_config_name,\n",
        "            cache_dir=model_args.cache_dir,\n",
        "            verification_mode=verification_mode,\n",
        "            # trust_remote_code=True # If dataset script requires it\n",
        "        )\n",
        "        if data_args.train_split_name not in raw_datasets_loaded:\n",
        "            raise ValueError(f\"Train split '{data_args.train_split_name}' not found. Available: {list(raw_datasets_loaded.keys())}\")\n",
        "        train_hf_dataset = raw_datasets_loaded[data_args.train_split_name]\n",
        "\n",
        "        if training_args.do_eval:\n",
        "            if data_args.eval_split_name and data_args.eval_split_name in raw_datasets_loaded:\n",
        "                eval_hf_dataset = raw_datasets_loaded[data_args.eval_split_name]\n",
        "            elif \"validation\" in raw_datasets_loaded: eval_hf_dataset = raw_datasets_loaded[\"validation\"]\n",
        "            elif \"test\" in raw_datasets_loaded: eval_hf_dataset = raw_datasets_loaded[\"test\"]\n",
        "            elif data_args.eval_split_size > 0 and len(train_hf_dataset) > 1 : # Ensure dataset is splittable\n",
        "                logger.info(f\"Splitting train dataset for evaluation with ratio {data_args.eval_split_size}\")\n",
        "                split_dataset = train_hf_dataset.train_test_split(test_size=data_args.eval_split_size, seed=training_args.seed)\n",
        "                train_hf_dataset, eval_hf_dataset = split_dataset[\"train\"], split_dataset[\"test\"]\n",
        "                logger.info(f\"Evaluation set size: {len(eval_hf_dataset)}\")\n",
        "            else: logger.warning(\"Evaluation requested but no eval split found/configured or train dataset too small to split. Skipping eval dataset.\")\n",
        "        is_hf_format_train, is_hf_format_eval = True, True\n",
        "    else:\n",
        "        all_files = []\n",
        "        if data_args.metadata_file:\n",
        "            metadata_path = Path(data_args.metadata_file)\n",
        "            dataset_root = metadata_path.parent\n",
        "            with open(metadata_path, 'r', encoding='utf-8') as f:\n",
        "                for line_idx, line in enumerate(f):\n",
        "                    # --- Báº®T Äáº¦U ÄOáº N CODE Sá»¬A ---\n",
        "                    parts = line.strip().split('|')\n",
        "                    # Náº¿u split báº±ng | mÃ  ra Ã­t hÆ¡n 2 cá»™t, thá»­ split báº±ng Tab\n",
        "                    if len(parts) < 2:\n",
        "                        parts = line.strip().split('\\t')\n",
        "\n",
        "                    # Sá»­a Ä‘iá»u kiá»‡n thÃ nh >= 2 (Cháº¥p nháº­n 2 cá»™t trá»Ÿ lÃªn)\n",
        "                    if len(parts) >= 2:\n",
        "                        audio_file = parts[0].strip()\n",
        "                        text = parts[1].strip()\n",
        "                        # CÃ¡c cá»™t sau (nhÆ° Speaker) sáº½ bá»‹ bá» qua, khÃ´ng gÃ¢y lá»—i ná»¯a\n",
        "\n",
        "                        audio_path = Path(audio_file) if Path(audio_file).is_absolute() else dataset_root / audio_file\n",
        "                        if audio_path.exists():\n",
        "                            all_files.append({\"audio\": str(audio_path), \"text\": text})\n",
        "                        else:\n",
        "                            logger.warning(f\"Audio file not found: {audio_path} (line {line_idx+1}). Skipping.\")\n",
        "                    else:\n",
        "                        logger.warning(f\"Skipping malformed line in metadata (line {line_idx+1}): {line.strip()}\")\n",
        "                    # --- Káº¾T THÃšC ÄOáº N CODE Sá»¬A ---\n",
        "        elif data_args.dataset_dir:\n",
        "            dataset_path = Path(data_args.dataset_dir)\n",
        "            for audio_file_path in dataset_path.rglob(\"*.wav\"):\n",
        "                text_file_path = audio_file_path.with_suffix(\".txt\")\n",
        "                if text_file_path.exists():\n",
        "                    with open(text_file_path, 'r', encoding='utf-8') as f: text = f.read().strip()\n",
        "                    all_files.append({\"audio\": str(audio_file_path), \"text\": text})\n",
        "        if not all_files: raise ValueError(\"No data files found from local paths. Check dataset_dir or metadata_file.\")\n",
        "        np.random.shuffle(all_files)\n",
        "        train_hf_dataset = all_files # type: ignore\n",
        "        if data_args.eval_split_size > 0 and training_args.do_eval and len(all_files) > 1:\n",
        "            split_idx = int(len(all_files) * (1 - data_args.eval_split_size))\n",
        "            if split_idx == 0 : split_idx = 1 # Ensure at least one for train if eval gets most\n",
        "            if split_idx == len(all_files): split_idx = len(all_files) -1 # Ensure at least one for eval\n",
        "            train_hf_dataset, eval_hf_dataset = all_files[:split_idx], all_files[split_idx:] # type: ignore\n",
        "        is_hf_format_train, is_hf_format_eval = False, False\n",
        "\n",
        "    train_dataset = SpeechFineTuningDataset(data_args,\n",
        "                                            chatterbox_model,\n",
        "                                            chatterbox_t3_config_instance,\n",
        "                                            train_hf_dataset,\n",
        "                                            is_hf_format_train\n",
        "                                            )\n",
        "\n",
        "\n",
        "    eval_dataset = None\n",
        "    if eval_hf_dataset and training_args.do_eval:\n",
        "        eval_dataset = SpeechFineTuningDataset(data_args,\n",
        "                                                chatterbox_model,\n",
        "                                                chatterbox_t3_config_instance,\n",
        "                                                eval_hf_dataset,\n",
        "                                                is_hf_format_eval\n",
        "                                                )\n",
        "\n",
        "    data_collator = SpeechDataCollator(chatterbox_t3_config_instance,\n",
        "                                       chatterbox_t3_config_instance.stop_text_token,\n",
        "                                       chatterbox_t3_config_instance.stop_speech_token)\n",
        "\n",
        "    hf_trainable_model = T3ForFineTuning(t3_model, chatterbox_t3_config_instance)\n",
        "\n",
        "\n",
        "    callbacks = []\n",
        "    if training_args.early_stopping_patience is not None and training_args.early_stopping_patience > 0:\n",
        "        callbacks.append(EarlyStoppingCallback(early_stopping_patience=training_args.early_stopping_patience))\n",
        "\n",
        "    trainer_instance = Trainer(\n",
        "        model=hf_trainable_model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=eval_dataset,\n",
        "        data_collator=data_collator,\n",
        "        callbacks=callbacks if callbacks else None\n",
        "    )\n",
        "\n",
        "    if training_args.label_names is None: trainer_instance.label_names = [\"labels_text\", \"labels_speech\"]\n",
        "\n",
        "\n",
        "    if training_args.do_train:\n",
        "        logger.info(\"*** Training T3 model ***\")\n",
        "        train_result = trainer_instance.train(resume_from_checkpoint=training_args.resume_from_checkpoint)\n",
        "        trainer_instance.save_model()\n",
        "\n",
        "        logger.info(\"Saving finetuned T3 model weights for ChatterboxTTS...\")\n",
        "        t3_to_save = trainer_instance.model.t3 if hasattr(trainer_instance.model, 't3') else trainer_instance.model.module.t3\n",
        "        finetuned_t3_state_dict = t3_to_save.state_dict()\n",
        "\n",
        "        output_t3_safetensor_path = Path(training_args.output_dir) / \"t3_cfg.safetensors\"\n",
        "        from safetensors.torch import save_file\n",
        "        save_file(finetuned_t3_state_dict, output_t3_safetensor_path)\n",
        "        logger.info(f\"Finetuned T3 model weights saved to {output_t3_safetensor_path}\")\n",
        "\n",
        "        if original_model_dir_for_copy:\n",
        "            import shutil\n",
        "            for f_name in [\"ve.safetensors\", \"s3gen.safetensors\", \"tokenizer.json\"]:\n",
        "                src_path = original_model_dir_for_copy / f_name\n",
        "                if src_path.exists(): shutil.copy2(src_path, Path(training_args.output_dir) / f_name)\n",
        "            if (original_model_dir_for_copy / \"conds.pt\").exists():\n",
        "                shutil.copy2(original_model_dir_for_copy / \"conds.pt\", Path(training_args.output_dir) / \"conds.pt\")\n",
        "            logger.info(f\"Full model components structured in {training_args.output_dir}\")\n",
        "\n",
        "        metrics = train_result.metrics\n",
        "        trainer_instance.log_metrics(\"train\", metrics)\n",
        "        trainer_instance.save_metrics(\"train\", metrics)\n",
        "        trainer_instance.save_state()\n",
        "\n",
        "    if training_args.do_eval and eval_dataset:\n",
        "        logger.info(\"*** Evaluating T3 model ***\")\n",
        "        metrics = trainer_instance.evaluate()\n",
        "        trainer_instance.log_metrics(\"eval\", metrics)\n",
        "        trainer_instance.save_metrics(\"eval\", metrics)\n",
        "\n",
        "    logger.info(\"Finetuning script finished.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "Ae4ng9bUZo_o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}